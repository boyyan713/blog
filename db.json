{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":1,"renderable":1},{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/images/avatarCycle999x999.png","path":"images/avatarCycle999x999.png","modified":1,"renderable":0},{"_id":"source/images/avatarFullSizeClearBackground1318x1997.png","path":"images/avatarFullSizeClearBackground1318x1997.png","modified":1,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"3170eff47c386db00883bd113090acbd3382d4f4","modified":1599056068657},{"_id":"source/_posts/AMLci.md","hash":"6922fd5a00fe5c1e00bce727ceed0534232b7516","modified":1600398823792},{"_id":"source/_posts/AMLworkspaceAuthentication.md","hash":"149db20a3812e9bee9dc467014135e73758196c1","modified":1601727311635},{"_id":"source/_posts/ExtentedImageTrainingSet.md","hash":"f2076939fb988402dccb047a133dd401e1e7d3a1","modified":1599550686374},{"_id":"source/_posts/baslerWithOpencv.md","hash":"e1cc06e0ef5e522b350b260bbe0a66b17517d5e0","modified":1602046341541},{"_id":"source/_posts/MachineLearningFileFormats.md","hash":"5129b73f142bfa1df105148d556553cb5f86582f","modified":1600762466142},{"_id":"source/_posts/DSVM.md","hash":"bc8400716e4dce3dcd3f4bde9964cb36a80355fc","modified":1600388150671},{"_id":"source/_posts/ffmpeg.md","hash":"6d2d81410b1cd20d589fb5f6698be53a237cc6a0","modified":1602040111883},{"_id":"source/_posts/azureRaiseCase.md","hash":"daa1438bd06a2e1f8c0526014b05b937efff4c1a","modified":1601644068644},{"_id":"source/_posts/conda.md","hash":"f6f07308ef37a8aac2401eb9eec156566957a917","modified":1600936273565},{"_id":"source/_posts/frp.md","hash":"978279c3b62ad8d5e72abeda9dd0efcfbc49b85b","modified":1601233338119},{"_id":"source/_posts/patent.md","hash":"394f8718f25a4a88c6625c6cbc62ec512abd1e3c","modified":1600256791622},{"_id":"source/_posts/plantuml.md","hash":"1c756bff43f56a78d56a9a3c451dfae691c3333a","modified":1600675730418},{"_id":"source/_posts/linux.md","hash":"95637f671f0d129346be7f86346993661eab91e7","modified":1600944741897},{"_id":"source/_posts/ssh.md","hash":"2a0d66bdfb4064b7ade9828f0e1165c5f28fb4e3","modified":1600953746356},{"_id":"source/_posts/ubuntuRouter.md","hash":"0f31cd77b22447d53863ea2557e09fa231b528ed","modified":1601103245366},{"_id":"source/_posts/tensorflowGPUsupport.md","hash":"8048a378930eb06910b41f968b9088fc09882863","modified":1600258912731},{"_id":"source/categories/index.md","hash":"34a0cd403363cd1b72435a9112dc9da6cd45867f","modified":1599732466917},{"_id":"source/tags/index.md","hash":"41f192e44449d114a2aac128647e94251e3045ea","modified":1599732417092},{"_id":"source/_posts/vim.md","hash":"10119b0c0927fb61d564951109b25dbf3ad31ace","modified":1599468210232},{"_id":"source/about/index.md","hash":"c942e3708fca54acb4610c277abbd888244f9e60","modified":1599733200274},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1599110831289},{"_id":"themes/next/.gitignore","hash":"56f3470755c20311ddd30d421b377697a6e5e68b","modified":1599110831289},{"_id":"themes/next/.stylintrc","hash":"2cf4d637b56d8eb423f59656a11f6403aa90f550","modified":1599110831289},{"_id":"themes/next/.travis.yml","hash":"ecca3b919a5b15886e3eca58aa84aafc395590da","modified":1599110831289},{"_id":"themes/next/.editorconfig","hash":"8570735a8d8d034a3a175afd1dd40b39140b3e6a","modified":1599110831289},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1599110831293},{"_id":"themes/next/README.md","hash":"9b4b7d66aca47f9c65d6321b14eef48d95c4dff1","modified":1599110831293},{"_id":"themes/next/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1599110831289},{"_id":"themes/next/package.json","hash":"62fad6de02adbbba9fb096cbe2dcc15fe25f2435","modified":1599110831293},{"_id":"themes/next/gulpfile.js","hash":"1b4fc262b89948937b9e3794de812a7c1f2f3592","modified":1599110831293},{"_id":"themes/next/_config.yml","hash":"56001b0a33072b50484023d7ba60b6cda0de7095","modified":1599729580776},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1599110831293},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"aa4cb7aff595ca628cb58160ee1eee117989ec4e","modified":1599110831289},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"e554931b98f251fd49ff1d2443006d9ea2c20461","modified":1599110831289},{"_id":"themes/next/.github/config.yml","hash":"1d3f4e8794986817c0fead095c74f756d45f91ed","modified":1599110831289},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1a435c20ae8fa183d49bbf96ac956f7c6c25c8af","modified":1599110831289},{"_id":"themes/next/.github/issue-close-app.yml","hash":"7cba457eec47dbfcfd4086acd1c69eaafca2f0cd","modified":1599110831289},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"fca600ddef6f80c5e61aeed21722d191e5606e5b","modified":1599110831289},{"_id":"themes/next/.github/lock.yml","hash":"61173b9522ebac13db2c544e138808295624f7fd","modified":1599110831289},{"_id":"themes/next/.github/release-drafter.yml","hash":"3cc10ce75ecc03a5ce86b00363e2a17eb65d15ea","modified":1599110831289},{"_id":"themes/next/.github/mergeable.yml","hash":"0ee56e23bbc71e1e76427d2bd255a9879bd36e22","modified":1599110831289},{"_id":"themes/next/.github/stale.yml","hash":"fdf82de9284f8bc8e0b0712b4cc1cb081a94de59","modified":1599110831289},{"_id":"themes/next/.github/support.yml","hash":"d75db6ffa7b4ca3b865a925f9de9aef3fc51925c","modified":1599110831289},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"c7a994b9542040317d8f99affa1405c143a94a38","modified":1599110831293},{"_id":"themes/next/docs/AUTHORS.md","hash":"10135a2f78ac40e9f46b3add3e360c025400752f","modified":1599110831293},{"_id":"themes/next/docs/DATA-FILES.md","hash":"cddbdc91ee9e65c37a50bec12194f93d36161616","modified":1599110831293},{"_id":"themes/next/docs/INSTALLATION.md","hash":"af88bcce035780aaa061261ed9d0d6c697678618","modified":1599110831293},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"94dc3404ccb0e5f663af2aa883c1af1d6eae553d","modified":1599110831293},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1599110831293},{"_id":"themes/next/docs/MATH.md","hash":"d645b025ec7fb9fbf799b9bb76af33b9f5b9ed93","modified":1599110831293},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"8b6e4b2c9cfcb969833092bdeaed78534082e3e6","modified":1599110831293},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1599110831293},{"_id":"themes/next/layout/_layout.swig","hash":"6a6e92a4664cdb981890a27ac11fd057f44de1d5","modified":1599110831293},{"_id":"themes/next/layout/archive.swig","hash":"e4e31317a8df68f23156cfc49e9b1aa9a12ad2ed","modified":1599110831293},{"_id":"themes/next/layout/category.swig","hash":"1bde61cf4d2d171647311a0ac2c5c7933f6a53b0","modified":1599110831293},{"_id":"themes/next/layout/index.swig","hash":"7f403a18a68e6d662ae3e154b2c1d3bbe0801a23","modified":1599110831293},{"_id":"themes/next/layout/page.swig","hash":"db581bdeac5c75fabb0f17d7c5e746e47f2a9168","modified":1599110831293},{"_id":"themes/next/layout/post.swig","hash":"2f6d992ced7e067521fdce05ffe4fd75481f41c5","modified":1599110831293},{"_id":"themes/next/layout/tag.swig","hash":"0dfb653bd5de980426d55a0606d1ab122bd8c017","modified":1599110831293},{"_id":"themes/next/languages/ar.yml","hash":"9815e84e53d750c8bcbd9193c2d44d8d910e3444","modified":1599110831293},{"_id":"themes/next/languages/de.yml","hash":"74c59f2744217003b717b59d96e275b54635abf5","modified":1599110831293},{"_id":"themes/next/languages/en.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1599189013914},{"_id":"themes/next/languages/default.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1599189013914},{"_id":"themes/next/languages/es.yml","hash":"c64cf05f356096f1464b4b1439da3c6c9b941062","modified":1599110831293},{"_id":"themes/next/languages/fa.yml","hash":"3676b32fda37e122f3c1a655085a1868fb6ad66b","modified":1599110831293},{"_id":"themes/next/languages/id.yml","hash":"572ed855d47aafe26f58c73b1394530754881ec2","modified":1599110831293},{"_id":"themes/next/languages/fr.yml","hash":"752bf309f46a2cd43890b82300b342d7218d625f","modified":1599110831293},{"_id":"themes/next/languages/it.yml","hash":"44759f779ce9c260b895532de1d209ad4bd144bf","modified":1599110831293},{"_id":"themes/next/languages/ja.yml","hash":"0cf0baa663d530f22ff380a051881216d6adcdd8","modified":1599110831293},{"_id":"themes/next/languages/hu.yml","hash":"b1ebb77a5fd101195b79f94de293bcf9001d996f","modified":1599110831293},{"_id":"themes/next/languages/ko.yml","hash":"0feea9e43cd399f3610b94d755a39fff1d371e97","modified":1599110831293},{"_id":"themes/next/languages/nl.yml","hash":"5af3473d9f22897204afabc08bb984b247493330","modified":1599110831293},{"_id":"themes/next/languages/pt-BR.yml","hash":"67555b1ba31a0242b12fc6ce3add28531160e35b","modified":1599110831293},{"_id":"themes/next/languages/pt.yml","hash":"718d131f42f214842337776e1eaddd1e9a584054","modified":1599110831293},{"_id":"themes/next/languages/ru.yml","hash":"e993d5ca072f7f6887e30fc0c19b4da791ca7a88","modified":1599110831293},{"_id":"themes/next/languages/tr.yml","hash":"fe793f4c2608e3f85f0b872fd0ac1fb93e6155e2","modified":1599110831293},{"_id":"themes/next/languages/uk.yml","hash":"3a6d635b1035423b22fc86d9455dba9003724de9","modified":1599110831293},{"_id":"themes/next/languages/vi.yml","hash":"93393b01df148dcbf0863f6eee8e404e2d94ef9e","modified":1599110831293},{"_id":"themes/next/scripts/renderer.js","hash":"49a65df2028a1bc24814dc72fa50d52231ca4f05","modified":1599110831293},{"_id":"themes/next/languages/zh-TW.yml","hash":"8c09da7c4ec3fca2c6ee897b2eea260596a2baa1","modified":1599110831293},{"_id":"themes/next/languages/zh-HK.yml","hash":"3789f94010f948e9f23e21235ef422a191753c65","modified":1599110831293},{"_id":"themes/next/languages/zh-CN.yml","hash":"a1f15571ee7e1e84e3cc0985c3ec4ba1a113f6f8","modified":1599110831293},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.md","hash":"c3e6b8196c983c40fd140bdeca012d03e6e86967","modified":1599110831289},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.md","hash":"12d99fb8b62bd9e34d9672f306c9ae4ace7e053e","modified":1599110831289},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"0bd2d696f62a997a11a7d84fec0130122234174e","modified":1599110831293},{"_id":"themes/next/.github/ISSUE_TEMPLATE/question.md","hash":"53df7d537e26aaf062d70d86835c5fd8f81412f3","modified":1599110831289},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.md","hash":"d3efc0df0275c98440e69476f733097916a2d579","modified":1599110831289},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"9c4fe2873123bf9ceacab5c50d17d8a0f1baef27","modified":1599110831293},{"_id":"themes/next/layout/_partials/comments.swig","hash":"db6ab5421b5f4b7cb32ac73ad0e053fdf065f83e","modified":1599110831293},{"_id":"themes/next/docs/ru/README.md","hash":"85dd68ed1250897a8e4a444a53a68c1d49eb7e11","modified":1599110831293},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"5237a368ab99123749d724b6c379415f2c142a96","modified":1599110831293},{"_id":"themes/next/layout/_partials/footer.swig","hash":"4369b313cbbeae742cb35f86d23d99d4285f7359","modified":1599110831293},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1599110831293},{"_id":"themes/next/layout/_partials/languages.swig","hash":"ba9e272f1065b8f0e8848648caa7dea3f02c6be1","modified":1599110831293},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"83a40ce83dfd5cada417444fb2d6f5470aae6bb0","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"34b88784ec120dfdc20fa82aadeb5f64ef614d14","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"fb23b85db6f7d8279d73ae1f41631f92f64fc864","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"d3f03be036b75dc71cf3c366cd75aee7c127c874","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"ca1030efdfca5e20f9db2e7a428998e66a24c0d0","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"579c7bd8341873fb8be4732476d412814f1a3df7","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"8b18f84503a361fc712b0fe4d4568e2f086ca97d","modified":1599110831293},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"9c8dc0b8170679cdc1ee9ee8dbcbaebf3f42897b","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"b92585d251f1f9ebe401abb5d932cb920f9b8b10","modified":1599110831293},{"_id":"themes/next/layout/_macro/post.swig","hash":"090b5a9b6fca8e968178004cbd6cff205b7eba57","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/README.md","hash":"c038629ff8f3f24e8593c4c8ecf0bef3a35c750d","modified":1599110831293},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"71655ca21907e9061b6e8ac52d0d8fbf54d0062b","modified":1599110831293},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"d9ce7331c1236bbe0a551d56cef2405e47e65325","modified":1599110831293},{"_id":"themes/next/layout/_scripts/index.swig","hash":"cea942b450bcb0f352da78d76dc6d6f1d23d5029","modified":1599110831293},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"4d2c93c66e069852bb0e3ea2e268d213d07bfa3f","modified":1599110831293},{"_id":"themes/next/layout/_scripts/three.swig","hash":"a4f42f2301866bd25a784a2281069d8b66836d0b","modified":1599110831293},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"d1f2bfde6f1da51a2b35a7ab9e7e8eb6eefd1c6b","modified":1599110831293},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"ef38c213679e7b6d2a4116f56c9e55d678446069","modified":1599110831293},{"_id":"themes/next/layout/_third-party/index.swig","hash":"70c3c01dd181de81270c57f3d99b6d8f4c723404","modified":1599110831293},{"_id":"themes/next/scripts/events/index.js","hash":"5743cde07f3d2aa11532a168a652e52ec28514fd","modified":1599110831293},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"aec50ed57b9d5d3faf2db3c88374f107203617e0","modified":1599110831293},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"703bdd142a671b4b67d3d9dfb4a19d1dd7e7e8f7","modified":1599110831293},{"_id":"themes/next/scripts/filters/locals.js","hash":"b193a936ee63451f09f8886343dcfdca577c0141","modified":1599110831293},{"_id":"themes/next/scripts/filters/minify.js","hash":"19985723b9f677ff775f3b17dcebf314819a76ac","modified":1599110831293},{"_id":"themes/next/scripts/filters/post.js","hash":"44ba9b1c0bdda57590b53141306bb90adf0678db","modified":1599110831293},{"_id":"themes/next/scripts/helpers/engine.js","hash":"bdb424c3cc0d145bd0c6015bb1d2443c8a9c6cda","modified":1599110831293},{"_id":"themes/next/scripts/helpers/font.js","hash":"40cf00e9f2b7aa6e5f33d412e03ed10304b15fd7","modified":1599110831293},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"5e11f30ddb5093a88a687446617a46b048fa02e5","modified":1599110831293},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"958e86b2bd24e4fdfcbf9ce73e998efe3491a71f","modified":1599110831293},{"_id":"themes/next/scripts/tags/button.js","hash":"8c6b45f36e324820c919a822674703769e6da32c","modified":1599110831293},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"94e0bbc7999b359baa42fa3731bdcf89c79ae2b3","modified":1599110831293},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"b782eb2e34c0c15440837040b5d65b093ab6ec04","modified":1599110831293},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f1826ade2d135e2f60e2d95cb035383685b3370c","modified":1599110831297},{"_id":"themes/next/scripts/tags/label.js","hash":"fc5b267d903facb7a35001792db28b801cccb1f8","modified":1599110831297},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"d902fd313e8d35c3cc36f237607c2a0536c9edf1","modified":1599110831297},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"983c6c4adea86160ecc0ba2204bc312aa338121d","modified":1599110831297},{"_id":"themes/next/scripts/tags/note.js","hash":"0a02bb4c15aec41f6d5f1271cdb5c65889e265d9","modified":1599110831297},{"_id":"themes/next/scripts/tags/pdf.js","hash":"8c613b39e7bff735473e35244b5629d02ee20618","modified":1599110831297},{"_id":"themes/next/scripts/tags/tabs.js","hash":"93d8a734a3035c1d3f04933167b500517557ba3e","modified":1599110831297},{"_id":"themes/next/scripts/tags/video.js","hash":"e5ff4c44faee604dd3ea9db6b222828c4750c227","modified":1599110831297},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"311e5eceec9e949f1ea8d623b083cec0b8700ff2","modified":1599110831293},{"_id":"themes/next/source/css/_colors.styl","hash":"a8442520f719d3d7a19811cb3b85bcfd4a596e1f","modified":1599110831297},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"2731e262a6b88eaee2a3ca61e6a3583a7f594702","modified":1599110831293},{"_id":"themes/next/source/css/main.styl","hash":"a3a3bbb5a973052f0186b3523911cb2539ff7b88","modified":1599110831297},{"_id":"themes/next/source/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1599110831297},{"_id":"themes/next/source/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1599110831297},{"_id":"themes/next/source/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1599110831297},{"_id":"themes/next/source/css/_mixins.styl","hash":"e31a557f8879c2f4d8d5567ee1800b3e03f91f6e","modified":1599110831297},{"_id":"themes/next/source/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1599110831297},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1599110831297},{"_id":"themes/next/source/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1599110831297},{"_id":"themes/next/source/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1599110831297},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1599110831297},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1599110831297},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1599110831297},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1599110831297},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1599110831297},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1599110831297},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1599110831297},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1599110831297},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1599110831297},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1599110831297},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1599110831297},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1599110831297},{"_id":"themes/next/source/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1599110831297},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"c70f8e71e026e878a4e9d5ab3bbbf9b0b23c240c","modified":1599110831293},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"7dbe93b8297b746afb89700b4d29289556e85267","modified":1599110831293},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"9440d8a3a181698b80e1fa47f5104f4565d8cdf3","modified":1599110831293},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"d31f896680a6c2f2c3f5128b4d4dd46c87ce2130","modified":1599110831293},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"ae2261bea836581918a1c2b0d1028a78718434e0","modified":1599110831293},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"000bad572d76ee95d9c0a78f9ccdc8d97cc7d4b4","modified":1599110831293},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"810d544019e4a8651b756dd23e5592ee851eda71","modified":1599110831293},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"c851717497ca64789f2176c9ecd1dedab237b752","modified":1599110831293},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"954ad71536b6eb08bd1f30ac6e2f5493b69d1c04","modified":1599110831293},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"9b7a66791d7822c52117fe167612265356512477","modified":1599110831293},{"_id":"themes/next/layout/_partials/post/post-followme.swig","hash":"ceba16b9bd3a0c5c8811af7e7e49d0f9dcb2f41e","modified":1599110831293},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"8f14f3f8a1b2998d5114cc56b680fb5c419a6b07","modified":1599110831293},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"f79c44692451db26efce704813f7a8872b7e63a0","modified":1599110831293},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"2b1a73556595c37951e39574df5a3f20b2edeaef","modified":1599110831293},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"48430bd03b8f19c9b8cdb2642005ed67d56c6e0b","modified":1599110831293},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"2be50f9bfb1c56b85b3b6910a7df27f51143632c","modified":1599110831293},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"c46849e0af8f8fb78baccd40d2af14df04a074af","modified":1599110831293},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"f48a6a8eba04eb962470ce76dd731e13074d4c45","modified":1599110831293},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1599110831293},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1599110831293},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"077b5d66f6309f2e7dcf08645058ff2e03143e6c","modified":1599110831293},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1599110831293},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1599110831293},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"4790058691b7d36cf6d2d6b4e93795a7b8d608ad","modified":1599110831293},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"2fa2b51d56bfac6a1ea76d651c93b9c20b01c09b","modified":1599110831293},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"5adea065641e8c55994dd2328ddae53215604928","modified":1599110831293},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"1472cabb0181f60a6a0b7fec8899a4d03dfb2040","modified":1599110831293},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"f910618292c63871ca2e6c6e66c491f344fa7b1f","modified":1599110831293},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"cba0e6e0fad08568a9e74ba9a5bee5341cfc04c1","modified":1599110831293},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"f39a5bf3ce9ee9adad282501235e0c588e4356ec","modified":1599110831293},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b14908644225d78c864cd0a9b60c52407de56183","modified":1599110831293},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"82f5b6822aa5ec958aa987b101ef860494c6cf1f","modified":1599110831293},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"d6ceb70648555338a80ae5724b778c8c58d7060d","modified":1599110831293},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"f7a9eca599a682479e8ca863db59be7c9c7508c8","modified":1599110831293},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"be0a8eccf1f6dc21154af297fc79555343031277","modified":1599110831293},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"6c5976621efd5db5f7c4c6b4f11bc79d6554885f","modified":1599110831293},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"4791c977a730f29c846efcf6c9c15131b9400ead","modified":1599110831293},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"ecf751321e799f0fb3bf94d049e535130e2547aa","modified":1599110831293},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"d35a999d67f4c302f76fdf13744ceef3c6506481","modified":1599110831293},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"767b6c714c22588bcd26ba70b0fc19b6810cbacd","modified":1599110831293},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"ba0dbc06b9d244073a1c681ff7a722dcbf920b51","modified":1599110831293},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"f3c43664a071ff3c0b28bd7e59b5523446829576","modified":1599110831293},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"4b1986e43d6abce13450d2b41a736dd6a5620a10","modified":1599110831293},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"d30b0e255a8092043bac46441243f943ed6fb09b","modified":1599110831293},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"a17ace37876822327a2f9306a472974442c9005d","modified":1599110831293},{"_id":"themes/next/scripts/events/lib/config.js","hash":"d34c6040b13649714939f59be5175e137de65ede","modified":1599110831293},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"6661c1c91c7cbdefc6a5e6a034b443b8811235a1","modified":1599110831293},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"f233d8d0103ae7f9b861344aa65c1a3c1de8a845","modified":1599110831293},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"a54708fd9309b4357c423a3730eb67f395344a5e","modified":1599110831293},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"2486f3e0150c753e5f3af1a3665d074704b8ee2c","modified":1599110831293},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"7f2d93af012c1e14b8596fecbfc7febb43d9b7f5","modified":1599110831293},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"4c0c99c7e0f00849003dfce02a131104fb671137","modified":1599110831293},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"7f8b92913d21070b489457fa5ed996d2a55f2c32","modified":1599110831293},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"e51dc3072c1ba0ea3008f09ecae8b46242ec6021","modified":1599110831293},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"d5fefc31fba4ab0188305b1af1feb61da49fdeb0","modified":1599110831293},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"6cbd85f9433c06bae22225ccf75ac55e04f2d106","modified":1599110831293},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"b26ac2bfbe91dd88267f8b96aee6bb222b265b7a","modified":1599110831293},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"5f6a966c509680dbfa70433f9d658cee59c304d7","modified":1599110831293},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"d56d5af427cdfecc33a0f62ee62c056b4e33d095","modified":1599110831293},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"f4e694e5db81e57442c7e34505a416d818b3044a","modified":1599110831297},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"f70be8e229da7e1715c11dd0e975a2e71e453ac8","modified":1599110831297},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"62df49459d552bbf73841753da8011a1f5e875c8","modified":1599110831297},{"_id":"themes/next/source/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1599110831297},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"612ec843372dae709acb17112c1145a53450cc59","modified":1599110831297},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1599110831297},{"_id":"themes/next/source/css/_variables/base.styl","hash":"818508748b7a62e02035e87fe58e75b603ed56dc","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"ca5e70662dcfb261c25191cc5db5084dcf661c76","modified":1599110831297},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"8e7b57a72e757cf95278239641726bb2d5b869d1","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"a47725574e1bee3bc3b63b0ff2039cc982b17eff","modified":1599110831297},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"2e3bf7baf383c9073ec5e67f157d3cb3823c0957","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"681d33e3bc85bdca407d93b134c089264837378c","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"b1f0fab7344a20ed6748b04065b141ad423cf4d9","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"0b2c4b78eead410020d7c4ded59c75592a648df8","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"a1690e035b505d28bdef2b4424c13fc6312ab049","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"a2e9e00962e43e98ec2614d6d248ef1773bb9b78","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"8f58570a1bbc34c4989a47a1b7d42a8030f38b06","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"179e33b8ac7f4d8a8e76736a7e4f965fe9ab8b42","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"7785bd756e0c4acede3a47fec1ed7b55988385a5","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"f6516d0f7d89dc7b6c6e143a5af54b926f585d82","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"18ce72d90459c9aa66910ac64eae115f2dde3767","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"7104b9cef90ca3b140d7a7afcf15540a250218fc","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"6136da4bbb7e70cec99f5c7ae8c7e74f5e7c261a","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"bb7ace23345364eb14983e860a7172e1683a4c94","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"f0131db6275ceaecae7e1a6a3798b8f89f6c850d","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"4d1c17345d2d39ef7698f7acf82dfc0f59308c34","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"a717969829fa6ef88225095737df3f8ee86c286b","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"93db5dafe9294542a6b5f647643cb9deaced8e06","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"2b2e7b5cea7783c9c8bb92655e26a67c266886f0","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"e282df938bd029f391c466168d0e68389978f120","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"70a4324b70501132855b5e59029acfc5d3da1ebd","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1599110831297},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1599110831297},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"44f47c88c06d89d06f220f102649057118715828","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"fafc96c86926b22afba8bb9418c05e6afbc05a57","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"e771dcb0b4673e063c0f3e2d73e7336ac05bcd57","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"2bd0eb1512415325653b26d62a4463e6de83c5ac","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"d21d4ac1982c13d02f125a67c065412085a92ff2","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"8a7fc03a568b95be8d3337195e38bc7ec5ba2b23","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"e2992846b39bf3857b5104675af02ba73e72eed5","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"b49e9fbd3c182b8fc066b8c2caf248e3eb748619","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"9f0b93d109c9aec79450c8a0cf4a4eab717d674d","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"85da2f3006f4bef9a2199416ecfab4d288f848c4","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"e75693f33dbc92afc55489438267869ae2f3db54","modified":1599110831297},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"e740deadcfc4f29c5cb01e40f9df6277262ba4e3","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"902569a9dea90548bec21a823dd3efd94ff7c133","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"ded41fd9d20a5e8db66aaff7cc50f105f5ef2952","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"72d495a88f7d6515af425c12cbc67308a57d88ea","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f49ca072b5a800f735e8f01fc3518f885951dd8e","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"1e4190c10c9e0c9ce92653b0dbcec21754b0b69d","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"65cb6edb69e94e70e3291e9132408361148d41d5","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"d114b2a531129e739a27ba6271cfe6857aa9a865","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"6a97bcfa635d637dc59005be3b931109e0d1ead5","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9a878d0119785a2316f42aebcceaa05a120b9a7a","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"f5c2788a78790aca1a2f37f7149d6058afb539e0","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"5b5649b9749e3fd8b63aef22ceeece0a6e1df605","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"a760ee83ba6216871a9f14c5e56dc9bd0d9e2103","modified":1599110831297},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"99e12c9ce3d14d4837e3d3f12fc867ba9c565317","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"e2d606f1ac343e9be4f15dbbaf3464bc4df8bf81","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"454a4aebfabb4469b92a8cbb49f46c49ac9bf165","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"e7a9fdb6478b8674b1cdf94de4f8052843fb71d9","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"a793cfff86ad4af818faef04c18013077873f8f0","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"0caf32492692ba8e854da43697a2ec8a41612194","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"5f432a6ed9ca80a413c68b00e93d4a411abf280a","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"45a239edca44acecf971d99b04f30a1aafbf6906","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b2fc519828fe89a1f8f03ff7b809ad68cd46f3d7","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"2cb1876e9e0c9ac32160888af27b1178dbcb0616","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"fa0222197b5eee47e18ac864cdc6eac75678b8fe","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"44487d9ab290dc97871fa8dd4487016deb56e123","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"1f0e7fbe80956f47087c2458ea880acf7a83078b","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"9b479c2f9a9bfed77885e5093b8245cc5d768ec7","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"a960a2dd587b15d3b3fe1b59525d6fa971c6a6ec","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"a05a4031e799bc864a4536f9ef61fe643cd421af","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"f71a3e86c05ea668b008cf05a81f67d92b6d65e4","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"b3220db827e1adbca7880c2bb23e78fa7cbe95cb","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"a9cd93c36bae5af9223e7804963096274e8a4f03","modified":1599110831297},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"2a47f8a6bb589c2fb635e6c1e4a2563c7f63c407","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"d3f73688bb7423e3ab0de1efdf6db46db5e34f80","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"35c871a809afa8306c8cde13651010e282548bc6","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"1d2778ca5aeeeafaa690dc2766b01b352ab76a02","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"3b3acc5caa0b95a2598bef4eeacb21bab21bea56","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"709d10f763e357e1472d6471f8be384ec9e2d983","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"d7fce4b51b5f4b7c31d93a9edb6c6ce740aa0d6b","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b49c64f8e9a6ca1c45c0ba98febf1974fdd03616","modified":1599110831297},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1599110831297},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"e4d9a77ffe98e851c1202676940097ba28253313","modified":1599110831297},{"_id":"source/images/avatarCycle999x999.png","hash":"5ef7384b056ffb4aa814254e0e0c6f190544dcb5","modified":1599189080000},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"f23670f1d8e749f3e83766d446790d8fd9620278","modified":1599110831297},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"9e4c0653cfd3cc6908fa0d97581bcf80861fb1e7","modified":1599110831297},{"_id":"source/images/avatarFullSizeClearBackground1318x1997.png","hash":"8a4e822770a94cbac572ff7b2651605267ea3c36","modified":1599189040000},{"_id":"public/about/index.html","hash":"c61e0caf51837d0f78415f0e8ed71bcb329cc6e9","modified":1602046354245},{"_id":"public/categories/index.html","hash":"be517a76707f14dd4b3ba9656c82b2286bb49d2b","modified":1602046354245},{"_id":"public/tags/index.html","hash":"589d709b6cc4450e50a410ac6a2c4a59f97bfe39","modified":1602046354245},{"_id":"public/2020/10/07/ffmpeg/index.html","hash":"869c404c1a0beff0372949233d9ef338a341bbed","modified":1602046354245},{"_id":"public/2020/10/03/azureRaiseCase/index.html","hash":"81afb3abe32d05e0707773a113591f667170db0a","modified":1602046354245},{"_id":"public/2020/09/26/frp/index.html","hash":"448aee2abc2342c2f8e11cfc0f6bf9f4f9bb5f6a","modified":1602046354245},{"_id":"public/2020/09/25/AMLworkspaceAuthentication/index.html","hash":"fc0b14f2d04b437a90e12642e83fe2deac0828ad","modified":1602046354245},{"_id":"public/2020/09/23/baslerWithOpencv/index.html","hash":"3e9ab7521430d4c565ee7269c62677ec78d50870","modified":1602046354245},{"_id":"public/2020/09/22/MachineLearningFileFormats/index.html","hash":"eece2dc7954ad1b4d38360e841ddfb685724ff75","modified":1602046354245},{"_id":"public/2020/09/21/plantuml/index.html","hash":"bfcf19c108bcca2e8b34a302b59b0d74b8411e43","modified":1602046354245},{"_id":"public/2020/09/17/AMLci/index.html","hash":"310bcf2f4401adb59af61f3046cb007a9bd07b21","modified":1602046354245},{"_id":"public/2020/09/17/linux/index.html","hash":"326efab1c6acd86a3d5ffaa1fcd0e69008dc51e5","modified":1602046354245},{"_id":"public/2020/09/16/patent/index.html","hash":"afae9dff390f25d850989fda397a695b1b69eaed","modified":1602046354245},{"_id":"public/2020/09/15/tensorflowGPUsupport/index.html","hash":"47282687139020ae29c3f5e7c9b47b9752c92ffb","modified":1602046354245},{"_id":"public/2020/09/10/DSVM/index.html","hash":"824136d73ce95a8323c00539ad726b16ae59aebb","modified":1602046354245},{"_id":"public/2020/09/08/ssh/index.html","hash":"ba3ca181677030baaad8c6e83e240fe81abc6d91","modified":1602046354245},{"_id":"public/2020/09/08/conda/index.html","hash":"9215e1d821362d5114a203c85d8c8dbb9b234277","modified":1602046354245},{"_id":"public/2020/09/08/ExtentedImageTrainingSet/index.html","hash":"f276d577628bce1aa5fb37d143b629295d4a3025","modified":1602046354245},{"_id":"public/2020/09/07/vim/index.html","hash":"7ad0c099a5028c498726a84c0201a4b989b8b28b","modified":1602046354245},{"_id":"public/2020/09/05/ubuntuRouter/index.html","hash":"4a233fe4730cbe0a7cdde21f385a2ac97aa6d6b9","modified":1602046354245},{"_id":"public/archives/index.html","hash":"505031b449ab47eb24ce2db03c8f9c1e0659d5b5","modified":1602046354245},{"_id":"public/archives/page/2/index.html","hash":"da0db17eee875c3d63662ac777b8fbba551a0572","modified":1602046354245},{"_id":"public/archives/2020/index.html","hash":"326b3d9d27ffe9e1e86ed39af221787d69162844","modified":1602046354245},{"_id":"public/archives/2020/page/2/index.html","hash":"d5b5fd6ff89bc6cf2c0392db15b7b07c71fc233b","modified":1602046354245},{"_id":"public/archives/2020/09/index.html","hash":"8c1c20b2704a2038777d8d09d1d4d622d96e32c6","modified":1602046354245},{"_id":"public/archives/2020/09/page/2/index.html","hash":"9a918176ded30563589320789e16f8fd059a6d6d","modified":1602046354245},{"_id":"public/archives/2020/10/index.html","hash":"194d3722aaefc7a6ece412b8c22f797dbf115f7b","modified":1602046354245},{"_id":"public/index.html","hash":"011e8dfbc3512a5eeb4cdc2d8358f7fc30a9b763","modified":1602046354245},{"_id":"public/page/2/index.html","hash":"4b0b325d86017b0a4cff68d78d2c75b940bf89f1","modified":1602046354245},{"_id":"public/tags/Azure/index.html","hash":"eea062dc95d559e72b41967f53fc32cd03492053","modified":1602046354245},{"_id":"public/tags/Compute-instance/index.html","hash":"3fab82c735c468838fc8aca2c5de233970873532","modified":1602046354245},{"_id":"public/tags/Azure-Machine-Learning/index.html","hash":"3dfe28b46e14a8ce72091699b0ad603e22c09ce1","modified":1602046354245},{"_id":"public/tags/Machine-Learning/index.html","hash":"9890ef0e04fb0cf4d5eb55986174656321c38eaf","modified":1602046354245},{"_id":"public/tags/Virtual-Machine/index.html","hash":"d4eccd978fd1fcaec5ddd6b60fec0cf479669011","modified":1602046354245},{"_id":"public/tags/Extented-Image-Training-Set/index.html","hash":"72ba01bab8caabd66e85178c90a4c0776213d34e","modified":1602046354245},{"_id":"public/tags/OpenCV/index.html","hash":"4d20c2935fed8c3563c3e54e43f6658c328a7e73","modified":1602046354245},{"_id":"public/tags/machine-Learning-File-Formats/index.html","hash":"4c4952898b1b375529d5e8ec68368fd48cd75a7d","modified":1602046354245},{"_id":"public/tags/Conda/index.html","hash":"dff12f605fd76ba971a5d9b3aa5bd617ff4b9643","modified":1602046354245},{"_id":"public/tags/Python/index.html","hash":"2f9ea6d84d9de45c4826d4ca273188068b1cd725","modified":1602046354245},{"_id":"public/tags/R/index.html","hash":"c0879d9ecc298e515e1cd047162be26d4d25254f","modified":1602046354245},{"_id":"public/tags/Networking/index.html","hash":"3fc6e47cc727d284674cf671ac8b2601908fc64a","modified":1602046354245},{"_id":"public/tags/Linux-command/index.html","hash":"c480965637e715644d71492e41d1e255c0370f44","modified":1602046354245},{"_id":"public/tags/Patent/index.html","hash":"b15e6025f1ec2fb6fbdc192856f1c0aed829baf0","modified":1602046354245},{"_id":"public/tags/UML/index.html","hash":"df57d76e378e341fcade844dbf57a243ca8d2578","modified":1602046354245},{"_id":"public/tags/plantuml/index.html","hash":"ebbe7d6cba504e8cb4dbe22dda07aed1e98b4a8c","modified":1602046354245},{"_id":"public/tags/Markdown/index.html","hash":"0745afa0c4eb3f66afe0957e6069c1b49ac88841","modified":1602046354245},{"_id":"public/tags/Emacs/index.html","hash":"2af931e550a6823f80bfb735baeabfdc63f1ab7a","modified":1602046354245},{"_id":"public/tags/spacemacs/index.html","hash":"2d920ac75706cbfe41adb2fc5c7e9f13181a412d","modified":1602046354245},{"_id":"public/tags/SSH/index.html","hash":"31676d7d8e509a7d9bdf7e23b4e509410fd0dd30","modified":1602046354245},{"_id":"public/tags/Tensorflow/index.html","hash":"94647d69a765da2902a7d132c24cce35819f7d8d","modified":1602046354245},{"_id":"public/tags/Nvidia-GPU/index.html","hash":"ed0f230f467d5e66c603609d68f519963f4a9ae8","modified":1602046354245},{"_id":"public/tags/vim/index.html","hash":"6c6e122cbbc0632cf82eda4e3e273da72b537cfc","modified":1602046354245},{"_id":"public/tags/Basler/index.html","hash":"54de0058e58f6621ef3428725337c551f2ec7574","modified":1602046354245},{"_id":"public/tags/Opencv/index.html","hash":"2c101fad5da41c69550948c889addcc0eac3f244","modified":1602046354245},{"_id":"public/tags/python/index.html","hash":"b03a9457bcc251f4e0c067d9ab81ee861d9ae312","modified":1602046354245},{"_id":"public/categories/Azure/index.html","hash":"61eaff7a7430949bec2ca11d8459b7e1ac0b53b5","modified":1602046354245},{"_id":"public/categories/Machine-Learning/index.html","hash":"4c2558759b82fb89b7dbaa57818015a51530e7b2","modified":1602046354245},{"_id":"public/categories/virtual-environment/index.html","hash":"e4ad8c164f53ca4a720c1a09085e03abd2009629","modified":1602046354245},{"_id":"public/categories/Networking/index.html","hash":"29917b3c126f55128a06fecf8835b513be17c6f1","modified":1602046354245},{"_id":"public/categories/Patent/index.html","hash":"de2e8cdff5006b07de6079f7f75af83a21bc951c","modified":1602046354245},{"_id":"public/categories/UML/index.html","hash":"c3d8e64476a3579c0cd18926103a60077ea9e305","modified":1602046354245},{"_id":"public/categories/GPU/index.html","hash":"7bebb19deb1c594449dfd4d4d86d9358c5e011e6","modified":1602046354245},{"_id":"public/categories/editor/index.html","hash":"9816231ac3d2189e638950ef7cfeefa290ee84b9","modified":1602046354245},{"_id":"public/categories/Basler/index.html","hash":"000802cb224c57816d23ece6111ed23ef8689823","modified":1602046354245},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1602046354245},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1602046354245},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1602046354245},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1602046354245},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1602046354245},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1602046354245},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1602046354245},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1602046354245},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1602046354245},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1602046354245},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1602046354245},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1602046354245},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1602046354245},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1602046354245},{"_id":"public/CNAME","hash":"3170eff47c386db00883bd113090acbd3382d4f4","modified":1602046354245},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1602046354245},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1602046354245},{"_id":"public/css/main.css","hash":"6b3ad716ca398497b11623ffaa04dcaabaa5a327","modified":1602046354245},{"_id":"public/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1602046354245},{"_id":"public/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1602046354245},{"_id":"public/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1602046354245},{"_id":"public/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1602046354245},{"_id":"public/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1602046354245},{"_id":"public/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1602046354245},{"_id":"public/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1602046354245},{"_id":"public/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1602046354245},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1602046354245},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1602046354245},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1602046354245},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1602046354245},{"_id":"public/images/avatarCycle999x999.png","hash":"5ef7384b056ffb4aa814254e0e0c6f190544dcb5","modified":1602046354245},{"_id":"public/images/avatarFullSizeClearBackground1318x1997.png","hash":"8a4e822770a94cbac572ff7b2651605267ea3c36","modified":1602046354245}],"Category":[{"name":"Azure","_id":"ckfyx1air0004iiiya4hf8xra"},{"name":"Machine Learning","_id":"ckfyx1aiy000liiiy4jgf5hfq"},{"name":"virtual environment","_id":"ckfyx1aj0000siiiydv9nbh1i"},{"name":"Networking","_id":"ckfyx1aj2000ziiiy9la91kr5"},{"name":"Patent","_id":"ckfyx1aj40016iiiy5lfw19cx"},{"name":"UML","_id":"ckfyx1aj40019iiiy5itq550o"},{"name":"GPU","_id":"ckfyx1aj5001hiiiy2v3j3rhm"},{"name":"editor","_id":"ckfyx1aje002uiiiyhkbrd9yd"},{"name":"Basler","_id":"ckfyx1aje002wiiiy36rs0sah"}],"Data":[],"Page":[{"title":"About Me","date":"2020-09-04T11:31:37.000Z","comments":0,"_content":"# Personal Evaluation\nI see myself advancing with a strong ability and interesting in new technology\nand academic research.\nI successfully participated two international academic conferences,\none published paper and one patent. In the University study, I got undergraduate\nscholarships and the best prize for final project. The final project is related\nto swipe card system. My insteresting research area on computer graphic, softerware testing and machine learning.\n\n# Working Experience\n1. 2020.3 - now\n\t* Support Engineer\n\t* Microsoft, China\n\t* Azure Machine Learning CSS Team\n2. 2018.12 - 2020.3\n\t* Algorithm Engineer\n\t* Peng Chen Laboratory, China\n\t* Network Communication Research Center\n3. 2018.1 - 2018.11\n\t* Research Assistant (Computer Science)\n\t* University of Wollongong, Australia\n\t* Metamorphic Testing - Software Testing\n\n# Education\n1. 2019.3 - now\n\t* Netmath\n\t* University of Illinois (Urbana–Champaign)\n\t* Major in Mathematics\n2. 2014.3 - 2017.12\n\t* Bachelor of Computer Science\n\t* University of Wollongong, Australia\n\t* Major in Software Engineering\n\t* Main Achievement:\n\t\t1. The best final project prize (Human Research Management System base on Web)\n\t\t2. First Three Semester had: Undergraduate Excellence Scholarship\n3. 2013.3 - 2014.3\n\t* English for Tertiary Studies\n\t* University of Wollongong College, Australia\n\t* Main subjects: Academic English\n4. 2011.9 - 2013.3\n\t* Bachelor of Business Management\n\t* China University Of Mining And Technology\n\t* Average mark of 91\\% . Most of courses got High Distinction\n# Publications\n* Boyang Yan, Brian Yecies, Zhi Quan Zhou: Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages. IEEE/ACM 4th International Workshop on Metamorphic Testing (MET '19), in conjunction with the 41st International Conference on Software Engineering (ICSE '19), Montreal, Canada; 05/2019\n\n# Patents\n1. June 2, 2020\n\t* An automated text difference analysis and verification system/method\n\t* China Patent Office Application ID: 202010489931.8\n\n# Academy Congress and Conference\n1. May 26, 2019\n\t* Paper Presentation - Title: Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages\n\t* ICSE, Montreal, Canada\n\n2. August 11, 2017\n\t* showing my final year project about Human Resource Management System based on Web (whole swap card subsystem and database are finish independently)\n\t* IEEE Sections Congress (SC2017), Sydney, Australia\n\n# Certifications\n1. 2019\n\t* First Aid CPR AED\n\t* American Heart Association\n2. 2017\n\t* Amateur Radio Operator's certificate of proficiency (Standard)\n\t* The Wireless Institute of Australia (WIA)\n3. 2016\n\t* Ross a. Hull memorial Vhf-Uhf contest\n\t* The Wireless Institute of Australia (WIA)\n\t* Twelfth Place in Section A (Analog Modes, Best 7 Days) and Twelfth Place in Section C (Analog Modes, Best 2 Days)\n\n4. 2014\n\t* Amateur Radio Operator's certificate of proficiency (Foundation)\n\t* The Wireless Institute of Australia (WIA)\n5. 2010\n\t* The Second Place Prize Awarded, Tianjin School Sports Competition Award \"92\" National Games Tianjin\n\t* Tianjin Basketball Tryouts, China\n\t* High school men's Group B. Primary and Secondary (Vocational) School Basketball Games. Have got the second grading certificate and title\n\n\n\n\n\n","source":"about/index.md","raw":"---\ntitle: About Me\ndate: 2020-09-04 11:31:37\ncomments: false\n---\n# Personal Evaluation\nI see myself advancing with a strong ability and interesting in new technology\nand academic research.\nI successfully participated two international academic conferences,\none published paper and one patent. In the University study, I got undergraduate\nscholarships and the best prize for final project. The final project is related\nto swipe card system. My insteresting research area on computer graphic, softerware testing and machine learning.\n\n# Working Experience\n1. 2020.3 - now\n\t* Support Engineer\n\t* Microsoft, China\n\t* Azure Machine Learning CSS Team\n2. 2018.12 - 2020.3\n\t* Algorithm Engineer\n\t* Peng Chen Laboratory, China\n\t* Network Communication Research Center\n3. 2018.1 - 2018.11\n\t* Research Assistant (Computer Science)\n\t* University of Wollongong, Australia\n\t* Metamorphic Testing - Software Testing\n\n# Education\n1. 2019.3 - now\n\t* Netmath\n\t* University of Illinois (Urbana–Champaign)\n\t* Major in Mathematics\n2. 2014.3 - 2017.12\n\t* Bachelor of Computer Science\n\t* University of Wollongong, Australia\n\t* Major in Software Engineering\n\t* Main Achievement:\n\t\t1. The best final project prize (Human Research Management System base on Web)\n\t\t2. First Three Semester had: Undergraduate Excellence Scholarship\n3. 2013.3 - 2014.3\n\t* English for Tertiary Studies\n\t* University of Wollongong College, Australia\n\t* Main subjects: Academic English\n4. 2011.9 - 2013.3\n\t* Bachelor of Business Management\n\t* China University Of Mining And Technology\n\t* Average mark of 91\\% . Most of courses got High Distinction\n# Publications\n* Boyang Yan, Brian Yecies, Zhi Quan Zhou: Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages. IEEE/ACM 4th International Workshop on Metamorphic Testing (MET '19), in conjunction with the 41st International Conference on Software Engineering (ICSE '19), Montreal, Canada; 05/2019\n\n# Patents\n1. June 2, 2020\n\t* An automated text difference analysis and verification system/method\n\t* China Patent Office Application ID: 202010489931.8\n\n# Academy Congress and Conference\n1. May 26, 2019\n\t* Paper Presentation - Title: Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages\n\t* ICSE, Montreal, Canada\n\n2. August 11, 2017\n\t* showing my final year project about Human Resource Management System based on Web (whole swap card subsystem and database are finish independently)\n\t* IEEE Sections Congress (SC2017), Sydney, Australia\n\n# Certifications\n1. 2019\n\t* First Aid CPR AED\n\t* American Heart Association\n2. 2017\n\t* Amateur Radio Operator's certificate of proficiency (Standard)\n\t* The Wireless Institute of Australia (WIA)\n3. 2016\n\t* Ross a. Hull memorial Vhf-Uhf contest\n\t* The Wireless Institute of Australia (WIA)\n\t* Twelfth Place in Section A (Analog Modes, Best 7 Days) and Twelfth Place in Section C (Analog Modes, Best 2 Days)\n\n4. 2014\n\t* Amateur Radio Operator's certificate of proficiency (Foundation)\n\t* The Wireless Institute of Australia (WIA)\n5. 2010\n\t* The Second Place Prize Awarded, Tianjin School Sports Competition Award \"92\" National Games Tianjin\n\t* Tianjin Basketball Tryouts, China\n\t* High school men's Group B. Primary and Secondary (Vocational) School Basketball Games. Have got the second grading certificate and title\n\n\n\n\n\n","updated":"2020-09-10T10:20:00.274Z","path":"about/index.html","layout":"page","_id":"ckfyx1ail0000iiiy3mn6gh2f","content":"<h1 id=\"Personal-Evaluation\"><a href=\"#Personal-Evaluation\" class=\"headerlink\" title=\"Personal Evaluation\"></a>Personal Evaluation</h1><p>I see myself advancing with a strong ability and interesting in new technology<br>and academic research.<br>I successfully participated two international academic conferences,<br>one published paper and one patent. In the University study, I got undergraduate<br>scholarships and the best prize for final project. The final project is related<br>to swipe card system. My insteresting research area on computer graphic, softerware testing and machine learning.</p>\n<h1 id=\"Working-Experience\"><a href=\"#Working-Experience\" class=\"headerlink\" title=\"Working Experience\"></a>Working Experience</h1><ol>\n<li>2020.3 - now<ul>\n<li>Support Engineer</li>\n<li>Microsoft, China</li>\n<li>Azure Machine Learning CSS Team</li>\n</ul>\n</li>\n<li>2018.12 - 2020.3<ul>\n<li>Algorithm Engineer</li>\n<li>Peng Chen Laboratory, China</li>\n<li>Network Communication Research Center</li>\n</ul>\n</li>\n<li>2018.1 - 2018.11<ul>\n<li>Research Assistant (Computer Science)</li>\n<li>University of Wollongong, Australia</li>\n<li>Metamorphic Testing - Software Testing</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Education\"><a href=\"#Education\" class=\"headerlink\" title=\"Education\"></a>Education</h1><ol>\n<li>2019.3 - now<ul>\n<li>Netmath</li>\n<li>University of Illinois (Urbana–Champaign)</li>\n<li>Major in Mathematics</li>\n</ul>\n</li>\n<li>2014.3 - 2017.12<ul>\n<li>Bachelor of Computer Science</li>\n<li>University of Wollongong, Australia</li>\n<li>Major in Software Engineering</li>\n<li>Main Achievement:<ol>\n<li>The best final project prize (Human Research Management System base on Web)</li>\n<li>First Three Semester had: Undergraduate Excellence Scholarship</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>2013.3 - 2014.3<ul>\n<li>English for Tertiary Studies</li>\n<li>University of Wollongong College, Australia</li>\n<li>Main subjects: Academic English</li>\n</ul>\n</li>\n<li>2011.9 - 2013.3<ul>\n<li>Bachelor of Business Management</li>\n<li>China University Of Mining And Technology</li>\n<li>Average mark of 91% . Most of courses got High Distinction<h1 id=\"Publications\"><a href=\"#Publications\" class=\"headerlink\" title=\"Publications\"></a>Publications</h1></li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>Boyang Yan, Brian Yecies, Zhi Quan Zhou: Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages. IEEE/ACM 4th International Workshop on Metamorphic Testing (MET ‘19), in conjunction with the 41st International Conference on Software Engineering (ICSE ‘19), Montreal, Canada; 05/2019</li>\n</ul>\n<h1 id=\"Patents\"><a href=\"#Patents\" class=\"headerlink\" title=\"Patents\"></a>Patents</h1><ol>\n<li>June 2, 2020<ul>\n<li>An automated text difference analysis and verification system/method</li>\n<li>China Patent Office Application ID: 202010489931.8</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Academy-Congress-and-Conference\"><a href=\"#Academy-Congress-and-Conference\" class=\"headerlink\" title=\"Academy Congress and Conference\"></a>Academy Congress and Conference</h1><ol>\n<li><p>May 26, 2019</p>\n<ul>\n<li>Paper Presentation - Title: Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages</li>\n<li>ICSE, Montreal, Canada</li>\n</ul>\n</li>\n<li><p>August 11, 2017</p>\n<ul>\n<li>showing my final year project about Human Resource Management System based on Web (whole swap card subsystem and database are finish independently)</li>\n<li>IEEE Sections Congress (SC2017), Sydney, Australia</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Certifications\"><a href=\"#Certifications\" class=\"headerlink\" title=\"Certifications\"></a>Certifications</h1><ol>\n<li><p>2019</p>\n<ul>\n<li>First Aid CPR AED</li>\n<li>American Heart Association</li>\n</ul>\n</li>\n<li><p>2017</p>\n<ul>\n<li>Amateur Radio Operator’s certificate of proficiency (Standard)</li>\n<li>The Wireless Institute of Australia (WIA)</li>\n</ul>\n</li>\n<li><p>2016</p>\n<ul>\n<li>Ross a. Hull memorial Vhf-Uhf contest</li>\n<li>The Wireless Institute of Australia (WIA)</li>\n<li>Twelfth Place in Section A (Analog Modes, Best 7 Days) and Twelfth Place in Section C (Analog Modes, Best 2 Days)</li>\n</ul>\n</li>\n<li><p>2014</p>\n<ul>\n<li>Amateur Radio Operator’s certificate of proficiency (Foundation)</li>\n<li>The Wireless Institute of Australia (WIA)</li>\n</ul>\n</li>\n<li><p>2010</p>\n<ul>\n<li>The Second Place Prize Awarded, Tianjin School Sports Competition Award “92” National Games Tianjin</li>\n<li>Tianjin Basketball Tryouts, China</li>\n<li>High school men’s Group B. Primary and Secondary (Vocational) School Basketball Games. Have got the second grading certificate and title</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Personal-Evaluation\"><a href=\"#Personal-Evaluation\" class=\"headerlink\" title=\"Personal Evaluation\"></a>Personal Evaluation</h1><p>I see myself advancing with a strong ability and interesting in new technology<br>and academic research.<br>I successfully participated two international academic conferences,<br>one published paper and one patent. In the University study, I got undergraduate<br>scholarships and the best prize for final project. The final project is related<br>to swipe card system. My insteresting research area on computer graphic, softerware testing and machine learning.</p>\n<h1 id=\"Working-Experience\"><a href=\"#Working-Experience\" class=\"headerlink\" title=\"Working Experience\"></a>Working Experience</h1><ol>\n<li>2020.3 - now<ul>\n<li>Support Engineer</li>\n<li>Microsoft, China</li>\n<li>Azure Machine Learning CSS Team</li>\n</ul>\n</li>\n<li>2018.12 - 2020.3<ul>\n<li>Algorithm Engineer</li>\n<li>Peng Chen Laboratory, China</li>\n<li>Network Communication Research Center</li>\n</ul>\n</li>\n<li>2018.1 - 2018.11<ul>\n<li>Research Assistant (Computer Science)</li>\n<li>University of Wollongong, Australia</li>\n<li>Metamorphic Testing - Software Testing</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Education\"><a href=\"#Education\" class=\"headerlink\" title=\"Education\"></a>Education</h1><ol>\n<li>2019.3 - now<ul>\n<li>Netmath</li>\n<li>University of Illinois (Urbana–Champaign)</li>\n<li>Major in Mathematics</li>\n</ul>\n</li>\n<li>2014.3 - 2017.12<ul>\n<li>Bachelor of Computer Science</li>\n<li>University of Wollongong, Australia</li>\n<li>Major in Software Engineering</li>\n<li>Main Achievement:<ol>\n<li>The best final project prize (Human Research Management System base on Web)</li>\n<li>First Three Semester had: Undergraduate Excellence Scholarship</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>2013.3 - 2014.3<ul>\n<li>English for Tertiary Studies</li>\n<li>University of Wollongong College, Australia</li>\n<li>Main subjects: Academic English</li>\n</ul>\n</li>\n<li>2011.9 - 2013.3<ul>\n<li>Bachelor of Business Management</li>\n<li>China University Of Mining And Technology</li>\n<li>Average mark of 91% . Most of courses got High Distinction<h1 id=\"Publications\"><a href=\"#Publications\" class=\"headerlink\" title=\"Publications\"></a>Publications</h1></li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>Boyang Yan, Brian Yecies, Zhi Quan Zhou: Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages. IEEE/ACM 4th International Workshop on Metamorphic Testing (MET ‘19), in conjunction with the 41st International Conference on Software Engineering (ICSE ‘19), Montreal, Canada; 05/2019</li>\n</ul>\n<h1 id=\"Patents\"><a href=\"#Patents\" class=\"headerlink\" title=\"Patents\"></a>Patents</h1><ol>\n<li>June 2, 2020<ul>\n<li>An automated text difference analysis and verification system/method</li>\n<li>China Patent Office Application ID: 202010489931.8</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Academy-Congress-and-Conference\"><a href=\"#Academy-Congress-and-Conference\" class=\"headerlink\" title=\"Academy Congress and Conference\"></a>Academy Congress and Conference</h1><ol>\n<li><p>May 26, 2019</p>\n<ul>\n<li>Paper Presentation - Title: Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages</li>\n<li>ICSE, Montreal, Canada</li>\n</ul>\n</li>\n<li><p>August 11, 2017</p>\n<ul>\n<li>showing my final year project about Human Resource Management System based on Web (whole swap card subsystem and database are finish independently)</li>\n<li>IEEE Sections Congress (SC2017), Sydney, Australia</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Certifications\"><a href=\"#Certifications\" class=\"headerlink\" title=\"Certifications\"></a>Certifications</h1><ol>\n<li><p>2019</p>\n<ul>\n<li>First Aid CPR AED</li>\n<li>American Heart Association</li>\n</ul>\n</li>\n<li><p>2017</p>\n<ul>\n<li>Amateur Radio Operator’s certificate of proficiency (Standard)</li>\n<li>The Wireless Institute of Australia (WIA)</li>\n</ul>\n</li>\n<li><p>2016</p>\n<ul>\n<li>Ross a. Hull memorial Vhf-Uhf contest</li>\n<li>The Wireless Institute of Australia (WIA)</li>\n<li>Twelfth Place in Section A (Analog Modes, Best 7 Days) and Twelfth Place in Section C (Analog Modes, Best 2 Days)</li>\n</ul>\n</li>\n<li><p>2014</p>\n<ul>\n<li>Amateur Radio Operator’s certificate of proficiency (Foundation)</li>\n<li>The Wireless Institute of Australia (WIA)</li>\n</ul>\n</li>\n<li><p>2010</p>\n<ul>\n<li>The Second Place Prize Awarded, Tianjin School Sports Competition Award “92” National Games Tianjin</li>\n<li>Tianjin Basketball Tryouts, China</li>\n<li>High school men’s Group B. Primary and Secondary (Vocational) School Basketball Games. Have got the second grading certificate and title</li>\n</ul>\n</li>\n</ol>\n"},{"title":"categories","date":"2020-09-04T11:33:00.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2020-09-04 11:33:00\ntype: \"categories\"\ncomments: false\n---\n","updated":"2020-09-10T10:07:46.917Z","path":"categories/index.html","layout":"page","_id":"ckfyx1aiq0002iiiy5tsv5357","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"All tags","date":"2020-09-03T10:51:08.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: All tags\ndate: 2020-09-03 10:51:08\ntype: \"tags\"\ncomments: false\n---\n","updated":"2020-09-10T10:06:57.092Z","path":"tags/index.html","layout":"page","_id":"ckfyx1ais0006iiiydhfy37v2","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Azure Machine Learning Compute Instance Getting Started","date":"2020-09-17T15:47:54.000Z","_content":"# Introduction\nThis post document is a brief introduction about Azure Machine Learning Service Compute Instance(CI).\nCI can be as your development environment or training compute tartget.\n**TIPS:**\nHowever, if your specialty on Linux, I recommand you using DSVM ({% post_link DSVM %}) as your development environment. For training process, I recommand you using Azure Machine Learning training cluster(Compute cluster).\n\n# Managing a compute instance\n## From portal\nIn your workspace in Azure Machine Learning studio, select Compute, then select Compute Instance on the top.\n![compute instance](https://docs.microsoft.com/en-us/azure/machine-learning/media/concept-compute-instance/manage-compute-instance.png)\nYou can perform the following actions:\n+ Create a compute instance.\n+ Refresh the compute instances tab.\n+ Start, stop, and restart a compute instance. You do pay for the instance whenever it is running. Stop the compute instance when you are not using it to reduce cost. Stopping a compute instance deallocates it. Then start it again when you need it.\n+ Delete a compute instance.\n+ Filter the list of compute instanced to show only those you have created.\n\nFor each compute instance in your workspace that you can use, you can:\n\n+ Access Jupyter, JupyterLab, RStudio on the compute instance\n+ SSH into compute instance. SSH access is disabled by default but can be enabled at compute instance creation time. SSH access is through public/private key mechanism. The tab will give you details for SSH connection such as IP address, username, and port number.\n+ Get details about a specific compute instance such as IP address, and region.\n\n**TIPS:**\nRBAC allows you to control which users in the workspace can create, delete, start, stop, restart a compute instance. All users in the workspace contributor and owner role can create, delete, start, stop, and restart compute instances across the workspace. However, only the creator of a specific compute instance, or the user assigned if it was created on their behalf, is allowed to access Jupyter, JupyterLab, and RStudio on that compute instance. A compute instance is dedicated to a single user who has root access, and can terminal in through Jupyter/JupyterLab/RStudio. Compute instance will have single-user log in and all actions will use that user’s identity for RBAC and attribution of experiment runs. SSH access is controlled through public/private key mechanism.\n\nThese actions can be controlled by RBAC:\n+ Microsoft.MachineLearningServices/workspaces/computes/read\n+ Microsoft.MachineLearningServices/workspaces/computes/write\n+ Microsoft.MachineLearningServices/workspaces/computes/delete\n+ Microsoft.MachineLearningServices/workspaces/computes/start/action\n+ Microsoft.MachineLearningServices/workspaces/computes/stop/action\n+ Microsoft.MachineLearningServices/workspaces/computes/restart/action\n\nDetails please check official website [Managing CI](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance#managing-a-compute-instance)\n\n## Using Azure Machine Learning SDK\nAll of management CI methods can be found in ComputeInstance class. Details please check official link at the below.\n<a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance(class)?view=azure-ml-py\" target=\"_top\">Managing CI SDK</a>\n\n### Delete CI object methods\n\n<a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance(class)?view=azure-ml-py#delete-wait-for-completion-false--show-output-false-\" target=\"_top\">Official link</a>\n\nRemove the ComputeInstance object from its associated workspace.\n```python\ndelete(wait_for_completion=False, show_output=False)\n```\n#### Parameters\nwait_for_completion - default value: False\nshow_output - default value: False\n\n[Exceptions](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.exceptions.computetargetexception?view=azure-ml-py)\n\n#### Remarks\n\nIf this object was created through Azure ML, the corresponding cloud based objects will also be deleted. If this object was created externally and only attached to the workspace, it will raise exception and nothing will be changed.\n\n## REST API\nREST API also can be used to manage CIs, How to delete CIs, please, have a check the link at the below.\n[Delete CIs](https://docs.microsoft.com/en-us/rest/api/azureml/workspacesandcomputes/machinelearningcompute/delete)\n\n","source":"_posts/AMLci.md","raw":"---\ntitle: Azure Machine Learning Compute Instance Getting Started\ndate: 2020-09-17 15:47:54\ntags:\n - Azure\n - Compute instance\n - Azure Machine Learning\ncategories: Azure\n---\n# Introduction\nThis post document is a brief introduction about Azure Machine Learning Service Compute Instance(CI).\nCI can be as your development environment or training compute tartget.\n**TIPS:**\nHowever, if your specialty on Linux, I recommand you using DSVM ({% post_link DSVM %}) as your development environment. For training process, I recommand you using Azure Machine Learning training cluster(Compute cluster).\n\n# Managing a compute instance\n## From portal\nIn your workspace in Azure Machine Learning studio, select Compute, then select Compute Instance on the top.\n![compute instance](https://docs.microsoft.com/en-us/azure/machine-learning/media/concept-compute-instance/manage-compute-instance.png)\nYou can perform the following actions:\n+ Create a compute instance.\n+ Refresh the compute instances tab.\n+ Start, stop, and restart a compute instance. You do pay for the instance whenever it is running. Stop the compute instance when you are not using it to reduce cost. Stopping a compute instance deallocates it. Then start it again when you need it.\n+ Delete a compute instance.\n+ Filter the list of compute instanced to show only those you have created.\n\nFor each compute instance in your workspace that you can use, you can:\n\n+ Access Jupyter, JupyterLab, RStudio on the compute instance\n+ SSH into compute instance. SSH access is disabled by default but can be enabled at compute instance creation time. SSH access is through public/private key mechanism. The tab will give you details for SSH connection such as IP address, username, and port number.\n+ Get details about a specific compute instance such as IP address, and region.\n\n**TIPS:**\nRBAC allows you to control which users in the workspace can create, delete, start, stop, restart a compute instance. All users in the workspace contributor and owner role can create, delete, start, stop, and restart compute instances across the workspace. However, only the creator of a specific compute instance, or the user assigned if it was created on their behalf, is allowed to access Jupyter, JupyterLab, and RStudio on that compute instance. A compute instance is dedicated to a single user who has root access, and can terminal in through Jupyter/JupyterLab/RStudio. Compute instance will have single-user log in and all actions will use that user’s identity for RBAC and attribution of experiment runs. SSH access is controlled through public/private key mechanism.\n\nThese actions can be controlled by RBAC:\n+ Microsoft.MachineLearningServices/workspaces/computes/read\n+ Microsoft.MachineLearningServices/workspaces/computes/write\n+ Microsoft.MachineLearningServices/workspaces/computes/delete\n+ Microsoft.MachineLearningServices/workspaces/computes/start/action\n+ Microsoft.MachineLearningServices/workspaces/computes/stop/action\n+ Microsoft.MachineLearningServices/workspaces/computes/restart/action\n\nDetails please check official website [Managing CI](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance#managing-a-compute-instance)\n\n## Using Azure Machine Learning SDK\nAll of management CI methods can be found in ComputeInstance class. Details please check official link at the below.\n<a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance(class)?view=azure-ml-py\" target=\"_top\">Managing CI SDK</a>\n\n### Delete CI object methods\n\n<a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance(class)?view=azure-ml-py#delete-wait-for-completion-false--show-output-false-\" target=\"_top\">Official link</a>\n\nRemove the ComputeInstance object from its associated workspace.\n```python\ndelete(wait_for_completion=False, show_output=False)\n```\n#### Parameters\nwait_for_completion - default value: False\nshow_output - default value: False\n\n[Exceptions](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.exceptions.computetargetexception?view=azure-ml-py)\n\n#### Remarks\n\nIf this object was created through Azure ML, the corresponding cloud based objects will also be deleted. If this object was created externally and only attached to the workspace, it will raise exception and nothing will be changed.\n\n## REST API\nREST API also can be used to manage CIs, How to delete CIs, please, have a check the link at the below.\n[Delete CIs](https://docs.microsoft.com/en-us/rest/api/azureml/workspacesandcomputes/machinelearningcompute/delete)\n\n","slug":"AMLci","published":1,"updated":"2020-09-18T03:13:43.792Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aio0001iiiy08kbgek4","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is a brief introduction about Azure Machine Learning Service Compute Instance(CI).<br>CI can be as your development environment or training compute tartget.<br><strong>TIPS:</strong><br>However, if your specialty on Linux, I recommand you using DSVM (<a href=\"/2020/09/10/DSVM/\" title=\"Azure Data Science Virtual Machine Getting Started\">Azure Data Science Virtual Machine Getting Started</a>) as your development environment. For training process, I recommand you using Azure Machine Learning training cluster(Compute cluster).</p>\n<h1 id=\"Managing-a-compute-instance\"><a href=\"#Managing-a-compute-instance\" class=\"headerlink\" title=\"Managing a compute instance\"></a>Managing a compute instance</h1><h2 id=\"From-portal\"><a href=\"#From-portal\" class=\"headerlink\" title=\"From portal\"></a>From portal</h2><p>In your workspace in Azure Machine Learning studio, select Compute, then select Compute Instance on the top.<br><img src=\"https://docs.microsoft.com/en-us/azure/machine-learning/media/concept-compute-instance/manage-compute-instance.png\" alt=\"compute instance\"><br>You can perform the following actions:</p>\n<ul>\n<li>Create a compute instance.</li>\n<li>Refresh the compute instances tab.</li>\n<li>Start, stop, and restart a compute instance. You do pay for the instance whenever it is running. Stop the compute instance when you are not using it to reduce cost. Stopping a compute instance deallocates it. Then start it again when you need it.</li>\n<li>Delete a compute instance.</li>\n<li>Filter the list of compute instanced to show only those you have created.</li>\n</ul>\n<p>For each compute instance in your workspace that you can use, you can:</p>\n<ul>\n<li>Access Jupyter, JupyterLab, RStudio on the compute instance</li>\n<li>SSH into compute instance. SSH access is disabled by default but can be enabled at compute instance creation time. SSH access is through public/private key mechanism. The tab will give you details for SSH connection such as IP address, username, and port number.</li>\n<li>Get details about a specific compute instance such as IP address, and region.</li>\n</ul>\n<p><strong>TIPS:</strong><br>RBAC allows you to control which users in the workspace can create, delete, start, stop, restart a compute instance. All users in the workspace contributor and owner role can create, delete, start, stop, and restart compute instances across the workspace. However, only the creator of a specific compute instance, or the user assigned if it was created on their behalf, is allowed to access Jupyter, JupyterLab, and RStudio on that compute instance. A compute instance is dedicated to a single user who has root access, and can terminal in through Jupyter/JupyterLab/RStudio. Compute instance will have single-user log in and all actions will use that user’s identity for RBAC and attribution of experiment runs. SSH access is controlled through public/private key mechanism.</p>\n<p>These actions can be controlled by RBAC:</p>\n<ul>\n<li>Microsoft.MachineLearningServices/workspaces/computes/read</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/write</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/delete</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/start/action</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/stop/action</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/restart/action</li>\n</ul>\n<p>Details please check official website <a href=\"https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance#managing-a-compute-instance\">Managing CI</a></p>\n<h2 id=\"Using-Azure-Machine-Learning-SDK\"><a href=\"#Using-Azure-Machine-Learning-SDK\" class=\"headerlink\" title=\"Using Azure Machine Learning SDK\"></a>Using Azure Machine Learning SDK</h2><p>All of management CI methods can be found in ComputeInstance class. Details please check official link at the below.<br><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance(class)?view=azure-ml-py\" target=\"_top\">Managing CI SDK</a></p>\n<h3 id=\"Delete-CI-object-methods\"><a href=\"#Delete-CI-object-methods\" class=\"headerlink\" title=\"Delete CI object methods\"></a>Delete CI object methods</h3><p><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance(class)?view=azure-ml-py#delete-wait-for-completion-false--show-output-false-\" target=\"_top\">Official link</a></p>\n<p>Remove the ComputeInstance object from its associated workspace.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delete(wait_for_completion=<span class=\"literal\">False</span>, show_output=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h4 id=\"Parameters\"><a href=\"#Parameters\" class=\"headerlink\" title=\"Parameters\"></a>Parameters</h4><p>wait_for_completion - default value: False<br>show_output - default value: False</p>\n<p><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.exceptions.computetargetexception?view=azure-ml-py\">Exceptions</a></p>\n<h4 id=\"Remarks\"><a href=\"#Remarks\" class=\"headerlink\" title=\"Remarks\"></a>Remarks</h4><p>If this object was created through Azure ML, the corresponding cloud based objects will also be deleted. If this object was created externally and only attached to the workspace, it will raise exception and nothing will be changed.</p>\n<h2 id=\"REST-API\"><a href=\"#REST-API\" class=\"headerlink\" title=\"REST API\"></a>REST API</h2><p>REST API also can be used to manage CIs, How to delete CIs, please, have a check the link at the below.<br><a href=\"https://docs.microsoft.com/en-us/rest/api/azureml/workspacesandcomputes/machinelearningcompute/delete\">Delete CIs</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is a brief introduction about Azure Machine Learning Service Compute Instance(CI).<br>CI can be as your development environment or training compute tartget.<br><strong>TIPS:</strong><br>However, if your specialty on Linux, I recommand you using DSVM (<a href=\"/2020/09/10/DSVM/\" title=\"Azure Data Science Virtual Machine Getting Started\">Azure Data Science Virtual Machine Getting Started</a>) as your development environment. For training process, I recommand you using Azure Machine Learning training cluster(Compute cluster).</p>\n<h1 id=\"Managing-a-compute-instance\"><a href=\"#Managing-a-compute-instance\" class=\"headerlink\" title=\"Managing a compute instance\"></a>Managing a compute instance</h1><h2 id=\"From-portal\"><a href=\"#From-portal\" class=\"headerlink\" title=\"From portal\"></a>From portal</h2><p>In your workspace in Azure Machine Learning studio, select Compute, then select Compute Instance on the top.<br><img src=\"https://docs.microsoft.com/en-us/azure/machine-learning/media/concept-compute-instance/manage-compute-instance.png\" alt=\"compute instance\"><br>You can perform the following actions:</p>\n<ul>\n<li>Create a compute instance.</li>\n<li>Refresh the compute instances tab.</li>\n<li>Start, stop, and restart a compute instance. You do pay for the instance whenever it is running. Stop the compute instance when you are not using it to reduce cost. Stopping a compute instance deallocates it. Then start it again when you need it.</li>\n<li>Delete a compute instance.</li>\n<li>Filter the list of compute instanced to show only those you have created.</li>\n</ul>\n<p>For each compute instance in your workspace that you can use, you can:</p>\n<ul>\n<li>Access Jupyter, JupyterLab, RStudio on the compute instance</li>\n<li>SSH into compute instance. SSH access is disabled by default but can be enabled at compute instance creation time. SSH access is through public/private key mechanism. The tab will give you details for SSH connection such as IP address, username, and port number.</li>\n<li>Get details about a specific compute instance such as IP address, and region.</li>\n</ul>\n<p><strong>TIPS:</strong><br>RBAC allows you to control which users in the workspace can create, delete, start, stop, restart a compute instance. All users in the workspace contributor and owner role can create, delete, start, stop, and restart compute instances across the workspace. However, only the creator of a specific compute instance, or the user assigned if it was created on their behalf, is allowed to access Jupyter, JupyterLab, and RStudio on that compute instance. A compute instance is dedicated to a single user who has root access, and can terminal in through Jupyter/JupyterLab/RStudio. Compute instance will have single-user log in and all actions will use that user’s identity for RBAC and attribution of experiment runs. SSH access is controlled through public/private key mechanism.</p>\n<p>These actions can be controlled by RBAC:</p>\n<ul>\n<li>Microsoft.MachineLearningServices/workspaces/computes/read</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/write</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/delete</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/start/action</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/stop/action</li>\n<li>Microsoft.MachineLearningServices/workspaces/computes/restart/action</li>\n</ul>\n<p>Details please check official website <a href=\"https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance#managing-a-compute-instance\">Managing CI</a></p>\n<h2 id=\"Using-Azure-Machine-Learning-SDK\"><a href=\"#Using-Azure-Machine-Learning-SDK\" class=\"headerlink\" title=\"Using Azure Machine Learning SDK\"></a>Using Azure Machine Learning SDK</h2><p>All of management CI methods can be found in ComputeInstance class. Details please check official link at the below.<br><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance(class)?view=azure-ml-py\" target=\"_top\">Managing CI SDK</a></p>\n<h3 id=\"Delete-CI-object-methods\"><a href=\"#Delete-CI-object-methods\" class=\"headerlink\" title=\"Delete CI object methods\"></a>Delete CI object methods</h3><p><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance(class)?view=azure-ml-py#delete-wait-for-completion-false--show-output-false-\" target=\"_top\">Official link</a></p>\n<p>Remove the ComputeInstance object from its associated workspace.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delete(wait_for_completion=<span class=\"literal\">False</span>, show_output=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h4 id=\"Parameters\"><a href=\"#Parameters\" class=\"headerlink\" title=\"Parameters\"></a>Parameters</h4><p>wait_for_completion - default value: False<br>show_output - default value: False</p>\n<p><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.exceptions.computetargetexception?view=azure-ml-py\">Exceptions</a></p>\n<h4 id=\"Remarks\"><a href=\"#Remarks\" class=\"headerlink\" title=\"Remarks\"></a>Remarks</h4><p>If this object was created through Azure ML, the corresponding cloud based objects will also be deleted. If this object was created externally and only attached to the workspace, it will raise exception and nothing will be changed.</p>\n<h2 id=\"REST-API\"><a href=\"#REST-API\" class=\"headerlink\" title=\"REST API\"></a>REST API</h2><p>REST API also can be used to manage CIs, How to delete CIs, please, have a check the link at the below.<br><a href=\"https://docs.microsoft.com/en-us/rest/api/azureml/workspacesandcomputes/machinelearningcompute/delete\">Delete CIs</a></p>\n"},{"title":"Azure Machine Learning Workspace Authentication Troubleshooting Guide","date":"2020-09-25T10:27:08.000Z","_content":"Could you try using config.json file connect to your Azure ML Workspace first? The steps you can following at the below.\n\n1. Go to https://portal.azure.com/\n2. Download config.json\n3. [config.json](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601020176/AML%20Authentication/config_c4idqa.png)\n3. Story config.json to the same directory as your Python code.\n4. run python code at the below\n```python\nfrom azureml.core import Workspace\nws = Workspace.from_config()\nprint(\"Found workspace {} at location {}\".format(ws.name, ws.location))\n```\n \nIf using config.json file connect to your Azure ML Workspace does not work, please check your SDK version and update your SDK.\n\nCheck SDK version python code:\n```python\nimport azureml.core\n\nprint(azureml.core.VERSION)\n```\nUpdate SDK version - Upgrade a previous version, make sure you upgrade all the dependencies as well:\n```bash\npip install --upgrade --upgrade-strategy eager azureml-sdk\n```\nIf Interactive Authentication does not work, please using Azure CLI Authentication or Service Principal Authentication. Details at the below.\n\nhttps://notebooks.azure.com/azureml/projects/azureml-getting-started/html/how-to-use-azureml/manage-azureml-service/authentication-in-azureml/authentication-in-azure-ml.ipynb\n","source":"_posts/AMLworkspaceAuthentication.md","raw":"---\ntitle: Azure Machine Learning Workspace Authentication Troubleshooting Guide\ndate: 2020-09-25 10:27:08\ntags:\n - Azure\n - Machine Learning\ncategories: Azure\n---\nCould you try using config.json file connect to your Azure ML Workspace first? The steps you can following at the below.\n\n1. Go to https://portal.azure.com/\n2. Download config.json\n3. [config.json](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601020176/AML%20Authentication/config_c4idqa.png)\n3. Story config.json to the same directory as your Python code.\n4. run python code at the below\n```python\nfrom azureml.core import Workspace\nws = Workspace.from_config()\nprint(\"Found workspace {} at location {}\".format(ws.name, ws.location))\n```\n \nIf using config.json file connect to your Azure ML Workspace does not work, please check your SDK version and update your SDK.\n\nCheck SDK version python code:\n```python\nimport azureml.core\n\nprint(azureml.core.VERSION)\n```\nUpdate SDK version - Upgrade a previous version, make sure you upgrade all the dependencies as well:\n```bash\npip install --upgrade --upgrade-strategy eager azureml-sdk\n```\nIf Interactive Authentication does not work, please using Azure CLI Authentication or Service Principal Authentication. Details at the below.\n\nhttps://notebooks.azure.com/azureml/projects/azureml-getting-started/html/how-to-use-azureml/manage-azureml-service/authentication-in-azureml/authentication-in-azure-ml.ipynb\n","slug":"AMLworkspaceAuthentication","published":1,"updated":"2020-10-03T12:15:11.635Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aiq0003iiiy3ve66u8c","content":"<p>Could you try using config.json file connect to your Azure ML Workspace first? The steps you can following at the below.</p>\n<ol>\n<li>Go to <a href=\"https://portal.azure.com/\">https://portal.azure.com/</a></li>\n<li>Download config.json</li>\n<li><a href=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601020176/AML%20Authentication/config_c4idqa.png\">config.json</a></li>\n<li>Story config.json to the same directory as your Python code.</li>\n<li>run python code at the below<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> azureml.core <span class=\"keyword\">import</span> Workspace</span><br><span class=\"line\">ws = Workspace.from_config()</span><br><span class=\"line\">print(<span class=\"string\">&quot;Found workspace &#123;&#125; at location &#123;&#125;&quot;</span>.format(ws.name, ws.location))</span><br></pre></td></tr></table></figure>\n <br>If using config.json file connect to your Azure ML Workspace does not work, please check your SDK version and update your SDK.</li>\n</ol>\n<p>Check SDK version python code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> azureml.core</span><br><span class=\"line\"></span><br><span class=\"line\">print(azureml.core.VERSION)</span><br></pre></td></tr></table></figure>\n<p>Update SDK version - Upgrade a previous version, make sure you upgrade all the dependencies as well:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install --upgrade --upgrade-strategy eager azureml-sdk</span><br></pre></td></tr></table></figure>\n<p>If Interactive Authentication does not work, please using Azure CLI Authentication or Service Principal Authentication. Details at the below.</p>\n<p><a href=\"https://notebooks.azure.com/azureml/projects/azureml-getting-started/html/how-to-use-azureml/manage-azureml-service/authentication-in-azureml/authentication-in-azure-ml.ipynb\">https://notebooks.azure.com/azureml/projects/azureml-getting-started/html/how-to-use-azureml/manage-azureml-service/authentication-in-azureml/authentication-in-azure-ml.ipynb</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Could you try using config.json file connect to your Azure ML Workspace first? The steps you can following at the below.</p>\n<ol>\n<li>Go to <a href=\"https://portal.azure.com/\">https://portal.azure.com/</a></li>\n<li>Download config.json</li>\n<li><a href=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601020176/AML%20Authentication/config_c4idqa.png\">config.json</a></li>\n<li>Story config.json to the same directory as your Python code.</li>\n<li>run python code at the below<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> azureml.core <span class=\"keyword\">import</span> Workspace</span><br><span class=\"line\">ws = Workspace.from_config()</span><br><span class=\"line\">print(<span class=\"string\">&quot;Found workspace &#123;&#125; at location &#123;&#125;&quot;</span>.format(ws.name, ws.location))</span><br></pre></td></tr></table></figure>\n <br>If using config.json file connect to your Azure ML Workspace does not work, please check your SDK version and update your SDK.</li>\n</ol>\n<p>Check SDK version python code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> azureml.core</span><br><span class=\"line\"></span><br><span class=\"line\">print(azureml.core.VERSION)</span><br></pre></td></tr></table></figure>\n<p>Update SDK version - Upgrade a previous version, make sure you upgrade all the dependencies as well:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install --upgrade --upgrade-strategy eager azureml-sdk</span><br></pre></td></tr></table></figure>\n<p>If Interactive Authentication does not work, please using Azure CLI Authentication or Service Principal Authentication. Details at the below.</p>\n<p><a href=\"https://notebooks.azure.com/azureml/projects/azureml-getting-started/html/how-to-use-azureml/manage-azureml-service/authentication-in-azureml/authentication-in-azure-ml.ipynb\">https://notebooks.azure.com/azureml/projects/azureml-getting-started/html/how-to-use-azureml/manage-azureml-service/authentication-in-azureml/authentication-in-azure-ml.ipynb</a></p>\n"},{"title":"Azure Data Science Virtual Machine Getting Started","date":"2020-09-09T19:35:15.000Z","_content":"# Introduction\nAzure Data Science Virtual Machine(DSVM) is Azure Virtual Machine image, pre-installed, configured and tested with several popular tools that are data analytics, machine learning and AI training. DSVM will be your best option as your develop environment base on cloud. DSVM helps in flexible virtualization without the need for purchasing and maintenance of hardware. You will see the DSVM highlights at the below section. DSVM almost cover all of popular tools for data science. This post document will fouced on how to create DSVM step by step. Others post will introduce DSVM integrate tool one by one.\n![Overview DSVM Environment](https://azurecomcdn.azureedge.net/cvt-0b40b1bff318268e721d52838dc296062380fe208d10d95a79603c3d7b06e390/images/page/services/virtual-machines/data-science-virtual-machines/data-science-diagram.jpg)\n\n# DSVM compare with Azure Machine Learning Compute Instances(AML-CI)\nI personal recommend you using DSVM instead of AML-CI.\nA couple of reason list at the below.\n1. DSVM is fully managed by yourself. You have all the permissions, so you can do whatever you want.\n2. DSVM have Windows OS and Ubuntu OS avaliable, AML-CI only have Ubuntu avaliable. But, I tend to use Ubuntu.\n3. DSVM have RDP Access feature. AML-CI have NOT this feature.\n\n**Note:**\nRDP (Remote Desktop Protocol) is a network communications protocol developed by Microsoft, which allows users to remotely connect to another computer. It is an extension of the T.120 protocols that are standards of the ITU (International Telecommunications Union). RDP provides a graphical interface for connecting two computers. To use RDP, the computer from which the end user originates the request must be running RDP client software. The computer that is being accessed must be running RDP server software.\nRDP client software provided by Microsoft is called Remote Desktop Connection (it used to be called “Terminal Services Client” and you may occasionally see it referred to that way.) Many non-Microsoft RDP clients and servers are available as well, including the open source client rdesktop. rdesktop is a command-line client; there are graphical user interface clients built on top of rdesktop.\n\nThe copyright of this Note belong to ericom, original article and more details can be found on [ericom website](https://www.ericom.com/whatis/rdp/)\n\n# DSVM some highlights\n1. Anaconda Python\n2. Jupyter, JupyterLab, and JupyterHub\n3. Deep learning with TensorFlow and PyTorch\n4. Machine learning with xgboost, Vowpal Wabbit, and LightGBM\n5. Julia\n6. Azure SDKs and libraries\n7. Azure Machine Learning SDKs and sample notebooks\n8. R support\n9. Spark\n\nThis image is pre-configured with NVIDIA drivers, CUDA Toolkit, and cuDNN library for GPU workloads if using NC class VM SKUs.\n\n# How to create a DSVM\n1. You need to do is log into the Azure Management portal through https://portal.azure.com . You should have an active Azure subscription to use the port. If you don't have a subscription, you can sign up for a free trial account.\n2. After logging in, you have to click **Create a resource** at the first position in Azure Services Section.\n![Create a resource](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599791501/DSVM/step1_fnow1a.png)\n3. In the Marketplace bar, search **Data Science Virtual Machine for Linux (Ubuntu)**\n![search](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599791843/DSVM/step2_jcaj5l.png)\n4. Click **create**\n![create](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599792009/DSVM/step3_jgt3yj.png)\n5. Now, we are enter the really steps for create our DSVM. Here, you would find seven distinct tabs on the Top of the screen. They are \"Basics\", \"Disks\", \"Networking\", \"Management\", \"Advanced\", \"Tags\", as well as \"Review + create\". I will one by one, talk how to set in details.\n\n## \"Basics\" Tab configuration\n![Basics1](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793176/DSVM/basics1_jkurkn.png)\n![Basics2](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793176/DSVM/basics2_ejbakz.png)\n## \"Disks\" Tab configuration\n![Disks](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793541/DSVM/disks_c6shkk.png)\n\n## \"Networking\" Tab configuration\n![Networking](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793690/DSVM/networking_ov8781.png)\n## \"Management\" Tab configuration\n![management1](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793906/DSVM/management1_m5bysi.png)\n![management2](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793906/DSVM/management2_qeq9n2.png)\n## \"Advanced\" Tab configuration\n![advanced1](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794121/DSVM/advanced1_dqxgph.png)\n![advanced2](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794121/DSVM/advanced2_ajxdsy.png)\n\n## \"Tags\" Tab configuration\n![tags](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794279/DSVM/tags_aipkzh.png)\n## \"Review + create\" Tab configuration\nThis step will be your last step. This step will vaild all of your configations. If failed, below image will be show.\n![Validation Failed](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794725/DSVM/validationFailed_gqbe3k.png)\n![Validation Passed](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794999/DSVM/validationPassed_s91clt.png)\n\n","source":"_posts/DSVM.md","raw":"---\ntitle: Azure Data Science Virtual Machine Getting Started\ndate: 2020-09-09 19:35:15\ntags:\n - Azure\n - Virtual Machine\ncategories: Azure\n---\n# Introduction\nAzure Data Science Virtual Machine(DSVM) is Azure Virtual Machine image, pre-installed, configured and tested with several popular tools that are data analytics, machine learning and AI training. DSVM will be your best option as your develop environment base on cloud. DSVM helps in flexible virtualization without the need for purchasing and maintenance of hardware. You will see the DSVM highlights at the below section. DSVM almost cover all of popular tools for data science. This post document will fouced on how to create DSVM step by step. Others post will introduce DSVM integrate tool one by one.\n![Overview DSVM Environment](https://azurecomcdn.azureedge.net/cvt-0b40b1bff318268e721d52838dc296062380fe208d10d95a79603c3d7b06e390/images/page/services/virtual-machines/data-science-virtual-machines/data-science-diagram.jpg)\n\n# DSVM compare with Azure Machine Learning Compute Instances(AML-CI)\nI personal recommend you using DSVM instead of AML-CI.\nA couple of reason list at the below.\n1. DSVM is fully managed by yourself. You have all the permissions, so you can do whatever you want.\n2. DSVM have Windows OS and Ubuntu OS avaliable, AML-CI only have Ubuntu avaliable. But, I tend to use Ubuntu.\n3. DSVM have RDP Access feature. AML-CI have NOT this feature.\n\n**Note:**\nRDP (Remote Desktop Protocol) is a network communications protocol developed by Microsoft, which allows users to remotely connect to another computer. It is an extension of the T.120 protocols that are standards of the ITU (International Telecommunications Union). RDP provides a graphical interface for connecting two computers. To use RDP, the computer from which the end user originates the request must be running RDP client software. The computer that is being accessed must be running RDP server software.\nRDP client software provided by Microsoft is called Remote Desktop Connection (it used to be called “Terminal Services Client” and you may occasionally see it referred to that way.) Many non-Microsoft RDP clients and servers are available as well, including the open source client rdesktop. rdesktop is a command-line client; there are graphical user interface clients built on top of rdesktop.\n\nThe copyright of this Note belong to ericom, original article and more details can be found on [ericom website](https://www.ericom.com/whatis/rdp/)\n\n# DSVM some highlights\n1. Anaconda Python\n2. Jupyter, JupyterLab, and JupyterHub\n3. Deep learning with TensorFlow and PyTorch\n4. Machine learning with xgboost, Vowpal Wabbit, and LightGBM\n5. Julia\n6. Azure SDKs and libraries\n7. Azure Machine Learning SDKs and sample notebooks\n8. R support\n9. Spark\n\nThis image is pre-configured with NVIDIA drivers, CUDA Toolkit, and cuDNN library for GPU workloads if using NC class VM SKUs.\n\n# How to create a DSVM\n1. You need to do is log into the Azure Management portal through https://portal.azure.com . You should have an active Azure subscription to use the port. If you don't have a subscription, you can sign up for a free trial account.\n2. After logging in, you have to click **Create a resource** at the first position in Azure Services Section.\n![Create a resource](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599791501/DSVM/step1_fnow1a.png)\n3. In the Marketplace bar, search **Data Science Virtual Machine for Linux (Ubuntu)**\n![search](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599791843/DSVM/step2_jcaj5l.png)\n4. Click **create**\n![create](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599792009/DSVM/step3_jgt3yj.png)\n5. Now, we are enter the really steps for create our DSVM. Here, you would find seven distinct tabs on the Top of the screen. They are \"Basics\", \"Disks\", \"Networking\", \"Management\", \"Advanced\", \"Tags\", as well as \"Review + create\". I will one by one, talk how to set in details.\n\n## \"Basics\" Tab configuration\n![Basics1](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793176/DSVM/basics1_jkurkn.png)\n![Basics2](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793176/DSVM/basics2_ejbakz.png)\n## \"Disks\" Tab configuration\n![Disks](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793541/DSVM/disks_c6shkk.png)\n\n## \"Networking\" Tab configuration\n![Networking](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793690/DSVM/networking_ov8781.png)\n## \"Management\" Tab configuration\n![management1](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793906/DSVM/management1_m5bysi.png)\n![management2](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793906/DSVM/management2_qeq9n2.png)\n## \"Advanced\" Tab configuration\n![advanced1](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794121/DSVM/advanced1_dqxgph.png)\n![advanced2](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794121/DSVM/advanced2_ajxdsy.png)\n\n## \"Tags\" Tab configuration\n![tags](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794279/DSVM/tags_aipkzh.png)\n## \"Review + create\" Tab configuration\nThis step will be your last step. This step will vaild all of your configations. If failed, below image will be show.\n![Validation Failed](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794725/DSVM/validationFailed_gqbe3k.png)\n![Validation Passed](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794999/DSVM/validationPassed_s91clt.png)\n\n","slug":"DSVM","published":1,"updated":"2020-09-18T00:15:50.671Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1ais0007iiiy3lun02jm","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>Azure Data Science Virtual Machine(DSVM) is Azure Virtual Machine image, pre-installed, configured and tested with several popular tools that are data analytics, machine learning and AI training. DSVM will be your best option as your develop environment base on cloud. DSVM helps in flexible virtualization without the need for purchasing and maintenance of hardware. You will see the DSVM highlights at the below section. DSVM almost cover all of popular tools for data science. This post document will fouced on how to create DSVM step by step. Others post will introduce DSVM integrate tool one by one.<br><img src=\"https://azurecomcdn.azureedge.net/cvt-0b40b1bff318268e721d52838dc296062380fe208d10d95a79603c3d7b06e390/images/page/services/virtual-machines/data-science-virtual-machines/data-science-diagram.jpg\" alt=\"Overview DSVM Environment\"></p>\n<h1 id=\"DSVM-compare-with-Azure-Machine-Learning-Compute-Instances-AML-CI\"><a href=\"#DSVM-compare-with-Azure-Machine-Learning-Compute-Instances-AML-CI\" class=\"headerlink\" title=\"DSVM compare with Azure Machine Learning Compute Instances(AML-CI)\"></a>DSVM compare with Azure Machine Learning Compute Instances(AML-CI)</h1><p>I personal recommend you using DSVM instead of AML-CI.<br>A couple of reason list at the below.</p>\n<ol>\n<li>DSVM is fully managed by yourself. You have all the permissions, so you can do whatever you want.</li>\n<li>DSVM have Windows OS and Ubuntu OS avaliable, AML-CI only have Ubuntu avaliable. But, I tend to use Ubuntu.</li>\n<li>DSVM have RDP Access feature. AML-CI have NOT this feature.</li>\n</ol>\n<p><strong>Note:</strong><br>RDP (Remote Desktop Protocol) is a network communications protocol developed by Microsoft, which allows users to remotely connect to another computer. It is an extension of the T.120 protocols that are standards of the ITU (International Telecommunications Union). RDP provides a graphical interface for connecting two computers. To use RDP, the computer from which the end user originates the request must be running RDP client software. The computer that is being accessed must be running RDP server software.<br>RDP client software provided by Microsoft is called Remote Desktop Connection (it used to be called “Terminal Services Client” and you may occasionally see it referred to that way.) Many non-Microsoft RDP clients and servers are available as well, including the open source client rdesktop. rdesktop is a command-line client; there are graphical user interface clients built on top of rdesktop.</p>\n<p>The copyright of this Note belong to ericom, original article and more details can be found on <a href=\"https://www.ericom.com/whatis/rdp/\">ericom website</a></p>\n<h1 id=\"DSVM-some-highlights\"><a href=\"#DSVM-some-highlights\" class=\"headerlink\" title=\"DSVM some highlights\"></a>DSVM some highlights</h1><ol>\n<li>Anaconda Python</li>\n<li>Jupyter, JupyterLab, and JupyterHub</li>\n<li>Deep learning with TensorFlow and PyTorch</li>\n<li>Machine learning with xgboost, Vowpal Wabbit, and LightGBM</li>\n<li>Julia</li>\n<li>Azure SDKs and libraries</li>\n<li>Azure Machine Learning SDKs and sample notebooks</li>\n<li>R support</li>\n<li>Spark</li>\n</ol>\n<p>This image is pre-configured with NVIDIA drivers, CUDA Toolkit, and cuDNN library for GPU workloads if using NC class VM SKUs.</p>\n<h1 id=\"How-to-create-a-DSVM\"><a href=\"#How-to-create-a-DSVM\" class=\"headerlink\" title=\"How to create a DSVM\"></a>How to create a DSVM</h1><ol>\n<li>You need to do is log into the Azure Management portal through <a href=\"https://portal.azure.com/\">https://portal.azure.com</a> . You should have an active Azure subscription to use the port. If you don’t have a subscription, you can sign up for a free trial account.</li>\n<li>After logging in, you have to click <strong>Create a resource</strong> at the first position in Azure Services Section.<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599791501/DSVM/step1_fnow1a.png\" alt=\"Create a resource\"></li>\n<li>In the Marketplace bar, search <strong>Data Science Virtual Machine for Linux (Ubuntu)</strong><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599791843/DSVM/step2_jcaj5l.png\" alt=\"search\"></li>\n<li>Click <strong>create</strong><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599792009/DSVM/step3_jgt3yj.png\" alt=\"create\"></li>\n<li>Now, we are enter the really steps for create our DSVM. Here, you would find seven distinct tabs on the Top of the screen. They are “Basics”, “Disks”, “Networking”, “Management”, “Advanced”, “Tags”, as well as “Review + create”. I will one by one, talk how to set in details.</li>\n</ol>\n<h2 id=\"“Basics”-Tab-configuration\"><a href=\"#“Basics”-Tab-configuration\" class=\"headerlink\" title=\"“Basics” Tab configuration\"></a>“Basics” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793176/DSVM/basics1_jkurkn.png\" alt=\"Basics1\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793176/DSVM/basics2_ejbakz.png\" alt=\"Basics2\"></p>\n<h2 id=\"“Disks”-Tab-configuration\"><a href=\"#“Disks”-Tab-configuration\" class=\"headerlink\" title=\"“Disks” Tab configuration\"></a>“Disks” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793541/DSVM/disks_c6shkk.png\" alt=\"Disks\"></p>\n<h2 id=\"“Networking”-Tab-configuration\"><a href=\"#“Networking”-Tab-configuration\" class=\"headerlink\" title=\"“Networking” Tab configuration\"></a>“Networking” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793690/DSVM/networking_ov8781.png\" alt=\"Networking\"></p>\n<h2 id=\"“Management”-Tab-configuration\"><a href=\"#“Management”-Tab-configuration\" class=\"headerlink\" title=\"“Management” Tab configuration\"></a>“Management” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793906/DSVM/management1_m5bysi.png\" alt=\"management1\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793906/DSVM/management2_qeq9n2.png\" alt=\"management2\"></p>\n<h2 id=\"“Advanced”-Tab-configuration\"><a href=\"#“Advanced”-Tab-configuration\" class=\"headerlink\" title=\"“Advanced” Tab configuration\"></a>“Advanced” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794121/DSVM/advanced1_dqxgph.png\" alt=\"advanced1\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794121/DSVM/advanced2_ajxdsy.png\" alt=\"advanced2\"></p>\n<h2 id=\"“Tags”-Tab-configuration\"><a href=\"#“Tags”-Tab-configuration\" class=\"headerlink\" title=\"“Tags” Tab configuration\"></a>“Tags” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794279/DSVM/tags_aipkzh.png\" alt=\"tags\"></p>\n<h2 id=\"“Review-create”-Tab-configuration\"><a href=\"#“Review-create”-Tab-configuration\" class=\"headerlink\" title=\"“Review + create” Tab configuration\"></a>“Review + create” Tab configuration</h2><p>This step will be your last step. This step will vaild all of your configations. If failed, below image will be show.<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794725/DSVM/validationFailed_gqbe3k.png\" alt=\"Validation Failed\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794999/DSVM/validationPassed_s91clt.png\" alt=\"Validation Passed\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>Azure Data Science Virtual Machine(DSVM) is Azure Virtual Machine image, pre-installed, configured and tested with several popular tools that are data analytics, machine learning and AI training. DSVM will be your best option as your develop environment base on cloud. DSVM helps in flexible virtualization without the need for purchasing and maintenance of hardware. You will see the DSVM highlights at the below section. DSVM almost cover all of popular tools for data science. This post document will fouced on how to create DSVM step by step. Others post will introduce DSVM integrate tool one by one.<br><img src=\"https://azurecomcdn.azureedge.net/cvt-0b40b1bff318268e721d52838dc296062380fe208d10d95a79603c3d7b06e390/images/page/services/virtual-machines/data-science-virtual-machines/data-science-diagram.jpg\" alt=\"Overview DSVM Environment\"></p>\n<h1 id=\"DSVM-compare-with-Azure-Machine-Learning-Compute-Instances-AML-CI\"><a href=\"#DSVM-compare-with-Azure-Machine-Learning-Compute-Instances-AML-CI\" class=\"headerlink\" title=\"DSVM compare with Azure Machine Learning Compute Instances(AML-CI)\"></a>DSVM compare with Azure Machine Learning Compute Instances(AML-CI)</h1><p>I personal recommend you using DSVM instead of AML-CI.<br>A couple of reason list at the below.</p>\n<ol>\n<li>DSVM is fully managed by yourself. You have all the permissions, so you can do whatever you want.</li>\n<li>DSVM have Windows OS and Ubuntu OS avaliable, AML-CI only have Ubuntu avaliable. But, I tend to use Ubuntu.</li>\n<li>DSVM have RDP Access feature. AML-CI have NOT this feature.</li>\n</ol>\n<p><strong>Note:</strong><br>RDP (Remote Desktop Protocol) is a network communications protocol developed by Microsoft, which allows users to remotely connect to another computer. It is an extension of the T.120 protocols that are standards of the ITU (International Telecommunications Union). RDP provides a graphical interface for connecting two computers. To use RDP, the computer from which the end user originates the request must be running RDP client software. The computer that is being accessed must be running RDP server software.<br>RDP client software provided by Microsoft is called Remote Desktop Connection (it used to be called “Terminal Services Client” and you may occasionally see it referred to that way.) Many non-Microsoft RDP clients and servers are available as well, including the open source client rdesktop. rdesktop is a command-line client; there are graphical user interface clients built on top of rdesktop.</p>\n<p>The copyright of this Note belong to ericom, original article and more details can be found on <a href=\"https://www.ericom.com/whatis/rdp/\">ericom website</a></p>\n<h1 id=\"DSVM-some-highlights\"><a href=\"#DSVM-some-highlights\" class=\"headerlink\" title=\"DSVM some highlights\"></a>DSVM some highlights</h1><ol>\n<li>Anaconda Python</li>\n<li>Jupyter, JupyterLab, and JupyterHub</li>\n<li>Deep learning with TensorFlow and PyTorch</li>\n<li>Machine learning with xgboost, Vowpal Wabbit, and LightGBM</li>\n<li>Julia</li>\n<li>Azure SDKs and libraries</li>\n<li>Azure Machine Learning SDKs and sample notebooks</li>\n<li>R support</li>\n<li>Spark</li>\n</ol>\n<p>This image is pre-configured with NVIDIA drivers, CUDA Toolkit, and cuDNN library for GPU workloads if using NC class VM SKUs.</p>\n<h1 id=\"How-to-create-a-DSVM\"><a href=\"#How-to-create-a-DSVM\" class=\"headerlink\" title=\"How to create a DSVM\"></a>How to create a DSVM</h1><ol>\n<li>You need to do is log into the Azure Management portal through <a href=\"https://portal.azure.com/\">https://portal.azure.com</a> . You should have an active Azure subscription to use the port. If you don’t have a subscription, you can sign up for a free trial account.</li>\n<li>After logging in, you have to click <strong>Create a resource</strong> at the first position in Azure Services Section.<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599791501/DSVM/step1_fnow1a.png\" alt=\"Create a resource\"></li>\n<li>In the Marketplace bar, search <strong>Data Science Virtual Machine for Linux (Ubuntu)</strong><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599791843/DSVM/step2_jcaj5l.png\" alt=\"search\"></li>\n<li>Click <strong>create</strong><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599792009/DSVM/step3_jgt3yj.png\" alt=\"create\"></li>\n<li>Now, we are enter the really steps for create our DSVM. Here, you would find seven distinct tabs on the Top of the screen. They are “Basics”, “Disks”, “Networking”, “Management”, “Advanced”, “Tags”, as well as “Review + create”. I will one by one, talk how to set in details.</li>\n</ol>\n<h2 id=\"“Basics”-Tab-configuration\"><a href=\"#“Basics”-Tab-configuration\" class=\"headerlink\" title=\"“Basics” Tab configuration\"></a>“Basics” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793176/DSVM/basics1_jkurkn.png\" alt=\"Basics1\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793176/DSVM/basics2_ejbakz.png\" alt=\"Basics2\"></p>\n<h2 id=\"“Disks”-Tab-configuration\"><a href=\"#“Disks”-Tab-configuration\" class=\"headerlink\" title=\"“Disks” Tab configuration\"></a>“Disks” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793541/DSVM/disks_c6shkk.png\" alt=\"Disks\"></p>\n<h2 id=\"“Networking”-Tab-configuration\"><a href=\"#“Networking”-Tab-configuration\" class=\"headerlink\" title=\"“Networking” Tab configuration\"></a>“Networking” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793690/DSVM/networking_ov8781.png\" alt=\"Networking\"></p>\n<h2 id=\"“Management”-Tab-configuration\"><a href=\"#“Management”-Tab-configuration\" class=\"headerlink\" title=\"“Management” Tab configuration\"></a>“Management” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793906/DSVM/management1_m5bysi.png\" alt=\"management1\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599793906/DSVM/management2_qeq9n2.png\" alt=\"management2\"></p>\n<h2 id=\"“Advanced”-Tab-configuration\"><a href=\"#“Advanced”-Tab-configuration\" class=\"headerlink\" title=\"“Advanced” Tab configuration\"></a>“Advanced” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794121/DSVM/advanced1_dqxgph.png\" alt=\"advanced1\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794121/DSVM/advanced2_ajxdsy.png\" alt=\"advanced2\"></p>\n<h2 id=\"“Tags”-Tab-configuration\"><a href=\"#“Tags”-Tab-configuration\" class=\"headerlink\" title=\"“Tags” Tab configuration\"></a>“Tags” Tab configuration</h2><p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794279/DSVM/tags_aipkzh.png\" alt=\"tags\"></p>\n<h2 id=\"“Review-create”-Tab-configuration\"><a href=\"#“Review-create”-Tab-configuration\" class=\"headerlink\" title=\"“Review + create” Tab configuration\"></a>“Review + create” Tab configuration</h2><p>This step will be your last step. This step will vaild all of your configations. If failed, below image will be show.<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794725/DSVM/validationFailed_gqbe3k.png\" alt=\"Validation Failed\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599794999/DSVM/validationPassed_s91clt.png\" alt=\"Validation Passed\"></p>\n"},{"title":"Extented Image Training Set Tips","subtitle":"Make Machine Learning model Robustness","date":"2020-09-07T17:41:36.000Z","_content":"# Introduction\nRegardless of the algorithm and framework used to train the neural network, the amount of image data is always an important prerequisite for determining the quality of the training model. Data expansion is a common method for training models, which is very important for the robustness and accuracy of the model. This post document will use OpenCV to show some of tips for how we can extented image training set.\n\n# Random cropping of images\n\n```python\nimport cv2\nimport random\n\nimg = cv2.imread(\"lena.jpg\")\nwidth, height, depth = img.shape\n\nimg_width_box = width * 0.2\nimg_width_box = height * 0.2\n\nfor _ in range(9):\n\tstart_pointX = int(random.uniform(0, img_width_box))\n\tstart_pointY = int(random.uniform(0, img_height_box))\n\t\n\tcopyImg = img[start_pointX:200, start_pointY:200]\n\n\tcv2.imshow (\"test\", copyImg)\n\tcv2.waitKey(0)\n\n```\n","source":"_posts/ExtentedImageTrainingSet.md","raw":"---\ntitle: Extented Image Training Set Tips\nsubtitle: Make Machine Learning model Robustness\ndate: 2020-09-07 17:41:36\ntags:\n - Machine Learning\n - Extented Image Training Set\n - OpenCV\ncategories: Machine Learning\n---\n# Introduction\nRegardless of the algorithm and framework used to train the neural network, the amount of image data is always an important prerequisite for determining the quality of the training model. Data expansion is a common method for training models, which is very important for the robustness and accuracy of the model. This post document will use OpenCV to show some of tips for how we can extented image training set.\n\n# Random cropping of images\n\n```python\nimport cv2\nimport random\n\nimg = cv2.imread(\"lena.jpg\")\nwidth, height, depth = img.shape\n\nimg_width_box = width * 0.2\nimg_width_box = height * 0.2\n\nfor _ in range(9):\n\tstart_pointX = int(random.uniform(0, img_width_box))\n\tstart_pointY = int(random.uniform(0, img_height_box))\n\t\n\tcopyImg = img[start_pointX:200, start_pointY:200]\n\n\tcv2.imshow (\"test\", copyImg)\n\tcv2.waitKey(0)\n\n```\n","slug":"ExtentedImageTrainingSet","published":1,"updated":"2020-09-08T07:38:06.374Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1ait0008iiiy551egwrt","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>Regardless of the algorithm and framework used to train the neural network, the amount of image data is always an important prerequisite for determining the quality of the training model. Data expansion is a common method for training models, which is very important for the robustness and accuracy of the model. This post document will use OpenCV to show some of tips for how we can extented image training set.</p>\n<h1 id=\"Random-cropping-of-images\"><a href=\"#Random-cropping-of-images\" class=\"headerlink\" title=\"Random cropping of images\"></a>Random cropping of images</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">&quot;lena.jpg&quot;</span>)</span><br><span class=\"line\">width, height, depth = img.shape</span><br><span class=\"line\"></span><br><span class=\"line\">img_width_box = width * <span class=\"number\">0.2</span></span><br><span class=\"line\">img_width_box = height * <span class=\"number\">0.2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(<span class=\"number\">9</span>):</span><br><span class=\"line\">    start_pointX = int(random.uniform(<span class=\"number\">0</span>, img_width_box))</span><br><span class=\"line\">    start_pointY = int(random.uniform(<span class=\"number\">0</span>, img_height_box))</span><br><span class=\"line\">    </span><br><span class=\"line\">    copyImg = img[start_pointX:<span class=\"number\">200</span>, start_pointY:<span class=\"number\">200</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    cv2.imshow (<span class=\"string\">&quot;test&quot;</span>, copyImg)</span><br><span class=\"line\">    cv2.waitKey(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>Regardless of the algorithm and framework used to train the neural network, the amount of image data is always an important prerequisite for determining the quality of the training model. Data expansion is a common method for training models, which is very important for the robustness and accuracy of the model. This post document will use OpenCV to show some of tips for how we can extented image training set.</p>\n<h1 id=\"Random-cropping-of-images\"><a href=\"#Random-cropping-of-images\" class=\"headerlink\" title=\"Random cropping of images\"></a>Random cropping of images</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">&quot;lena.jpg&quot;</span>)</span><br><span class=\"line\">width, height, depth = img.shape</span><br><span class=\"line\"></span><br><span class=\"line\">img_width_box = width * <span class=\"number\">0.2</span></span><br><span class=\"line\">img_width_box = height * <span class=\"number\">0.2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> range(<span class=\"number\">9</span>):</span><br><span class=\"line\">    start_pointX = int(random.uniform(<span class=\"number\">0</span>, img_width_box))</span><br><span class=\"line\">    start_pointY = int(random.uniform(<span class=\"number\">0</span>, img_height_box))</span><br><span class=\"line\">    </span><br><span class=\"line\">    copyImg = img[start_pointX:<span class=\"number\">200</span>, start_pointY:<span class=\"number\">200</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    cv2.imshow (<span class=\"string\">&quot;test&quot;</span>, copyImg)</span><br><span class=\"line\">    cv2.waitKey(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n"},{"title":"Guide to File Formats for Machine Learning","subtitle":"Columnar, Training, Inferencing, and the Feature Store","date":"2020-09-21T16:28:25.000Z","categoties":"machine Learning","_content":"# Introduction\nThis post document is a guide to the popular file formats used in open source frameworks for machine learning in Python, including TensorFlow/Keras, PyTorch, Scikit-Learn, and PySpark. We will also describe how a Feature Store can make the Data Scientist’s life easier by generating training/test data in a file format of choice on a file system of choice. This guide is base on [Jim Dowling's blog](https://towardsdatascience.com/guide-to-file-formats-for-machine-learning-columnar-training-inferencing-and-the-feature-store-2e0c3d18d4f9).\n\nA file format defines the structure and encoding of the data stored in it and it is typically identified by its file extension — for example, a filename ending in .txt indicates the file is a text file. However, even though files are used to store much of the world’s data, most of that data is not in a format that can be used directly to train ML models.\n\nThis post is mostly concerned with file formats for structured data and we will discuss the easy creation of training data in popular file formats for ML, such as .tfrecords, .csv, .npy, and .petastorm, as well as the file formats used to store models, such as .pb and .pkl . \n\n![Overview](https://miro.medium.com/max/700/0*EswBCD4bwdpoHn6S.png)\n\n# Data sources\nMachine learning frameworks want to consume training data as a sequence of samples, so file formats for training ML models should have easily consumable layouts with no impedance mismatch with the storage platform or the language used to read/write the files. Additionally, distributed training (training ML models on many GPUs at the same time to make training go faster) requires files to be splittable and accessible over a distributed file system or object store, so that different GPUs can read different shards (partitions) of the data in parallel from different servers.\n","source":"_posts/MachineLearningFileFormats.md","raw":"---\ntitle: Guide to File Formats for Machine Learning\nsubtitle: Columnar, Training, Inferencing, and the Feature Store\ndate: 2020-09-21 16:28:25\ntags:\n - Machine Learning\n - machine Learning File Formats\ncategoties: machine Learning\n---\n# Introduction\nThis post document is a guide to the popular file formats used in open source frameworks for machine learning in Python, including TensorFlow/Keras, PyTorch, Scikit-Learn, and PySpark. We will also describe how a Feature Store can make the Data Scientist’s life easier by generating training/test data in a file format of choice on a file system of choice. This guide is base on [Jim Dowling's blog](https://towardsdatascience.com/guide-to-file-formats-for-machine-learning-columnar-training-inferencing-and-the-feature-store-2e0c3d18d4f9).\n\nA file format defines the structure and encoding of the data stored in it and it is typically identified by its file extension — for example, a filename ending in .txt indicates the file is a text file. However, even though files are used to store much of the world’s data, most of that data is not in a format that can be used directly to train ML models.\n\nThis post is mostly concerned with file formats for structured data and we will discuss the easy creation of training data in popular file formats for ML, such as .tfrecords, .csv, .npy, and .petastorm, as well as the file formats used to store models, such as .pb and .pkl . \n\n![Overview](https://miro.medium.com/max/700/0*EswBCD4bwdpoHn6S.png)\n\n# Data sources\nMachine learning frameworks want to consume training data as a sequence of samples, so file formats for training ML models should have easily consumable layouts with no impedance mismatch with the storage platform or the language used to read/write the files. Additionally, distributed training (training ML models on many GPUs at the same time to make training go faster) requires files to be splittable and accessible over a distributed file system or object store, so that different GPUs can read different shards (partitions) of the data in parallel from different servers.\n","slug":"MachineLearningFileFormats","published":1,"updated":"2020-09-22T08:14:26.142Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aiu0009iiiy7max3bkm","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is a guide to the popular file formats used in open source frameworks for machine learning in Python, including TensorFlow/Keras, PyTorch, Scikit-Learn, and PySpark. We will also describe how a Feature Store can make the Data Scientist’s life easier by generating training/test data in a file format of choice on a file system of choice. This guide is base on <a href=\"https://towardsdatascience.com/guide-to-file-formats-for-machine-learning-columnar-training-inferencing-and-the-feature-store-2e0c3d18d4f9\">Jim Dowling’s blog</a>.</p>\n<p>A file format defines the structure and encoding of the data stored in it and it is typically identified by its file extension — for example, a filename ending in .txt indicates the file is a text file. However, even though files are used to store much of the world’s data, most of that data is not in a format that can be used directly to train ML models.</p>\n<p>This post is mostly concerned with file formats for structured data and we will discuss the easy creation of training data in popular file formats for ML, such as .tfrecords, .csv, .npy, and .petastorm, as well as the file formats used to store models, such as .pb and .pkl . </p>\n<p><img src=\"https://miro.medium.com/max/700/0*EswBCD4bwdpoHn6S.png\" alt=\"Overview\"></p>\n<h1 id=\"Data-sources\"><a href=\"#Data-sources\" class=\"headerlink\" title=\"Data sources\"></a>Data sources</h1><p>Machine learning frameworks want to consume training data as a sequence of samples, so file formats for training ML models should have easily consumable layouts with no impedance mismatch with the storage platform or the language used to read/write the files. Additionally, distributed training (training ML models on many GPUs at the same time to make training go faster) requires files to be splittable and accessible over a distributed file system or object store, so that different GPUs can read different shards (partitions) of the data in parallel from different servers.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is a guide to the popular file formats used in open source frameworks for machine learning in Python, including TensorFlow/Keras, PyTorch, Scikit-Learn, and PySpark. We will also describe how a Feature Store can make the Data Scientist’s life easier by generating training/test data in a file format of choice on a file system of choice. This guide is base on <a href=\"https://towardsdatascience.com/guide-to-file-formats-for-machine-learning-columnar-training-inferencing-and-the-feature-store-2e0c3d18d4f9\">Jim Dowling’s blog</a>.</p>\n<p>A file format defines the structure and encoding of the data stored in it and it is typically identified by its file extension — for example, a filename ending in .txt indicates the file is a text file. However, even though files are used to store much of the world’s data, most of that data is not in a format that can be used directly to train ML models.</p>\n<p>This post is mostly concerned with file formats for structured data and we will discuss the easy creation of training data in popular file formats for ML, such as .tfrecords, .csv, .npy, and .petastorm, as well as the file formats used to store models, such as .pb and .pkl . </p>\n<p><img src=\"https://miro.medium.com/max/700/0*EswBCD4bwdpoHn6S.png\" alt=\"Overview\"></p>\n<h1 id=\"Data-sources\"><a href=\"#Data-sources\" class=\"headerlink\" title=\"Data sources\"></a>Data sources</h1><p>Machine learning frameworks want to consume training data as a sequence of samples, so file formats for training ML models should have easily consumable layouts with no impedance mismatch with the storage platform or the language used to read/write the files. Additionally, distributed training (training ML models on many GPUs at the same time to make training go faster) requires files to be splittable and accessible over a distributed file system or object store, so that different GPUs can read different shards (partitions) of the data in parallel from different servers.</p>\n"},{"title":"Azure Raise Support Ticket/Case and Troubleshooting Guide","date":"2020-10-02T20:19:07.000Z","_content":"# Introduction\nWhen you use the Azure platform, you can open a case/ticket at any time when you encounter problems or have questions.\n\n# The steps for raise a new case/ticket\n1. Go to [portal](https://portal.azure.com/).\n2. Click question mark. ![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642169/raiseCaseAzure/questionMark_lmcxby.png)\n3. Click \"Help+support\"\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642435/raiseCaseAzure/help_support_hkfrey.png)\n4. Click + New support request\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642617/raiseCaseAzure/newSupportRequest_frt0zt.png)\n5. You can open a Technical support request. There is an example.\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643095/raiseCaseAzure/1_tjkamt.png)\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643175/raiseCaseAzure/2_ymbzj0.png)\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643279/raiseCaseAzure/3_klrqrf.png)\n\n# Troubleshooting\n## Permission Issue\nIf you face the error MSG at the below.\n**You don't have permission to create a support request\nTo get permission, ask your subscription administrator or owner to assign you ‘Support Request Contributor’ role for the selected subscription. Learn more about role assignments in the portal.**\n\nYou need contact your subscription administrator or owner to assign the \"support request provider\" role to the subscription you are currently in used. After, you can raise support ticket.\n","source":"_posts/azureRaiseCase.md","raw":"---\ntitle: Azure Raise Support Ticket/Case and Troubleshooting Guide\ndate: 2020-10-02 20:19:07\ntags:\n - Azure\ncategories: Azure\n---\n# Introduction\nWhen you use the Azure platform, you can open a case/ticket at any time when you encounter problems or have questions.\n\n# The steps for raise a new case/ticket\n1. Go to [portal](https://portal.azure.com/).\n2. Click question mark. ![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642169/raiseCaseAzure/questionMark_lmcxby.png)\n3. Click \"Help+support\"\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642435/raiseCaseAzure/help_support_hkfrey.png)\n4. Click + New support request\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642617/raiseCaseAzure/newSupportRequest_frt0zt.png)\n5. You can open a Technical support request. There is an example.\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643095/raiseCaseAzure/1_tjkamt.png)\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643175/raiseCaseAzure/2_ymbzj0.png)\n![](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643279/raiseCaseAzure/3_klrqrf.png)\n\n# Troubleshooting\n## Permission Issue\nIf you face the error MSG at the below.\n**You don't have permission to create a support request\nTo get permission, ask your subscription administrator or owner to assign you ‘Support Request Contributor’ role for the selected subscription. Learn more about role assignments in the portal.**\n\nYou need contact your subscription administrator or owner to assign the \"support request provider\" role to the subscription you are currently in used. After, you can raise support ticket.\n","slug":"azureRaiseCase","published":1,"updated":"2020-10-02T13:07:48.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aiv000ciiiyhmjp9k94","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>When you use the Azure platform, you can open a case/ticket at any time when you encounter problems or have questions.</p>\n<h1 id=\"The-steps-for-raise-a-new-case-ticket\"><a href=\"#The-steps-for-raise-a-new-case-ticket\" class=\"headerlink\" title=\"The steps for raise a new case/ticket\"></a>The steps for raise a new case/ticket</h1><ol>\n<li>Go to <a href=\"https://portal.azure.com/\">portal</a>.</li>\n<li>Click question mark. <img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642169/raiseCaseAzure/questionMark_lmcxby.png\"></li>\n<li>Click “Help+support”<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642435/raiseCaseAzure/help_support_hkfrey.png\"></li>\n<li>Click + New support request<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642617/raiseCaseAzure/newSupportRequest_frt0zt.png\"></li>\n<li>You can open a Technical support request. There is an example.<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643095/raiseCaseAzure/1_tjkamt.png\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643175/raiseCaseAzure/2_ymbzj0.png\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643279/raiseCaseAzure/3_klrqrf.png\"></li>\n</ol>\n<h1 id=\"Troubleshooting\"><a href=\"#Troubleshooting\" class=\"headerlink\" title=\"Troubleshooting\"></a>Troubleshooting</h1><h2 id=\"Permission-Issue\"><a href=\"#Permission-Issue\" class=\"headerlink\" title=\"Permission Issue\"></a>Permission Issue</h2><p>If you face the error MSG at the below.<br><strong>You don’t have permission to create a support request<br>To get permission, ask your subscription administrator or owner to assign you ‘Support Request Contributor’ role for the selected subscription. Learn more about role assignments in the portal.</strong></p>\n<p>You need contact your subscription administrator or owner to assign the “support request provider” role to the subscription you are currently in used. After, you can raise support ticket.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>When you use the Azure platform, you can open a case/ticket at any time when you encounter problems or have questions.</p>\n<h1 id=\"The-steps-for-raise-a-new-case-ticket\"><a href=\"#The-steps-for-raise-a-new-case-ticket\" class=\"headerlink\" title=\"The steps for raise a new case/ticket\"></a>The steps for raise a new case/ticket</h1><ol>\n<li>Go to <a href=\"https://portal.azure.com/\">portal</a>.</li>\n<li>Click question mark. <img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642169/raiseCaseAzure/questionMark_lmcxby.png\"></li>\n<li>Click “Help+support”<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642435/raiseCaseAzure/help_support_hkfrey.png\"></li>\n<li>Click + New support request<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601642617/raiseCaseAzure/newSupportRequest_frt0zt.png\"></li>\n<li>You can open a Technical support request. There is an example.<br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643095/raiseCaseAzure/1_tjkamt.png\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643175/raiseCaseAzure/2_ymbzj0.png\"><br><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1601643279/raiseCaseAzure/3_klrqrf.png\"></li>\n</ol>\n<h1 id=\"Troubleshooting\"><a href=\"#Troubleshooting\" class=\"headerlink\" title=\"Troubleshooting\"></a>Troubleshooting</h1><h2 id=\"Permission-Issue\"><a href=\"#Permission-Issue\" class=\"headerlink\" title=\"Permission Issue\"></a>Permission Issue</h2><p>If you face the error MSG at the below.<br><strong>You don’t have permission to create a support request<br>To get permission, ask your subscription administrator or owner to assign you ‘Support Request Contributor’ role for the selected subscription. Learn more about role assignments in the portal.</strong></p>\n<p>You need contact your subscription administrator or owner to assign the “support request provider” role to the subscription you are currently in used. After, you can raise support ticket.</p>\n"},{"title":"Getting started with Python and R environments using Conda","date":"2020-09-08T13:12:51.000Z","_content":"# Introduction\nThis post document is about using Conda to management Python and R language packages (libraries/dependencies), as well as virtual environment. Conda is an open source package management system and environment management system. Conda can quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language. Conda as a package manager helps you find and install packages. If you need a package that requires a different version of Python, you do not need to switch to a different environment manager, because conda is also an environment manager. With just a few commands, you can set up a totally separate environment to run that different version of Python, while continuing to run your usual version of Python in your normal environment.\n\nAnaconda is a distribution of conda. It is a data science platform that comes with a lot of packages.Unlike Anaconda, Miniconda doesn’t come with any installed packages by default. For this tutorial, I am using miniconda. If you have Anaconda, the commands will be the same! This also applies across operating systems (Except for the activation of environment).\n\nThis document is base on [geohackweek's introduction to conda](https://geohackweek.github.io/Introductory/01-conda-tutorial/). At the end, there are two example for Python and R language.\n\n\n# Conda\n## Installation\nInstallation details, please have a look the [Official Installation guide](https://conda.io/projects/conda/en/latest/user-guide/install/linux.html)\n\nThere are brief steps at the below.\n```bash\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n```\n## Managing Conda\nLet’s first start by checking if conda is installed.\n\n```bash\nconda --version\n```\n\nOnce it has been confirmed that conda has been installed, we will now make sure that it is up to date.\n\n```bash\nconda update conda\n```\nConda will compare versions and let you know what is available to install. It will also tell you about other packages that will be automatically updated or changed with the update. If there are newer version available, follow the instruction to install the newest version of conda.\n\n**TIPS:**\nTo see the full documentation for any command, type the command followed by --help. For example, to learn about the conda update command:\n```bash\nconda update --help\n```\n\n## Managing Environments\nUsing conda, you can create an isolated environment for your project. An environment is a set of packages that can be used in one or multiple projects. The default environment is the root environment, which contains default packages listed here.\n\nThere are two ways of creating a conda environment.\n1. An environment file in YAML format (such as environment.yml).\n2. Manual specifications of packages.\n\n### Creating environment with an environment file\nYAML stands for YAML Ain’t Markup Language. It is a human friendly data serialization standard for all programming languages.\nThis is an example of an environment file that will install python 3.6, python-pip, and pyjokes library using pip. Conda is friendly with pip, so if some packages are not found in Anaconda Cloud, then you can install them with pip install. Open up your favorite text editor, copy and paste the code below, save your file as environment.yml.\n\n```\nname: playenv\nchannels:\n- conda-forge\ndependencies:\n- python=3.6\n- pip\n- pip:\n    - pyjokes\n```\nNow, let’s install environment.yml environment file above so that we can create a conda environment called playenv.\n\n```bash\nconda env create --file environment.yml\n```\n\n**TIPS:**\nThere is instruction for how to activate and deactivate environment. This command is slighty different between operating systems.\n1. Use an environment:\n\t1. Linux, OS X:\n\t\t```bash\n\t\tsource activate playenv\n\t\t```\n\t2. Windows:\n\t\t```bash\n\t\tactivate playenv\n\t\t```\n2. Deactivate an environment (goes back to root):\n\t1. Linux, OS X:\n\t\t```bash\n\t\tsource deactivate\n\t\t```\n\t2. Windows:\n\t\t```bash\n\t\tdeactivate\n\t\t```\n### Creating environment by manually specifying packages\nWe can create test_env conda environment by specifying the name, channel, and list of packages within the terminal window. In the example below, I am creating the test_env environment that uses python 2.7 and a list of libraries: numpy, matplotlib, pandas.\n\n```bash\nconda create -c conda-forge -n test_env python=2.7 numpy matplotlib pandas\n```\nConda will solve any dependencies between the packages like before and create a new environment with those packages.\n\n### Verifying current environment\nTo know the current environment that you’re in you can either look at your terminal:\n```bash\n(test_env) D-69-91-135-15:env_files lsetiawan$\n```\nThe (test_env) in the beginning of the line indicates that I’m curently using the test_env conda environment.\n\nAnother way that you can check for your current active environment is a command:\n```console\nfoo@bar:~$ conda env list\ntest_env              *  //anaconda/envs/test_env\nplayenv                  //anaconda/envs/playenv\nroot                     //anaconda\n```\n\nThe current environment is indicated by (\\*) character. This is also a great way to see the list of environments that have been created. In the list, the path to each environment is also shown.\n\n### Sharing Environments with others\nTo share an environment, you can export your conda environment to an environment file. By doing this, the resulting environment file is very detailed with specific version listing.\n\nExporting your environment to a file called myenv.yml:\n\n```bash\nconda env export -f test_env.yml -n test_env\n```\nThis will export a very detailed environment file that you can share with others. This file specifies the package=version=build. Note that this environment file will not work to share across platforms, since the builds and versions might be different for different operating systems.\n\n#### Best practice to share environments\n1. When starting a new environment, always generate it from an environment file rather than the command line.\n2. As you add packages to the environment, be sure to update the environment file.\n3. Unless you have to, try to avoid specifying the version of each package. This will ensure you have the most up to date version that will work across platform.\n\nIf you follow these guidelines, you should be able to give your environment file to anyone, and they will be able to install your packages with no problem.\n\n#### Making an exact copy of an environment and deleting environments\n##### Copying an environment\nWe can make an exact copy of an environment to an environment with a different name. This maybe useful for any testing versus live environments or python 2.7 vs python 3.6 for the same packages. In this example, test_env is cloned to create live_env.\n```bash\nconda create --name live_env --clone test_env\n```\n##### Deleting an environment\nDeleting an environment is very easy using conda. Since we are only testing out our environment, we will delete live_env to remove some clutter. Make sure that you are not currently using live_env.\n\n```bash\nconda env remove -n live_env\n```\n\n## Managing Packages\n### Seeing what packages are available\nWe will now check packages that are available to us. The command below will list all the packages in an environment, in this case test_env. The list will include versions of each package, the specific build, and the channel that the package was downloaded from. conda list is also useful to ensure that you have installed the packages that you desire.\n\n```console\nfoo@bar:~$ conda list -n test_env\n# packages in environment at //anaconda/envs/test_env:\n#\nUsing Anaconda Cloud api site https://api.anaconda.org\nblas                      1.1                    openblas    conda-forge\nca-certificates           2016.9.26                     0    conda-forge\ncertifi                   2016.9.26                py27_0    conda-forge\ncycler                    0.10.0                   py27_0    conda-forge\nfreetype                  2.6.3                         1    conda-forge\nfunctools32               3.2.3.2                  py27_1    conda-forge\nlibgfortran               3.0.0                         0    conda-forge\n...\n```\n### Searching for a certain package\nSome packages might not be available in conda, but are available in pypi. For example, we will search for rasterio within the anaconda cloud. It is not necessary to create an account with anaconda cloud, unless you’d like to contribute in the future when you are pro with conda.\n![anaconda cloud](https://geohackweek.github.io/Introductory/fig/Anaconda_cloud_rasterio_listing.png)\n\n#### Anaconda Cloud and Trusted Sources\nAnaconda Cloud is a package management service that makes it easy to find, access, store and share public and private notebooks, environments, and conda and PyPI packages, and to keep up with updates made to the packages and environments you’re using (Ref. Anaconda Cloud Doc). Anaconda Cloud is made up of channels/owners. Each channels contains one or more conda packages.\n\nIt is important to be careful when downloading any packages from an untrusted source. Conda forge is a reliable source for many popular python packages. It is wise to research about the source of a conda package.\n\nIn this example, we will use rasterio from conda-forge. The anaconda cloud page for rasterio will show how to install the package, compatible OS, individual files for that package, etc.\n![conda-forge](https://geohackweek.github.io/Introductory/fig/Anaconda_cloud_rasterio_page.png)\n\nIf you are using anaconda, you can do this search within the command line:\n```console\nfoo@bar:~$ anaconda search rasterio\nUsing Anaconda Cloud api site https://api.anaconda.org\nRun 'anaconda show <USER/PACKAGE>' to get more details:\nPackages:\n     Name                      |  Version | Package Types   | Platforms      \n     ------------------------- |   ------ | --------------- | ---------------\n     IOOS/rasterio             |    1.0a2 | conda           | linux-64, win-32, win-64, osx-64\n     Terradue/rasterio         |   0.32.0 | conda           | linux-64       \n                                          : Fast and direct raster I/O for use with Numpy and SciPy\n     anaconda/rasterio         |   0.36.0 | conda           | linux-64, win-32, win-64, linux-32, osx-64\n     conda-forge/rasterio      |    1.0a2 | conda           | linux-64, win-32, win-64, osx-64\n                                          : Rasterio reads and writes geospatial raster datasets\n     dharhas/rasterio          |   0.23.0 | conda           | win-64         \n                                          : Rasterio reads and writes geospatial raster datasets.\n     erdc/rasterio             |   0.23.0 | conda           | win-64         \n                                          : Rasterio reads and writes geospatial raster datasets.\n     jesserobertson/rasterio   |   0.23.0 | conda           | linux-64, linux-32, osx-64\n     jhamman/rasterio_to_xarray | 2016.03.16-1558 | ipynb           |                \n                                          : IPython notebook\n     krisvanneste/rasterio     |   0.26.0 | conda           | win-64         \n     ocefpaf/rasterio          |   0.19.1 | conda           | linux-64, osx-64\n     omgarcia/rasterio         |   0.25.0 | conda           | linux-64       \n     pypi/rasterio             |   0.13.2 | pypi            |                \n                                          : Fast and direct raster I/O for Python programmers who use Numpy\n     robintw/rasterio          |   0.35.1 | conda           | osx-64         \n                                          : Rasterio reads and writes geospatial raster datasets\n     sgillies/rasterio         |     0.15 | conda           | osx-64         \n     ztessler/rasterio         |   0.31.0 | conda           | osx-64         \n                                          : Fast and direct raster I/O for use with Numpy and SciPy\nFound 15 packages\n```\n\n### Installing conda package\nUnder the name column of the result in the terminal or the package column in the Anaconda Cloud listing, shows the necessary information to install the package. Ex. conda-forge/rasterio. The first word list the channel that this package is from and the second part shows the name of the package.\n\nTo install the latest version available within the channel, do not specify in the install command. We will install version 0.35 of rasterio from conda-forge into test_env in this example. Conda will also automatically install the dependencies for this package.\n\n```bash\nconda install -c conda-forge rasterio=0.35\n```\n\n**Pre-configuring Channels**\nIf you have a few trusted channels that you prefer to use, you can pre-configure these so that everytime you are creating an environment, you won’t need to explicitly declare the channel.\n```bash\nconda config --add channels conda-forge\n```\n\n### Removing Conda Package\nWe decided that rasterio is not needed in this tutorial, so we will remove it from test_env. Note that this will only remove the main package rasterio, not its dependencies.\n\n```console\nfoo@bar:~$ conda remove -n test_env rasterio\nUsing Anaconda Cloud api site https://api.anaconda.org\nFetching package metadata .........\nSolving package specifications: ..........\n\nPackage plan for package removal in environment //anaconda/envs/test_env:\n\nThe following packages will be REMOVED:\n\n    rasterio: 0.35.1-np111py27_1 conda-forge\n\nProceed ([y]/n)? y\n\nUnlinking packages ...\n[      COMPLETE      ]|#######################################################################################################| 100%\n\n```\n\n# Python\nThere is a example for using conda install Jupyter Notebooks and set Jupyter environment.\n```bash\nconda create -n myenv python=3.7.7\nconda activate myenv\nconda install notebook ipykernel\nipython kernel install --user --name myenv --display-name \"Python (myenv)\"\npip install azureml-sdk[notebooks,automl]\n```\n\n# R\n\n# Conclusion\n\n","source":"_posts/conda.md","raw":"---\ntitle: Getting started with Python and R environments using Conda\ndate: 2020-09-08 13:12:51\ntags:\n - Machine Learning\n - Conda\n - Python\n - R\ncategories: virtual environment\n---\n# Introduction\nThis post document is about using Conda to management Python and R language packages (libraries/dependencies), as well as virtual environment. Conda is an open source package management system and environment management system. Conda can quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language. Conda as a package manager helps you find and install packages. If you need a package that requires a different version of Python, you do not need to switch to a different environment manager, because conda is also an environment manager. With just a few commands, you can set up a totally separate environment to run that different version of Python, while continuing to run your usual version of Python in your normal environment.\n\nAnaconda is a distribution of conda. It is a data science platform that comes with a lot of packages.Unlike Anaconda, Miniconda doesn’t come with any installed packages by default. For this tutorial, I am using miniconda. If you have Anaconda, the commands will be the same! This also applies across operating systems (Except for the activation of environment).\n\nThis document is base on [geohackweek's introduction to conda](https://geohackweek.github.io/Introductory/01-conda-tutorial/). At the end, there are two example for Python and R language.\n\n\n# Conda\n## Installation\nInstallation details, please have a look the [Official Installation guide](https://conda.io/projects/conda/en/latest/user-guide/install/linux.html)\n\nThere are brief steps at the below.\n```bash\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n```\n## Managing Conda\nLet’s first start by checking if conda is installed.\n\n```bash\nconda --version\n```\n\nOnce it has been confirmed that conda has been installed, we will now make sure that it is up to date.\n\n```bash\nconda update conda\n```\nConda will compare versions and let you know what is available to install. It will also tell you about other packages that will be automatically updated or changed with the update. If there are newer version available, follow the instruction to install the newest version of conda.\n\n**TIPS:**\nTo see the full documentation for any command, type the command followed by --help. For example, to learn about the conda update command:\n```bash\nconda update --help\n```\n\n## Managing Environments\nUsing conda, you can create an isolated environment for your project. An environment is a set of packages that can be used in one or multiple projects. The default environment is the root environment, which contains default packages listed here.\n\nThere are two ways of creating a conda environment.\n1. An environment file in YAML format (such as environment.yml).\n2. Manual specifications of packages.\n\n### Creating environment with an environment file\nYAML stands for YAML Ain’t Markup Language. It is a human friendly data serialization standard for all programming languages.\nThis is an example of an environment file that will install python 3.6, python-pip, and pyjokes library using pip. Conda is friendly with pip, so if some packages are not found in Anaconda Cloud, then you can install them with pip install. Open up your favorite text editor, copy and paste the code below, save your file as environment.yml.\n\n```\nname: playenv\nchannels:\n- conda-forge\ndependencies:\n- python=3.6\n- pip\n- pip:\n    - pyjokes\n```\nNow, let’s install environment.yml environment file above so that we can create a conda environment called playenv.\n\n```bash\nconda env create --file environment.yml\n```\n\n**TIPS:**\nThere is instruction for how to activate and deactivate environment. This command is slighty different between operating systems.\n1. Use an environment:\n\t1. Linux, OS X:\n\t\t```bash\n\t\tsource activate playenv\n\t\t```\n\t2. Windows:\n\t\t```bash\n\t\tactivate playenv\n\t\t```\n2. Deactivate an environment (goes back to root):\n\t1. Linux, OS X:\n\t\t```bash\n\t\tsource deactivate\n\t\t```\n\t2. Windows:\n\t\t```bash\n\t\tdeactivate\n\t\t```\n### Creating environment by manually specifying packages\nWe can create test_env conda environment by specifying the name, channel, and list of packages within the terminal window. In the example below, I am creating the test_env environment that uses python 2.7 and a list of libraries: numpy, matplotlib, pandas.\n\n```bash\nconda create -c conda-forge -n test_env python=2.7 numpy matplotlib pandas\n```\nConda will solve any dependencies between the packages like before and create a new environment with those packages.\n\n### Verifying current environment\nTo know the current environment that you’re in you can either look at your terminal:\n```bash\n(test_env) D-69-91-135-15:env_files lsetiawan$\n```\nThe (test_env) in the beginning of the line indicates that I’m curently using the test_env conda environment.\n\nAnother way that you can check for your current active environment is a command:\n```console\nfoo@bar:~$ conda env list\ntest_env              *  //anaconda/envs/test_env\nplayenv                  //anaconda/envs/playenv\nroot                     //anaconda\n```\n\nThe current environment is indicated by (\\*) character. This is also a great way to see the list of environments that have been created. In the list, the path to each environment is also shown.\n\n### Sharing Environments with others\nTo share an environment, you can export your conda environment to an environment file. By doing this, the resulting environment file is very detailed with specific version listing.\n\nExporting your environment to a file called myenv.yml:\n\n```bash\nconda env export -f test_env.yml -n test_env\n```\nThis will export a very detailed environment file that you can share with others. This file specifies the package=version=build. Note that this environment file will not work to share across platforms, since the builds and versions might be different for different operating systems.\n\n#### Best practice to share environments\n1. When starting a new environment, always generate it from an environment file rather than the command line.\n2. As you add packages to the environment, be sure to update the environment file.\n3. Unless you have to, try to avoid specifying the version of each package. This will ensure you have the most up to date version that will work across platform.\n\nIf you follow these guidelines, you should be able to give your environment file to anyone, and they will be able to install your packages with no problem.\n\n#### Making an exact copy of an environment and deleting environments\n##### Copying an environment\nWe can make an exact copy of an environment to an environment with a different name. This maybe useful for any testing versus live environments or python 2.7 vs python 3.6 for the same packages. In this example, test_env is cloned to create live_env.\n```bash\nconda create --name live_env --clone test_env\n```\n##### Deleting an environment\nDeleting an environment is very easy using conda. Since we are only testing out our environment, we will delete live_env to remove some clutter. Make sure that you are not currently using live_env.\n\n```bash\nconda env remove -n live_env\n```\n\n## Managing Packages\n### Seeing what packages are available\nWe will now check packages that are available to us. The command below will list all the packages in an environment, in this case test_env. The list will include versions of each package, the specific build, and the channel that the package was downloaded from. conda list is also useful to ensure that you have installed the packages that you desire.\n\n```console\nfoo@bar:~$ conda list -n test_env\n# packages in environment at //anaconda/envs/test_env:\n#\nUsing Anaconda Cloud api site https://api.anaconda.org\nblas                      1.1                    openblas    conda-forge\nca-certificates           2016.9.26                     0    conda-forge\ncertifi                   2016.9.26                py27_0    conda-forge\ncycler                    0.10.0                   py27_0    conda-forge\nfreetype                  2.6.3                         1    conda-forge\nfunctools32               3.2.3.2                  py27_1    conda-forge\nlibgfortran               3.0.0                         0    conda-forge\n...\n```\n### Searching for a certain package\nSome packages might not be available in conda, but are available in pypi. For example, we will search for rasterio within the anaconda cloud. It is not necessary to create an account with anaconda cloud, unless you’d like to contribute in the future when you are pro with conda.\n![anaconda cloud](https://geohackweek.github.io/Introductory/fig/Anaconda_cloud_rasterio_listing.png)\n\n#### Anaconda Cloud and Trusted Sources\nAnaconda Cloud is a package management service that makes it easy to find, access, store and share public and private notebooks, environments, and conda and PyPI packages, and to keep up with updates made to the packages and environments you’re using (Ref. Anaconda Cloud Doc). Anaconda Cloud is made up of channels/owners. Each channels contains one or more conda packages.\n\nIt is important to be careful when downloading any packages from an untrusted source. Conda forge is a reliable source for many popular python packages. It is wise to research about the source of a conda package.\n\nIn this example, we will use rasterio from conda-forge. The anaconda cloud page for rasterio will show how to install the package, compatible OS, individual files for that package, etc.\n![conda-forge](https://geohackweek.github.io/Introductory/fig/Anaconda_cloud_rasterio_page.png)\n\nIf you are using anaconda, you can do this search within the command line:\n```console\nfoo@bar:~$ anaconda search rasterio\nUsing Anaconda Cloud api site https://api.anaconda.org\nRun 'anaconda show <USER/PACKAGE>' to get more details:\nPackages:\n     Name                      |  Version | Package Types   | Platforms      \n     ------------------------- |   ------ | --------------- | ---------------\n     IOOS/rasterio             |    1.0a2 | conda           | linux-64, win-32, win-64, osx-64\n     Terradue/rasterio         |   0.32.0 | conda           | linux-64       \n                                          : Fast and direct raster I/O for use with Numpy and SciPy\n     anaconda/rasterio         |   0.36.0 | conda           | linux-64, win-32, win-64, linux-32, osx-64\n     conda-forge/rasterio      |    1.0a2 | conda           | linux-64, win-32, win-64, osx-64\n                                          : Rasterio reads and writes geospatial raster datasets\n     dharhas/rasterio          |   0.23.0 | conda           | win-64         \n                                          : Rasterio reads and writes geospatial raster datasets.\n     erdc/rasterio             |   0.23.0 | conda           | win-64         \n                                          : Rasterio reads and writes geospatial raster datasets.\n     jesserobertson/rasterio   |   0.23.0 | conda           | linux-64, linux-32, osx-64\n     jhamman/rasterio_to_xarray | 2016.03.16-1558 | ipynb           |                \n                                          : IPython notebook\n     krisvanneste/rasterio     |   0.26.0 | conda           | win-64         \n     ocefpaf/rasterio          |   0.19.1 | conda           | linux-64, osx-64\n     omgarcia/rasterio         |   0.25.0 | conda           | linux-64       \n     pypi/rasterio             |   0.13.2 | pypi            |                \n                                          : Fast and direct raster I/O for Python programmers who use Numpy\n     robintw/rasterio          |   0.35.1 | conda           | osx-64         \n                                          : Rasterio reads and writes geospatial raster datasets\n     sgillies/rasterio         |     0.15 | conda           | osx-64         \n     ztessler/rasterio         |   0.31.0 | conda           | osx-64         \n                                          : Fast and direct raster I/O for use with Numpy and SciPy\nFound 15 packages\n```\n\n### Installing conda package\nUnder the name column of the result in the terminal or the package column in the Anaconda Cloud listing, shows the necessary information to install the package. Ex. conda-forge/rasterio. The first word list the channel that this package is from and the second part shows the name of the package.\n\nTo install the latest version available within the channel, do not specify in the install command. We will install version 0.35 of rasterio from conda-forge into test_env in this example. Conda will also automatically install the dependencies for this package.\n\n```bash\nconda install -c conda-forge rasterio=0.35\n```\n\n**Pre-configuring Channels**\nIf you have a few trusted channels that you prefer to use, you can pre-configure these so that everytime you are creating an environment, you won’t need to explicitly declare the channel.\n```bash\nconda config --add channels conda-forge\n```\n\n### Removing Conda Package\nWe decided that rasterio is not needed in this tutorial, so we will remove it from test_env. Note that this will only remove the main package rasterio, not its dependencies.\n\n```console\nfoo@bar:~$ conda remove -n test_env rasterio\nUsing Anaconda Cloud api site https://api.anaconda.org\nFetching package metadata .........\nSolving package specifications: ..........\n\nPackage plan for package removal in environment //anaconda/envs/test_env:\n\nThe following packages will be REMOVED:\n\n    rasterio: 0.35.1-np111py27_1 conda-forge\n\nProceed ([y]/n)? y\n\nUnlinking packages ...\n[      COMPLETE      ]|#######################################################################################################| 100%\n\n```\n\n# Python\nThere is a example for using conda install Jupyter Notebooks and set Jupyter environment.\n```bash\nconda create -n myenv python=3.7.7\nconda activate myenv\nconda install notebook ipykernel\nipython kernel install --user --name myenv --display-name \"Python (myenv)\"\npip install azureml-sdk[notebooks,automl]\n```\n\n# R\n\n# Conclusion\n\n","slug":"conda","published":1,"updated":"2020-09-24T08:31:13.565Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aiw000diiiya6lr3zr6","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about using Conda to management Python and R language packages (libraries/dependencies), as well as virtual environment. Conda is an open source package management system and environment management system. Conda can quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language. Conda as a package manager helps you find and install packages. If you need a package that requires a different version of Python, you do not need to switch to a different environment manager, because conda is also an environment manager. With just a few commands, you can set up a totally separate environment to run that different version of Python, while continuing to run your usual version of Python in your normal environment.</p>\n<p>Anaconda is a distribution of conda. It is a data science platform that comes with a lot of packages.Unlike Anaconda, Miniconda doesn’t come with any installed packages by default. For this tutorial, I am using miniconda. If you have Anaconda, the commands will be the same! This also applies across operating systems (Except for the activation of environment).</p>\n<p>This document is base on <a href=\"https://geohackweek.github.io/Introductory/01-conda-tutorial/\">geohackweek’s introduction to conda</a>. At the end, there are two example for Python and R language.</p>\n<h1 id=\"Conda\"><a href=\"#Conda\" class=\"headerlink\" title=\"Conda\"></a>Conda</h1><h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><p>Installation details, please have a look the <a href=\"https://conda.io/projects/conda/en/latest/user-guide/install/linux.html\">Official Installation guide</a></p>\n<p>There are brief steps at the below.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class=\"line\">bash Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>\n<h2 id=\"Managing-Conda\"><a href=\"#Managing-Conda\" class=\"headerlink\" title=\"Managing Conda\"></a>Managing Conda</h2><p>Let’s first start by checking if conda is installed.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda --version</span><br></pre></td></tr></table></figure>\n\n<p>Once it has been confirmed that conda has been installed, we will now make sure that it is up to date.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda update conda</span><br></pre></td></tr></table></figure>\n<p>Conda will compare versions and let you know what is available to install. It will also tell you about other packages that will be automatically updated or changed with the update. If there are newer version available, follow the instruction to install the newest version of conda.</p>\n<p><strong>TIPS:</strong><br>To see the full documentation for any command, type the command followed by –help. For example, to learn about the conda update command:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda update --<span class=\"built_in\">help</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Managing-Environments\"><a href=\"#Managing-Environments\" class=\"headerlink\" title=\"Managing Environments\"></a>Managing Environments</h2><p>Using conda, you can create an isolated environment for your project. An environment is a set of packages that can be used in one or multiple projects. The default environment is the root environment, which contains default packages listed here.</p>\n<p>There are two ways of creating a conda environment.</p>\n<ol>\n<li>An environment file in YAML format (such as environment.yml).</li>\n<li>Manual specifications of packages.</li>\n</ol>\n<h3 id=\"Creating-environment-with-an-environment-file\"><a href=\"#Creating-environment-with-an-environment-file\" class=\"headerlink\" title=\"Creating environment with an environment file\"></a>Creating environment with an environment file</h3><p>YAML stands for YAML Ain’t Markup Language. It is a human friendly data serialization standard for all programming languages.<br>This is an example of an environment file that will install python 3.6, python-pip, and pyjokes library using pip. Conda is friendly with pip, so if some packages are not found in Anaconda Cloud, then you can install them with pip install. Open up your favorite text editor, copy and paste the code below, save your file as environment.yml.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name: playenv</span><br><span class=\"line\">channels:</span><br><span class=\"line\">- conda-forge</span><br><span class=\"line\">dependencies:</span><br><span class=\"line\">- python&#x3D;3.6</span><br><span class=\"line\">- pip</span><br><span class=\"line\">- pip:</span><br><span class=\"line\">    - pyjokes</span><br></pre></td></tr></table></figure>\n<p>Now, let’s install environment.yml environment file above so that we can create a conda environment called playenv.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda env create --file environment.yml</span><br></pre></td></tr></table></figure>\n\n<p><strong>TIPS:</strong><br>There is instruction for how to activate and deactivate environment. This command is slighty different between operating systems.</p>\n<ol>\n<li>Use an environment:<ol>\n<li>Linux, OS X: <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> activate playenv</span><br></pre></td></tr></table></figure></li>\n<li>Windows: <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">activate playenv</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li>Deactivate an environment (goes back to root):<ol>\n<li>Linux, OS X: <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> deactivate</span><br></pre></td></tr></table></figure></li>\n<li>Windows: <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deactivate</span><br></pre></td></tr></table></figure>\n<h3 id=\"Creating-environment-by-manually-specifying-packages\"><a href=\"#Creating-environment-by-manually-specifying-packages\" class=\"headerlink\" title=\"Creating environment by manually specifying packages\"></a>Creating environment by manually specifying packages</h3>We can create test_env conda environment by specifying the name, channel, and list of packages within the terminal window. In the example below, I am creating the test_env environment that uses python 2.7 and a list of libraries: numpy, matplotlib, pandas.</li>\n</ol>\n</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -c conda-forge -n test_env python=2.7 numpy matplotlib pandas</span><br></pre></td></tr></table></figure>\n<p>Conda will solve any dependencies between the packages like before and create a new environment with those packages.</p>\n<h3 id=\"Verifying-current-environment\"><a href=\"#Verifying-current-environment\" class=\"headerlink\" title=\"Verifying current environment\"></a>Verifying current environment</h3><p>To know the current environment that you’re in you can either look at your terminal:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(test_env) D-69-91-135-15:env_files lsetiawan$</span><br></pre></td></tr></table></figure>\n<p>The (test_env) in the beginning of the line indicates that I’m curently using the test_env conda environment.</p>\n<p>Another way that you can check for your current active environment is a command:</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo@bar:~$ conda env list</span><br><span class=\"line\">test_env              *  //anaconda/envs/test_env</span><br><span class=\"line\">playenv                  //anaconda/envs/playenv</span><br><span class=\"line\">root                     //anaconda</span><br></pre></td></tr></table></figure>\n\n<p>The current environment is indicated by (*) character. This is also a great way to see the list of environments that have been created. In the list, the path to each environment is also shown.</p>\n<h3 id=\"Sharing-Environments-with-others\"><a href=\"#Sharing-Environments-with-others\" class=\"headerlink\" title=\"Sharing Environments with others\"></a>Sharing Environments with others</h3><p>To share an environment, you can export your conda environment to an environment file. By doing this, the resulting environment file is very detailed with specific version listing.</p>\n<p>Exporting your environment to a file called myenv.yml:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda env <span class=\"built_in\">export</span> -f test_env.yml -n test_env</span><br></pre></td></tr></table></figure>\n<p>This will export a very detailed environment file that you can share with others. This file specifies the package=version=build. Note that this environment file will not work to share across platforms, since the builds and versions might be different for different operating systems.</p>\n<h4 id=\"Best-practice-to-share-environments\"><a href=\"#Best-practice-to-share-environments\" class=\"headerlink\" title=\"Best practice to share environments\"></a>Best practice to share environments</h4><ol>\n<li>When starting a new environment, always generate it from an environment file rather than the command line.</li>\n<li>As you add packages to the environment, be sure to update the environment file.</li>\n<li>Unless you have to, try to avoid specifying the version of each package. This will ensure you have the most up to date version that will work across platform.</li>\n</ol>\n<p>If you follow these guidelines, you should be able to give your environment file to anyone, and they will be able to install your packages with no problem.</p>\n<h4 id=\"Making-an-exact-copy-of-an-environment-and-deleting-environments\"><a href=\"#Making-an-exact-copy-of-an-environment-and-deleting-environments\" class=\"headerlink\" title=\"Making an exact copy of an environment and deleting environments\"></a>Making an exact copy of an environment and deleting environments</h4><h5 id=\"Copying-an-environment\"><a href=\"#Copying-an-environment\" class=\"headerlink\" title=\"Copying an environment\"></a>Copying an environment</h5><p>We can make an exact copy of an environment to an environment with a different name. This maybe useful for any testing versus live environments or python 2.7 vs python 3.6 for the same packages. In this example, test_env is cloned to create live_env.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create --name live_env --<span class=\"built_in\">clone</span> test_env</span><br></pre></td></tr></table></figure>\n<h5 id=\"Deleting-an-environment\"><a href=\"#Deleting-an-environment\" class=\"headerlink\" title=\"Deleting an environment\"></a>Deleting an environment</h5><p>Deleting an environment is very easy using conda. Since we are only testing out our environment, we will delete live_env to remove some clutter. Make sure that you are not currently using live_env.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda env remove -n live_env</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Managing-Packages\"><a href=\"#Managing-Packages\" class=\"headerlink\" title=\"Managing Packages\"></a>Managing Packages</h2><h3 id=\"Seeing-what-packages-are-available\"><a href=\"#Seeing-what-packages-are-available\" class=\"headerlink\" title=\"Seeing what packages are available\"></a>Seeing what packages are available</h3><p>We will now check packages that are available to us. The command below will list all the packages in an environment, in this case test_env. The list will include versions of each package, the specific build, and the channel that the package was downloaded from. conda list is also useful to ensure that you have installed the packages that you desire.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo@bar:~$ conda list -n test_env</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> packages <span class=\"keyword\">in</span> environment at //anaconda/envs/test_env:</span></span><br><span class=\"line\"><span class=\"meta\">#</span></span><br><span class=\"line\">Using Anaconda Cloud api site https://api.anaconda.org</span><br><span class=\"line\">blas                      1.1                    openblas    conda-forge</span><br><span class=\"line\">ca-certificates           2016.9.26                     0    conda-forge</span><br><span class=\"line\">certifi                   2016.9.26                py27_0    conda-forge</span><br><span class=\"line\">cycler                    0.10.0                   py27_0    conda-forge</span><br><span class=\"line\">freetype                  2.6.3                         1    conda-forge</span><br><span class=\"line\">functools32               3.2.3.2                  py27_1    conda-forge</span><br><span class=\"line\">libgfortran               3.0.0                         0    conda-forge</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h3 id=\"Searching-for-a-certain-package\"><a href=\"#Searching-for-a-certain-package\" class=\"headerlink\" title=\"Searching for a certain package\"></a>Searching for a certain package</h3><p>Some packages might not be available in conda, but are available in pypi. For example, we will search for rasterio within the anaconda cloud. It is not necessary to create an account with anaconda cloud, unless you’d like to contribute in the future when you are pro with conda.<br><img src=\"https://geohackweek.github.io/Introductory/fig/Anaconda_cloud_rasterio_listing.png\" alt=\"anaconda cloud\"></p>\n<h4 id=\"Anaconda-Cloud-and-Trusted-Sources\"><a href=\"#Anaconda-Cloud-and-Trusted-Sources\" class=\"headerlink\" title=\"Anaconda Cloud and Trusted Sources\"></a>Anaconda Cloud and Trusted Sources</h4><p>Anaconda Cloud is a package management service that makes it easy to find, access, store and share public and private notebooks, environments, and conda and PyPI packages, and to keep up with updates made to the packages and environments you’re using (Ref. Anaconda Cloud Doc). Anaconda Cloud is made up of channels/owners. Each channels contains one or more conda packages.</p>\n<p>It is important to be careful when downloading any packages from an untrusted source. Conda forge is a reliable source for many popular python packages. It is wise to research about the source of a conda package.</p>\n<p>In this example, we will use rasterio from conda-forge. The anaconda cloud page for rasterio will show how to install the package, compatible OS, individual files for that package, etc.<br><img src=\"https://geohackweek.github.io/Introductory/fig/Anaconda_cloud_rasterio_page.png\" alt=\"conda-forge\"></p>\n<p>If you are using anaconda, you can do this search within the command line:</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo@bar:~$ anaconda search rasterio</span><br><span class=\"line\">Using Anaconda Cloud api site https://api.anaconda.org</span><br><span class=\"line\">Run &#x27;anaconda show &lt;USER/PACKAGE&gt;&#x27; to get more details:</span><br><span class=\"line\">Packages:</span><br><span class=\"line\">     Name                      |  Version | Package Types   | Platforms      </span><br><span class=\"line\">     ------------------------- |   ------ | --------------- | ---------------</span><br><span class=\"line\">     IOOS/rasterio             |    1.0a2 | conda           | linux-64, win-32, win-64, osx-64</span><br><span class=\"line\">     Terradue/rasterio         |   0.32.0 | conda           | linux-64       </span><br><span class=\"line\">                                          : Fast and direct raster I/O for use with Numpy and SciPy</span><br><span class=\"line\">     anaconda/rasterio         |   0.36.0 | conda           | linux-64, win-32, win-64, linux-32, osx-64</span><br><span class=\"line\">     conda-forge/rasterio      |    1.0a2 | conda           | linux-64, win-32, win-64, osx-64</span><br><span class=\"line\">                                          : Rasterio reads and writes geospatial raster datasets</span><br><span class=\"line\">     dharhas/rasterio          |   0.23.0 | conda           | win-64         </span><br><span class=\"line\">                                          : Rasterio reads and writes geospatial raster datasets.</span><br><span class=\"line\">     erdc/rasterio             |   0.23.0 | conda           | win-64         </span><br><span class=\"line\">                                          : Rasterio reads and writes geospatial raster datasets.</span><br><span class=\"line\">     jesserobertson/rasterio   |   0.23.0 | conda           | linux-64, linux-32, osx-64</span><br><span class=\"line\">     jhamman/rasterio_to_xarray | 2016.03.16-1558 | ipynb           |                </span><br><span class=\"line\">                                          : IPython notebook</span><br><span class=\"line\">     krisvanneste/rasterio     |   0.26.0 | conda           | win-64         </span><br><span class=\"line\">     ocefpaf/rasterio          |   0.19.1 | conda           | linux-64, osx-64</span><br><span class=\"line\">     omgarcia/rasterio         |   0.25.0 | conda           | linux-64       </span><br><span class=\"line\">     pypi/rasterio             |   0.13.2 | pypi            |                </span><br><span class=\"line\">                                          : Fast and direct raster I/O for Python programmers who use Numpy</span><br><span class=\"line\">     robintw/rasterio          |   0.35.1 | conda           | osx-64         </span><br><span class=\"line\">                                          : Rasterio reads and writes geospatial raster datasets</span><br><span class=\"line\">     sgillies/rasterio         |     0.15 | conda           | osx-64         </span><br><span class=\"line\">     ztessler/rasterio         |   0.31.0 | conda           | osx-64         </span><br><span class=\"line\">                                          : Fast and direct raster I/O for use with Numpy and SciPy</span><br><span class=\"line\">Found 15 packages</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Installing-conda-package\"><a href=\"#Installing-conda-package\" class=\"headerlink\" title=\"Installing conda package\"></a>Installing conda package</h3><p>Under the name column of the result in the terminal or the package column in the Anaconda Cloud listing, shows the necessary information to install the package. Ex. conda-forge/rasterio. The first word list the channel that this package is from and the second part shows the name of the package.</p>\n<p>To install the latest version available within the channel, do not specify in the install command. We will install version 0.35 of rasterio from conda-forge into test_env in this example. Conda will also automatically install the dependencies for this package.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install -c conda-forge rasterio=0.35</span><br></pre></td></tr></table></figure>\n\n<p><strong>Pre-configuring Channels</strong><br>If you have a few trusted channels that you prefer to use, you can pre-configure these so that everytime you are creating an environment, you won’t need to explicitly declare the channel.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda config --add channels conda-forge</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Removing-Conda-Package\"><a href=\"#Removing-Conda-Package\" class=\"headerlink\" title=\"Removing Conda Package\"></a>Removing Conda Package</h3><p>We decided that rasterio is not needed in this tutorial, so we will remove it from test_env. Note that this will only remove the main package rasterio, not its dependencies.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo@bar:~$ conda remove -n test_env rasterio</span><br><span class=\"line\">Using Anaconda Cloud api site https://api.anaconda.org</span><br><span class=\"line\">Fetching package metadata .........</span><br><span class=\"line\">Solving package specifications: ..........</span><br><span class=\"line\"></span><br><span class=\"line\">Package plan for package removal in environment //anaconda/envs/test_env:</span><br><span class=\"line\"></span><br><span class=\"line\">The following packages will be REMOVED:</span><br><span class=\"line\"></span><br><span class=\"line\">    rasterio: 0.35.1-np111py27_1 conda-forge</span><br><span class=\"line\"></span><br><span class=\"line\">Proceed ([y]/n)? y</span><br><span class=\"line\"></span><br><span class=\"line\">Unlinking packages ...</span><br><span class=\"line\">[      COMPLETE      ]|#######################################################################################################| 100%</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h1><p>There is a example for using conda install Jupyter Notebooks and set Jupyter environment.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n myenv python=3.7.7</span><br><span class=\"line\">conda activate myenv</span><br><span class=\"line\">conda install notebook ipykernel</span><br><span class=\"line\">ipython kernel install --user --name myenv --display-name <span class=\"string\">&quot;Python (myenv)&quot;</span></span><br><span class=\"line\">pip install azureml-sdk[notebooks,automl]</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"R\"><a href=\"#R\" class=\"headerlink\" title=\"R\"></a>R</h1><h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about using Conda to management Python and R language packages (libraries/dependencies), as well as virtual environment. Conda is an open source package management system and environment management system. Conda can quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language. Conda as a package manager helps you find and install packages. If you need a package that requires a different version of Python, you do not need to switch to a different environment manager, because conda is also an environment manager. With just a few commands, you can set up a totally separate environment to run that different version of Python, while continuing to run your usual version of Python in your normal environment.</p>\n<p>Anaconda is a distribution of conda. It is a data science platform that comes with a lot of packages.Unlike Anaconda, Miniconda doesn’t come with any installed packages by default. For this tutorial, I am using miniconda. If you have Anaconda, the commands will be the same! This also applies across operating systems (Except for the activation of environment).</p>\n<p>This document is base on <a href=\"https://geohackweek.github.io/Introductory/01-conda-tutorial/\">geohackweek’s introduction to conda</a>. At the end, there are two example for Python and R language.</p>\n<h1 id=\"Conda\"><a href=\"#Conda\" class=\"headerlink\" title=\"Conda\"></a>Conda</h1><h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><p>Installation details, please have a look the <a href=\"https://conda.io/projects/conda/en/latest/user-guide/install/linux.html\">Official Installation guide</a></p>\n<p>There are brief steps at the below.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class=\"line\">bash Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>\n<h2 id=\"Managing-Conda\"><a href=\"#Managing-Conda\" class=\"headerlink\" title=\"Managing Conda\"></a>Managing Conda</h2><p>Let’s first start by checking if conda is installed.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda --version</span><br></pre></td></tr></table></figure>\n\n<p>Once it has been confirmed that conda has been installed, we will now make sure that it is up to date.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda update conda</span><br></pre></td></tr></table></figure>\n<p>Conda will compare versions and let you know what is available to install. It will also tell you about other packages that will be automatically updated or changed with the update. If there are newer version available, follow the instruction to install the newest version of conda.</p>\n<p><strong>TIPS:</strong><br>To see the full documentation for any command, type the command followed by –help. For example, to learn about the conda update command:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda update --<span class=\"built_in\">help</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Managing-Environments\"><a href=\"#Managing-Environments\" class=\"headerlink\" title=\"Managing Environments\"></a>Managing Environments</h2><p>Using conda, you can create an isolated environment for your project. An environment is a set of packages that can be used in one or multiple projects. The default environment is the root environment, which contains default packages listed here.</p>\n<p>There are two ways of creating a conda environment.</p>\n<ol>\n<li>An environment file in YAML format (such as environment.yml).</li>\n<li>Manual specifications of packages.</li>\n</ol>\n<h3 id=\"Creating-environment-with-an-environment-file\"><a href=\"#Creating-environment-with-an-environment-file\" class=\"headerlink\" title=\"Creating environment with an environment file\"></a>Creating environment with an environment file</h3><p>YAML stands for YAML Ain’t Markup Language. It is a human friendly data serialization standard for all programming languages.<br>This is an example of an environment file that will install python 3.6, python-pip, and pyjokes library using pip. Conda is friendly with pip, so if some packages are not found in Anaconda Cloud, then you can install them with pip install. Open up your favorite text editor, copy and paste the code below, save your file as environment.yml.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name: playenv</span><br><span class=\"line\">channels:</span><br><span class=\"line\">- conda-forge</span><br><span class=\"line\">dependencies:</span><br><span class=\"line\">- python&#x3D;3.6</span><br><span class=\"line\">- pip</span><br><span class=\"line\">- pip:</span><br><span class=\"line\">    - pyjokes</span><br></pre></td></tr></table></figure>\n<p>Now, let’s install environment.yml environment file above so that we can create a conda environment called playenv.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda env create --file environment.yml</span><br></pre></td></tr></table></figure>\n\n<p><strong>TIPS:</strong><br>There is instruction for how to activate and deactivate environment. This command is slighty different between operating systems.</p>\n<ol>\n<li>Use an environment:<ol>\n<li>Linux, OS X: <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> activate playenv</span><br></pre></td></tr></table></figure></li>\n<li>Windows: <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">activate playenv</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li>Deactivate an environment (goes back to root):<ol>\n<li>Linux, OS X: <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> deactivate</span><br></pre></td></tr></table></figure></li>\n<li>Windows: <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deactivate</span><br></pre></td></tr></table></figure>\n<h3 id=\"Creating-environment-by-manually-specifying-packages\"><a href=\"#Creating-environment-by-manually-specifying-packages\" class=\"headerlink\" title=\"Creating environment by manually specifying packages\"></a>Creating environment by manually specifying packages</h3>We can create test_env conda environment by specifying the name, channel, and list of packages within the terminal window. In the example below, I am creating the test_env environment that uses python 2.7 and a list of libraries: numpy, matplotlib, pandas.</li>\n</ol>\n</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -c conda-forge -n test_env python=2.7 numpy matplotlib pandas</span><br></pre></td></tr></table></figure>\n<p>Conda will solve any dependencies between the packages like before and create a new environment with those packages.</p>\n<h3 id=\"Verifying-current-environment\"><a href=\"#Verifying-current-environment\" class=\"headerlink\" title=\"Verifying current environment\"></a>Verifying current environment</h3><p>To know the current environment that you’re in you can either look at your terminal:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(test_env) D-69-91-135-15:env_files lsetiawan$</span><br></pre></td></tr></table></figure>\n<p>The (test_env) in the beginning of the line indicates that I’m curently using the test_env conda environment.</p>\n<p>Another way that you can check for your current active environment is a command:</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo@bar:~$ conda env list</span><br><span class=\"line\">test_env              *  //anaconda/envs/test_env</span><br><span class=\"line\">playenv                  //anaconda/envs/playenv</span><br><span class=\"line\">root                     //anaconda</span><br></pre></td></tr></table></figure>\n\n<p>The current environment is indicated by (*) character. This is also a great way to see the list of environments that have been created. In the list, the path to each environment is also shown.</p>\n<h3 id=\"Sharing-Environments-with-others\"><a href=\"#Sharing-Environments-with-others\" class=\"headerlink\" title=\"Sharing Environments with others\"></a>Sharing Environments with others</h3><p>To share an environment, you can export your conda environment to an environment file. By doing this, the resulting environment file is very detailed with specific version listing.</p>\n<p>Exporting your environment to a file called myenv.yml:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda env <span class=\"built_in\">export</span> -f test_env.yml -n test_env</span><br></pre></td></tr></table></figure>\n<p>This will export a very detailed environment file that you can share with others. This file specifies the package=version=build. Note that this environment file will not work to share across platforms, since the builds and versions might be different for different operating systems.</p>\n<h4 id=\"Best-practice-to-share-environments\"><a href=\"#Best-practice-to-share-environments\" class=\"headerlink\" title=\"Best practice to share environments\"></a>Best practice to share environments</h4><ol>\n<li>When starting a new environment, always generate it from an environment file rather than the command line.</li>\n<li>As you add packages to the environment, be sure to update the environment file.</li>\n<li>Unless you have to, try to avoid specifying the version of each package. This will ensure you have the most up to date version that will work across platform.</li>\n</ol>\n<p>If you follow these guidelines, you should be able to give your environment file to anyone, and they will be able to install your packages with no problem.</p>\n<h4 id=\"Making-an-exact-copy-of-an-environment-and-deleting-environments\"><a href=\"#Making-an-exact-copy-of-an-environment-and-deleting-environments\" class=\"headerlink\" title=\"Making an exact copy of an environment and deleting environments\"></a>Making an exact copy of an environment and deleting environments</h4><h5 id=\"Copying-an-environment\"><a href=\"#Copying-an-environment\" class=\"headerlink\" title=\"Copying an environment\"></a>Copying an environment</h5><p>We can make an exact copy of an environment to an environment with a different name. This maybe useful for any testing versus live environments or python 2.7 vs python 3.6 for the same packages. In this example, test_env is cloned to create live_env.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create --name live_env --<span class=\"built_in\">clone</span> test_env</span><br></pre></td></tr></table></figure>\n<h5 id=\"Deleting-an-environment\"><a href=\"#Deleting-an-environment\" class=\"headerlink\" title=\"Deleting an environment\"></a>Deleting an environment</h5><p>Deleting an environment is very easy using conda. Since we are only testing out our environment, we will delete live_env to remove some clutter. Make sure that you are not currently using live_env.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda env remove -n live_env</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Managing-Packages\"><a href=\"#Managing-Packages\" class=\"headerlink\" title=\"Managing Packages\"></a>Managing Packages</h2><h3 id=\"Seeing-what-packages-are-available\"><a href=\"#Seeing-what-packages-are-available\" class=\"headerlink\" title=\"Seeing what packages are available\"></a>Seeing what packages are available</h3><p>We will now check packages that are available to us. The command below will list all the packages in an environment, in this case test_env. The list will include versions of each package, the specific build, and the channel that the package was downloaded from. conda list is also useful to ensure that you have installed the packages that you desire.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo@bar:~$ conda list -n test_env</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> packages <span class=\"keyword\">in</span> environment at //anaconda/envs/test_env:</span></span><br><span class=\"line\"><span class=\"meta\">#</span></span><br><span class=\"line\">Using Anaconda Cloud api site https://api.anaconda.org</span><br><span class=\"line\">blas                      1.1                    openblas    conda-forge</span><br><span class=\"line\">ca-certificates           2016.9.26                     0    conda-forge</span><br><span class=\"line\">certifi                   2016.9.26                py27_0    conda-forge</span><br><span class=\"line\">cycler                    0.10.0                   py27_0    conda-forge</span><br><span class=\"line\">freetype                  2.6.3                         1    conda-forge</span><br><span class=\"line\">functools32               3.2.3.2                  py27_1    conda-forge</span><br><span class=\"line\">libgfortran               3.0.0                         0    conda-forge</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h3 id=\"Searching-for-a-certain-package\"><a href=\"#Searching-for-a-certain-package\" class=\"headerlink\" title=\"Searching for a certain package\"></a>Searching for a certain package</h3><p>Some packages might not be available in conda, but are available in pypi. For example, we will search for rasterio within the anaconda cloud. It is not necessary to create an account with anaconda cloud, unless you’d like to contribute in the future when you are pro with conda.<br><img src=\"https://geohackweek.github.io/Introductory/fig/Anaconda_cloud_rasterio_listing.png\" alt=\"anaconda cloud\"></p>\n<h4 id=\"Anaconda-Cloud-and-Trusted-Sources\"><a href=\"#Anaconda-Cloud-and-Trusted-Sources\" class=\"headerlink\" title=\"Anaconda Cloud and Trusted Sources\"></a>Anaconda Cloud and Trusted Sources</h4><p>Anaconda Cloud is a package management service that makes it easy to find, access, store and share public and private notebooks, environments, and conda and PyPI packages, and to keep up with updates made to the packages and environments you’re using (Ref. Anaconda Cloud Doc). Anaconda Cloud is made up of channels/owners. Each channels contains one or more conda packages.</p>\n<p>It is important to be careful when downloading any packages from an untrusted source. Conda forge is a reliable source for many popular python packages. It is wise to research about the source of a conda package.</p>\n<p>In this example, we will use rasterio from conda-forge. The anaconda cloud page for rasterio will show how to install the package, compatible OS, individual files for that package, etc.<br><img src=\"https://geohackweek.github.io/Introductory/fig/Anaconda_cloud_rasterio_page.png\" alt=\"conda-forge\"></p>\n<p>If you are using anaconda, you can do this search within the command line:</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo@bar:~$ anaconda search rasterio</span><br><span class=\"line\">Using Anaconda Cloud api site https://api.anaconda.org</span><br><span class=\"line\">Run &#x27;anaconda show &lt;USER/PACKAGE&gt;&#x27; to get more details:</span><br><span class=\"line\">Packages:</span><br><span class=\"line\">     Name                      |  Version | Package Types   | Platforms      </span><br><span class=\"line\">     ------------------------- |   ------ | --------------- | ---------------</span><br><span class=\"line\">     IOOS/rasterio             |    1.0a2 | conda           | linux-64, win-32, win-64, osx-64</span><br><span class=\"line\">     Terradue/rasterio         |   0.32.0 | conda           | linux-64       </span><br><span class=\"line\">                                          : Fast and direct raster I/O for use with Numpy and SciPy</span><br><span class=\"line\">     anaconda/rasterio         |   0.36.0 | conda           | linux-64, win-32, win-64, linux-32, osx-64</span><br><span class=\"line\">     conda-forge/rasterio      |    1.0a2 | conda           | linux-64, win-32, win-64, osx-64</span><br><span class=\"line\">                                          : Rasterio reads and writes geospatial raster datasets</span><br><span class=\"line\">     dharhas/rasterio          |   0.23.0 | conda           | win-64         </span><br><span class=\"line\">                                          : Rasterio reads and writes geospatial raster datasets.</span><br><span class=\"line\">     erdc/rasterio             |   0.23.0 | conda           | win-64         </span><br><span class=\"line\">                                          : Rasterio reads and writes geospatial raster datasets.</span><br><span class=\"line\">     jesserobertson/rasterio   |   0.23.0 | conda           | linux-64, linux-32, osx-64</span><br><span class=\"line\">     jhamman/rasterio_to_xarray | 2016.03.16-1558 | ipynb           |                </span><br><span class=\"line\">                                          : IPython notebook</span><br><span class=\"line\">     krisvanneste/rasterio     |   0.26.0 | conda           | win-64         </span><br><span class=\"line\">     ocefpaf/rasterio          |   0.19.1 | conda           | linux-64, osx-64</span><br><span class=\"line\">     omgarcia/rasterio         |   0.25.0 | conda           | linux-64       </span><br><span class=\"line\">     pypi/rasterio             |   0.13.2 | pypi            |                </span><br><span class=\"line\">                                          : Fast and direct raster I/O for Python programmers who use Numpy</span><br><span class=\"line\">     robintw/rasterio          |   0.35.1 | conda           | osx-64         </span><br><span class=\"line\">                                          : Rasterio reads and writes geospatial raster datasets</span><br><span class=\"line\">     sgillies/rasterio         |     0.15 | conda           | osx-64         </span><br><span class=\"line\">     ztessler/rasterio         |   0.31.0 | conda           | osx-64         </span><br><span class=\"line\">                                          : Fast and direct raster I/O for use with Numpy and SciPy</span><br><span class=\"line\">Found 15 packages</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Installing-conda-package\"><a href=\"#Installing-conda-package\" class=\"headerlink\" title=\"Installing conda package\"></a>Installing conda package</h3><p>Under the name column of the result in the terminal or the package column in the Anaconda Cloud listing, shows the necessary information to install the package. Ex. conda-forge/rasterio. The first word list the channel that this package is from and the second part shows the name of the package.</p>\n<p>To install the latest version available within the channel, do not specify in the install command. We will install version 0.35 of rasterio from conda-forge into test_env in this example. Conda will also automatically install the dependencies for this package.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install -c conda-forge rasterio=0.35</span><br></pre></td></tr></table></figure>\n\n<p><strong>Pre-configuring Channels</strong><br>If you have a few trusted channels that you prefer to use, you can pre-configure these so that everytime you are creating an environment, you won’t need to explicitly declare the channel.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda config --add channels conda-forge</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Removing-Conda-Package\"><a href=\"#Removing-Conda-Package\" class=\"headerlink\" title=\"Removing Conda Package\"></a>Removing Conda Package</h3><p>We decided that rasterio is not needed in this tutorial, so we will remove it from test_env. Note that this will only remove the main package rasterio, not its dependencies.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo@bar:~$ conda remove -n test_env rasterio</span><br><span class=\"line\">Using Anaconda Cloud api site https://api.anaconda.org</span><br><span class=\"line\">Fetching package metadata .........</span><br><span class=\"line\">Solving package specifications: ..........</span><br><span class=\"line\"></span><br><span class=\"line\">Package plan for package removal in environment //anaconda/envs/test_env:</span><br><span class=\"line\"></span><br><span class=\"line\">The following packages will be REMOVED:</span><br><span class=\"line\"></span><br><span class=\"line\">    rasterio: 0.35.1-np111py27_1 conda-forge</span><br><span class=\"line\"></span><br><span class=\"line\">Proceed ([y]/n)? y</span><br><span class=\"line\"></span><br><span class=\"line\">Unlinking packages ...</span><br><span class=\"line\">[      COMPLETE      ]|#######################################################################################################| 100%</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h1><p>There is a example for using conda install Jupyter Notebooks and set Jupyter environment.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n myenv python=3.7.7</span><br><span class=\"line\">conda activate myenv</span><br><span class=\"line\">conda install notebook ipykernel</span><br><span class=\"line\">ipython kernel install --user --name myenv --display-name <span class=\"string\">&quot;Python (myenv)&quot;</span></span><br><span class=\"line\">pip install azureml-sdk[notebooks,automl]</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"R\"><a href=\"#R\" class=\"headerlink\" title=\"R\"></a>R</h1><h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1>"},{"title":"ffmpeg","date":"2020-10-07T02:32:22.000Z","_content":"# Using Linux Terminal to Install VLC in Ubuntu\nsudo snap install vlc\n\n","source":"_posts/ffmpeg.md","raw":"---\ntitle: ffmpeg\ndate: 2020-10-07 02:32:22\ntags:\n---\n# Using Linux Terminal to Install VLC in Ubuntu\nsudo snap install vlc\n\n","slug":"ffmpeg","published":1,"updated":"2020-10-07T03:08:31.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aix000iiiiy1yy4aj89","content":"<h1 id=\"Using-Linux-Terminal-to-Install-VLC-in-Ubuntu\"><a href=\"#Using-Linux-Terminal-to-Install-VLC-in-Ubuntu\" class=\"headerlink\" title=\"Using Linux Terminal to Install VLC in Ubuntu\"></a>Using Linux Terminal to Install VLC in Ubuntu</h1><p>sudo snap install vlc</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Using-Linux-Terminal-to-Install-VLC-in-Ubuntu\"><a href=\"#Using-Linux-Terminal-to-Install-VLC-in-Ubuntu\" class=\"headerlink\" title=\"Using Linux Terminal to Install VLC in Ubuntu\"></a>Using Linux Terminal to Install VLC in Ubuntu</h1><p>sudo snap install vlc</p>\n"},{"title":"Getting Started with Reverse Proxy","subtitle":"A case study of FRP","date":"2020-09-26T14:14:14.000Z","_content":"# What is frp?\nfrp is a fast reverse proxy to help you expose a local server behind a NAT or firewall to the Internet. As of now, it supports TCP and UDP, as well as HTTP and HTTPS protocols, where requests can be forwarded to internal services by domain name.\n\nfrp also has a P2P connect mode.\n\n# Architecture\n[architecture](https://github.com/fatedier/frp/blob/dev/doc/pic/architecture.png)\n\n# Installation\n1. Download the latest programs from [Release](https://github.com/fatedier/frp/releases) page according to your operating system and architecture.\n\nThere is a example:\n```console\nyanboyang713@boyang$ wget https://github.com/fatedier/frp/releases/download/v0.34.0/frp_0.34.0_linux_amd64.tar.gz\nyanboyang713@boyang$ tar -xzf frp_0.34.0_linux_amd64.tar.gz\nyanboyang713@boyang$ cd frp_0.34.0_linux_amd64\nyanboyang713@boyang$ ls\nfrpc  frpc_full.ini  frpc.ini  frps  frps_full.ini  frps.ini  LICENSE  systemd\n```\n2. Put frps and frps.ini onto your server A (usually is cloud VM) with public IP.\nThere is a example:\n```console\nyanboyang713@boyang:~/Downloads/frp_0.34.0_linux_amd64$ sftp boyyan@52.141.58.83\nboyyan@52.141.58.83's password: \nConnected to 52.141.58.83.\nsftp> ls\nsftp> lls\nfrpc  frpc_full.ini  frpc.ini  frps  frps_full.ini  frps.ini  LICENSE  systemd\nsftp> put frps.ini\nUploading frps to /home/boyyan/frps.ini\nfrps.ini  \nsftp> put frps\nUploading frps to /home/boyyan/frps\nfrps                                                               100%   13MB   7.4MB/s   00:01    \nsftp> ls\nfrps      frps.ini  \nsftp> exit\n```\n3. Put frpc and frpc.ini onto your server B in LAN (that can't be connected from public Internet).\n\n# Access your computer in LAN by SSH\n1. Modify frps.ini on server A and set the bind_port to be connected to frp clients:\n```\n[common]\nbind_port = 7000\n```\n2. Start frps on server A:\n```console\n./frps -c ./frps.ini\n```\n3. On server B, modify frpc.ini to put in your frps server public IP as server_addr field:\n```\n[common]\nserver_addr = 20.194.22.192\nserver_port = 7000\n\n[ssh]\ntype = tcp\nlocal_ip = 127.0.0.1\nlocal_port = 22\nremote_port = 6000\n```\n**Note** that local_port (listened on client) and remote_port (exposed on server) are for traffic goes in/out the frp system, whereas server_port is used between frps.\n\n4. Start frpc on server B:\n```\n./frpc -c ./frpc.ini\n```\n5. From another machine, SSH to server B like this (assuming that username is test):\n```console\nssh -oPort=6000 test@x.x.x.x\n```\n\n","source":"_posts/frp.md","raw":"---\ntitle: Getting Started with Reverse Proxy\nsubtitle: A case study of FRP\ndate: 2020-09-26 14:14:14\ntags:\n - Networking\ncategories: Networking\n---\n# What is frp?\nfrp is a fast reverse proxy to help you expose a local server behind a NAT or firewall to the Internet. As of now, it supports TCP and UDP, as well as HTTP and HTTPS protocols, where requests can be forwarded to internal services by domain name.\n\nfrp also has a P2P connect mode.\n\n# Architecture\n[architecture](https://github.com/fatedier/frp/blob/dev/doc/pic/architecture.png)\n\n# Installation\n1. Download the latest programs from [Release](https://github.com/fatedier/frp/releases) page according to your operating system and architecture.\n\nThere is a example:\n```console\nyanboyang713@boyang$ wget https://github.com/fatedier/frp/releases/download/v0.34.0/frp_0.34.0_linux_amd64.tar.gz\nyanboyang713@boyang$ tar -xzf frp_0.34.0_linux_amd64.tar.gz\nyanboyang713@boyang$ cd frp_0.34.0_linux_amd64\nyanboyang713@boyang$ ls\nfrpc  frpc_full.ini  frpc.ini  frps  frps_full.ini  frps.ini  LICENSE  systemd\n```\n2. Put frps and frps.ini onto your server A (usually is cloud VM) with public IP.\nThere is a example:\n```console\nyanboyang713@boyang:~/Downloads/frp_0.34.0_linux_amd64$ sftp boyyan@52.141.58.83\nboyyan@52.141.58.83's password: \nConnected to 52.141.58.83.\nsftp> ls\nsftp> lls\nfrpc  frpc_full.ini  frpc.ini  frps  frps_full.ini  frps.ini  LICENSE  systemd\nsftp> put frps.ini\nUploading frps to /home/boyyan/frps.ini\nfrps.ini  \nsftp> put frps\nUploading frps to /home/boyyan/frps\nfrps                                                               100%   13MB   7.4MB/s   00:01    \nsftp> ls\nfrps      frps.ini  \nsftp> exit\n```\n3. Put frpc and frpc.ini onto your server B in LAN (that can't be connected from public Internet).\n\n# Access your computer in LAN by SSH\n1. Modify frps.ini on server A and set the bind_port to be connected to frp clients:\n```\n[common]\nbind_port = 7000\n```\n2. Start frps on server A:\n```console\n./frps -c ./frps.ini\n```\n3. On server B, modify frpc.ini to put in your frps server public IP as server_addr field:\n```\n[common]\nserver_addr = 20.194.22.192\nserver_port = 7000\n\n[ssh]\ntype = tcp\nlocal_ip = 127.0.0.1\nlocal_port = 22\nremote_port = 6000\n```\n**Note** that local_port (listened on client) and remote_port (exposed on server) are for traffic goes in/out the frp system, whereas server_port is used between frps.\n\n4. Start frpc on server B:\n```\n./frpc -c ./frpc.ini\n```\n5. From another machine, SSH to server B like this (assuming that username is test):\n```console\nssh -oPort=6000 test@x.x.x.x\n```\n\n","slug":"frp","published":1,"updated":"2020-09-27T19:02:18.119Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aiy000jiiiycrqw76q3","content":"<h1 id=\"What-is-frp\"><a href=\"#What-is-frp\" class=\"headerlink\" title=\"What is frp?\"></a>What is frp?</h1><p>frp is a fast reverse proxy to help you expose a local server behind a NAT or firewall to the Internet. As of now, it supports TCP and UDP, as well as HTTP and HTTPS protocols, where requests can be forwarded to internal services by domain name.</p>\n<p>frp also has a P2P connect mode.</p>\n<h1 id=\"Architecture\"><a href=\"#Architecture\" class=\"headerlink\" title=\"Architecture\"></a>Architecture</h1><p><a href=\"https://github.com/fatedier/frp/blob/dev/doc/pic/architecture.png\">architecture</a></p>\n<h1 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h1><ol>\n<li>Download the latest programs from <a href=\"https://github.com/fatedier/frp/releases\">Release</a> page according to your operating system and architecture.</li>\n</ol>\n<p>There is a example:</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> wget https://github.com/fatedier/frp/releases/download/v0.34.0/frp_0.34.0_linux_amd64.tar.gz</span></span><br><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> tar -xzf frp_0.34.0_linux_amd64.tar.gz</span></span><br><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> frp_0.34.0_linux_amd64</span></span><br><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> ls</span></span><br><span class=\"line\">frpc  frpc_full.ini  frpc.ini  frps  frps_full.ini  frps.ini  LICENSE  systemd</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>Put frps and frps.ini onto your server A (usually is cloud VM) with public IP.<br>There is a example:<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yanboyang713@boyang:~/Downloads/frp_0.34.0_linux_amd64$ sftp boyyan@52.141.58.83</span><br><span class=\"line\">boyyan@52.141.58.83&#x27;s password: </span><br><span class=\"line\">Connected to 52.141.58.83.</span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> ls</span></span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> lls</span></span><br><span class=\"line\">frpc  frpc_full.ini  frpc.ini  frps  frps_full.ini  frps.ini  LICENSE  systemd</span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> put frps.ini</span></span><br><span class=\"line\">Uploading frps to /home/boyyan/frps.ini</span><br><span class=\"line\">frps.ini  </span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> put frps</span></span><br><span class=\"line\">Uploading frps to /home/boyyan/frps</span><br><span class=\"line\">frps                                                               100%   13MB   7.4MB/s   00:01    </span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> ls</span></span><br><span class=\"line\">frps      frps.ini  </span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> <span class=\"built_in\">exit</span></span></span><br></pre></td></tr></table></figure></li>\n<li>Put frpc and frpc.ini onto your server B in LAN (that can’t be connected from public Internet).</li>\n</ol>\n<h1 id=\"Access-your-computer-in-LAN-by-SSH\"><a href=\"#Access-your-computer-in-LAN-by-SSH\" class=\"headerlink\" title=\"Access your computer in LAN by SSH\"></a>Access your computer in LAN by SSH</h1><ol>\n<li>Modify frps.ini on server A and set the bind_port to be connected to frp clients:<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[common]</span><br><span class=\"line\">bind_port &#x3D; 7000</span><br></pre></td></tr></table></figure></li>\n<li>Start frps on server A:<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./frps -c ./frps.ini</span><br></pre></td></tr></table></figure></li>\n<li>On server B, modify frpc.ini to put in your frps server public IP as server_addr field:<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[common]</span><br><span class=\"line\">server_addr &#x3D; 20.194.22.192</span><br><span class=\"line\">server_port &#x3D; 7000</span><br><span class=\"line\"></span><br><span class=\"line\">[ssh]</span><br><span class=\"line\">type &#x3D; tcp</span><br><span class=\"line\">local_ip &#x3D; 127.0.0.1</span><br><span class=\"line\">local_port &#x3D; 22</span><br><span class=\"line\">remote_port &#x3D; 6000</span><br></pre></td></tr></table></figure></li>\n</ol>\n<p><strong>Note</strong> that local_port (listened on client) and remote_port (exposed on server) are for traffic goes in/out the frp system, whereas server_port is used between frps.</p>\n<ol start=\"4\">\n<li>Start frpc on server B:<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.&#x2F;frpc -c .&#x2F;frpc.ini</span><br></pre></td></tr></table></figure></li>\n<li>From another machine, SSH to server B like this (assuming that username is test):<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -oPort=6000 test@x.x.x.x</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"What-is-frp\"><a href=\"#What-is-frp\" class=\"headerlink\" title=\"What is frp?\"></a>What is frp?</h1><p>frp is a fast reverse proxy to help you expose a local server behind a NAT or firewall to the Internet. As of now, it supports TCP and UDP, as well as HTTP and HTTPS protocols, where requests can be forwarded to internal services by domain name.</p>\n<p>frp also has a P2P connect mode.</p>\n<h1 id=\"Architecture\"><a href=\"#Architecture\" class=\"headerlink\" title=\"Architecture\"></a>Architecture</h1><p><a href=\"https://github.com/fatedier/frp/blob/dev/doc/pic/architecture.png\">architecture</a></p>\n<h1 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h1><ol>\n<li>Download the latest programs from <a href=\"https://github.com/fatedier/frp/releases\">Release</a> page according to your operating system and architecture.</li>\n</ol>\n<p>There is a example:</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> wget https://github.com/fatedier/frp/releases/download/v0.34.0/frp_0.34.0_linux_amd64.tar.gz</span></span><br><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> tar -xzf frp_0.34.0_linux_amd64.tar.gz</span></span><br><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> frp_0.34.0_linux_amd64</span></span><br><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> ls</span></span><br><span class=\"line\">frpc  frpc_full.ini  frpc.ini  frps  frps_full.ini  frps.ini  LICENSE  systemd</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>Put frps and frps.ini onto your server A (usually is cloud VM) with public IP.<br>There is a example:<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yanboyang713@boyang:~/Downloads/frp_0.34.0_linux_amd64$ sftp boyyan@52.141.58.83</span><br><span class=\"line\">boyyan@52.141.58.83&#x27;s password: </span><br><span class=\"line\">Connected to 52.141.58.83.</span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> ls</span></span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> lls</span></span><br><span class=\"line\">frpc  frpc_full.ini  frpc.ini  frps  frps_full.ini  frps.ini  LICENSE  systemd</span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> put frps.ini</span></span><br><span class=\"line\">Uploading frps to /home/boyyan/frps.ini</span><br><span class=\"line\">frps.ini  </span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> put frps</span></span><br><span class=\"line\">Uploading frps to /home/boyyan/frps</span><br><span class=\"line\">frps                                                               100%   13MB   7.4MB/s   00:01    </span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> ls</span></span><br><span class=\"line\">frps      frps.ini  </span><br><span class=\"line\"><span class=\"meta\">sftp&gt;</span><span class=\"bash\"> <span class=\"built_in\">exit</span></span></span><br></pre></td></tr></table></figure></li>\n<li>Put frpc and frpc.ini onto your server B in LAN (that can’t be connected from public Internet).</li>\n</ol>\n<h1 id=\"Access-your-computer-in-LAN-by-SSH\"><a href=\"#Access-your-computer-in-LAN-by-SSH\" class=\"headerlink\" title=\"Access your computer in LAN by SSH\"></a>Access your computer in LAN by SSH</h1><ol>\n<li>Modify frps.ini on server A and set the bind_port to be connected to frp clients:<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[common]</span><br><span class=\"line\">bind_port &#x3D; 7000</span><br></pre></td></tr></table></figure></li>\n<li>Start frps on server A:<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./frps -c ./frps.ini</span><br></pre></td></tr></table></figure></li>\n<li>On server B, modify frpc.ini to put in your frps server public IP as server_addr field:<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[common]</span><br><span class=\"line\">server_addr &#x3D; 20.194.22.192</span><br><span class=\"line\">server_port &#x3D; 7000</span><br><span class=\"line\"></span><br><span class=\"line\">[ssh]</span><br><span class=\"line\">type &#x3D; tcp</span><br><span class=\"line\">local_ip &#x3D; 127.0.0.1</span><br><span class=\"line\">local_port &#x3D; 22</span><br><span class=\"line\">remote_port &#x3D; 6000</span><br></pre></td></tr></table></figure></li>\n</ol>\n<p><strong>Note</strong> that local_port (listened on client) and remote_port (exposed on server) are for traffic goes in/out the frp system, whereas server_port is used between frps.</p>\n<ol start=\"4\">\n<li>Start frpc on server B:<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.&#x2F;frpc -c .&#x2F;frpc.ini</span><br></pre></td></tr></table></figure></li>\n<li>From another machine, SSH to server B like this (assuming that username is test):<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -oPort=6000 test@x.x.x.x</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n"},{"title":"linux basic commands and common tools","date":"2020-09-16T20:22:04.000Z","_content":"# Hardware Information\nThere are plenty of commands to check information about the hardware of Linux system. Some commands report only specific hardware components like CPU or memory while the rest cover multiple hardware units. This section will look at some of the most commonly used commands to check information and configuration details about various hardware peripherals and devices.\n\nThe list includes lscpu, hwinfo, lshw, dmidecode, lspci etc.\n\n## lscpu\nThe lscpu command reports information about the cpu and processing units. It does not have any further options or functionality.\n\n``` console\n$ lscpu\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              8\nOn-line CPU(s) list: 0-7\nThread(s) per core:  1\nCore(s) per socket:  8\nSocket(s):           1\nNUMA node(s):        1\nVendor ID:           GenuineIntel\nCPU family:          6\nModel:               158\nModel name:          Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\nStepping:            13\nCPU MHz:             3710.930\nCPU max MHz:         4700.0000\nCPU min MHz:         800.0000\nBogoMIPS:            6000.00\nVirtualization:      VT-x\nL1d cache:           32K\nL1i cache:           32K\nL2 cache:            256K\nL3 cache:            12288K\nNUMA node0 CPU(s):   0-7\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilities\n\n```\n\n## lshw - List Hardware\nA general purpose utility, that reports detailed and brief information about multiple different hardware units such as cpu, memory, disk, usb controllers, network adapters etc. Lshw extracts the information from different /proc files.\n\n### Display Full Information\nRunning lshw without any options would generate full information report about all detected hardware. It would generate a big output with quite a lot of technical details.\n\n``` bash\nsudo lshw\n```\n### Display information in short\nWith the \"-short\" the lshw command would generate a brief information report about the hardware devices that would quickly give an idea about the hardware profile of the system.\n\n``` console\nyanboyang713@boyang$ sudo lshw -short\nH/W path         Device    Class          Description\n=====================================================\n                           system         MS-7C22 (Default string)\n/0                         bus            Z390 PLUS (MS-7C22)\n/0/0                       memory         64KiB BIOS\n/0/39                      memory         16GiB System Memory\n/0/39/0                    memory         [empty]\n/0/39/1                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)\n/0/39/2                    memory         [empty]\n/0/39/3                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)\n/0/43                      memory         512KiB L1 cache\n/0/44                      memory         2MiB L2 cache\n/0/45                      memory         12MiB L3 cache\n/0/46                      processor      Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\n/0/100                     bridge         Intel Corporation\n/0/100/1                   bridge         Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Cont\n/0/100/1/0                 display        NVIDIA Corporation\n/0/100/1/0.1               multimedia     NVIDIA Corporation\n/0/100/1/0.2               bus            NVIDIA Corporation\n/0/100/1/0.2/0   usb3      bus            xHCI Host Controller\n/0/100/1/0.2/1   usb4      bus            xHCI Host Controller\n/0/100/1/0.3               bus            NVIDIA Corporation\n/0/100/8                   generic        Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th Gen Core Processo\n/0/100/12                  generic        Cannon Lake PCH Thermal Controller\n/0/100/14                  bus            Cannon Lake PCH USB 3.1 xHCI Host Controller\n/0/100/14/0      usb1      bus            xHCI Host Controller\n/0/100/14/0/2              input          HP Basic USB Keyboard\n/0/100/14/0/8              input          2.4G Mouse\n/0/100/14/1      usb2      bus            xHCI Host Controller\n/0/100/14.2                memory         RAM memory\n/0/100/16                  communication  Cannon Lake PCH HECI Controller\n/0/100/17                  storage        Cannon Lake PCH SATA AHCI Controller\n/0/100/1b                  bridge         Intel Corporation\n/0/100/1b.4                bridge         Cannon Lake PCH PCI Express Root Port 21\n/0/100/1b.4/0    enp3s0f0  network        I350 Gigabit Network Connection\n/0/100/1b.4/0.1  enp3s0f1  network        I350 Gigabit Network Connection\n/0/100/1b.4/0.2  enp3s0f2  network        I350 Gigabit Network Connection\n/0/100/1b.4/0.3  enp3s0f3  network        I350 Gigabit Network Connection\n/0/100/1c                  bridge         Intel Corporation\n/0/100/1c.4                bridge         Intel Corporation\n/0/100/1c.4/0    enp5s0    network        RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller\n/0/100/1d                  bridge         Cannon Lake PCH PCI Express Root Port 9\n/0/100/1d/0                storage        Micron/Crucial Technology\n/0/100/1f                  bridge         Intel Corporation\n/0/100/1f.3                multimedia     Cannon Lake PCH cAVS\n/0/100/1f.4                bus            Cannon Lake PCH SMBus Controller\n/0/100/1f.5                bus            Cannon Lake PCH SPI Controller\n/1                         power          To Be Filled By O.E.M.\n/2               docker0   network        Ethernet interface\n/3               br0       network        Ethernet interface\n```\n### Display only memory information\nTo display information about the memory, specify the memory class.\n\n``` console\nyanboyang713@boyang $ sudo lshw -short -class memory\nH/W path         Device    Class          Description\n=====================================================\n/0/0                       memory         64KiB BIOS\n/0/39                      memory         16GiB System Memory\n/0/39/0                    memory         [empty]\n/0/39/1                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)\n/0/39/2                    memory         [empty]\n/0/39/3                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)\n/0/43                      memory         512KiB L1 cache\n/0/44                      memory         2MiB L2 cache\n/0/45                      memory         12MiB L3 cache\n/0/100/14.2                memory         RAM memory\n```\n\n### Display processor information\nWith class processor, lshw would display information about the cpu. It is better to not use the short option and get full details about the processor.\n\n``` console\nyanboyang713@boyang$ sudo lshw -class processor\n  *-cpu                     \n       description: CPU\n       product: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\n       vendor: Intel Corp.\n       physical id: 46\n       bus info: cpu@0\n       version: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\n       serial: To Be Filled By O.E.M.\n       slot: U3E1\n       size: 4631MHz\n       capacity: 4700MHz\n       width: 64 bits\n       clock: 100MHz\n       capabilities: x86-64 fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilities cpufreq\n       configuration: cores=8 enabledcores=8 threads=8\n```\n\nIt should be noted that lshw does not accurately tell about the number of cores or processing units available. The above system for example is a quadcore processor with 4 processing units. Another command called lscpu gives more accurate information about the cpu.\n\n### Disk drives\nDisplay the disk drives with the disk class.\n\n``` bash\nsudo lshw -short -class disk\n```\n\nTo display information about the partitions and controllers also, specify the storage and volume class along with the disk class. Then it would give a more clear picture about the storage on the system.\n\n```bash\nsudo lshw -short -class disk -class storage -class volume\n```\n### Network adapter information\nUse the network class to display information about the network adapter/interface. Omitting the short option is a good idea to get detailed information about it.\n\n``` bash\nsudo lshw -class network\n```\nThe value of the \"serial\" field is same as the MAC address. The configuration field indicates that autonegotiation is turned on and the current operating speed is 100Mbit/s. These configurations can be modified with the ethtool command.\n\n### Display address details with businfo\n\nWith the businfo option lshw would output the address details of pci, usb, scsi and ide devices.\n\n```bash\nsudo lshw -businfo\n```\nThe output is similar to \"short\" option, with the first column replaced with Bus Info.\n\n### Generate report in html/xml format\nLshw is capable of producing reports in html, xml and json formats.\n```bash\n$ sudo lshw -html > hardware.html\n```\n\nFor xml format\n```bash\n$ sudo lshw -xml > hardware.xml\n```\n\n## lspci - List PCI\nThe lspci command lists out all the pci buses and details about the devices connected to them.\nThe vga adapter, graphics card, network adapter, usb ports, sata controllers, etc all fall under this category.\n\n``` console\nyanboyang713@boyang$ lspci\n00:00.0 Host bridge: Intel Corporation Device 3e30 (rev 0d)\n00:01.0 PCI bridge: Intel Corporation Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Controller (x16) (rev 0d)\n00:08.0 System peripheral: Intel Corporation Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th Gen Core Processor Gaussian Mixture Model\n00:12.0 Signal processing controller: Intel Corporation Cannon Lake PCH Thermal Controller (rev 10)\n00:14.0 USB controller: Intel Corporation Cannon Lake PCH USB 3.1 xHCI Host Controller (rev 10)\n00:14.2 RAM memory: Intel Corporation Cannon Lake PCH Shared SRAM (rev 10)\n00:16.0 Communication controller: Intel Corporation Cannon Lake PCH HECI Controller (rev 10)\n00:17.0 SATA controller: Intel Corporation Cannon Lake PCH SATA AHCI Controller (rev 10)\n00:1b.0 PCI bridge: Intel Corporation Device a340 (rev f0)\n00:1b.4 PCI bridge: Intel Corporation Cannon Lake PCH PCI Express Root Port 21 (rev f0)\n00:1c.0 PCI bridge: Intel Corporation Device a338 (rev f0)\n00:1c.4 PCI bridge: Intel Corporation Device a33c (rev f0)\n00:1d.0 PCI bridge: Intel Corporation Cannon Lake PCH PCI Express Root Port 9 (rev f0)\n00:1f.0 ISA bridge: Intel Corporation Device a305 (rev 10)\n00:1f.3 Audio device: Intel Corporation Cannon Lake PCH cAVS (rev 10)\n00:1f.4 SMBus: Intel Corporation Cannon Lake PCH SMBus Controller (rev 10)\n00:1f.5 Serial bus controller [0c80]: Intel Corporation Cannon Lake PCH SPI Controller (rev 10)\n01:00.0 VGA compatible controller: NVIDIA Corporation Device 1f02 (rev a1)\n01:00.1 Audio device: NVIDIA Corporation Device 10f9 (rev a1)\n01:00.2 USB controller: NVIDIA Corporation Device 1ada (rev a1)\n01:00.3 Serial bus controller [0c80]: NVIDIA Corporation Device 1adb (rev a1)\n03:00.0 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)\n03:00.1 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)\n03:00.2 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)\n03:00.3 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)\n05:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 15)\n06:00.0 Non-Volatile memory controller: Micron/Crucial Technology Device 2263 (rev 03)\n```\n\nFilter out specific device information with grep.\n\n```bash\n$ lspci -v | grep \"VGA\" -A 12\n```\n\n## lsscsi - List scsi devices\nLists out the scsi/sata devices like hard drives and optical drives.\n```bash\nsudo apt install lsscsi\n```\n\n## lsusb - List usb buses and device details\nThis command shows the USB controllers and details about devices connected to them. By default brief information is printed. Use the verbose option \"-v\" to print detailed information about each usb port\n\n```bash\n$ lsusb\n```\nOn the above system, 1 usb port is being used by the mouse.\n\n## Inxi\nInxi is a 10K line mega bash script that fetches hardware details from multiple different sources and commands on the system, and generates a beautiful looking report that non technical users can read easily.\n\n```bash\n$ inxi -Fx\n```\n## lsblk - List block devices\nList out information all block devices, which are the hard drive partitions and other storage devices like optical drives and flash drives\n```bash\n$ lsblk\n```\n\n## df - disk space of file systems\n\nReports various partitions, their mount points and the used and available space on each.\n```bash\n$ df -H\n```\n\n## Pydf - Python df\n\nAn improved df version written in python, that displays colored output that looks better than df\n```bash\n$ pydf\n```\n\n## fdisk\n\nFdisk is a utility to modify partitions on hard drives, and can be used to list out the partition information as well.\n```bash\n$ sudo fdisk -l\n```\n\n## mount\n\nThe mount is used to mount/unmount and view mounted file systems.\n```bash\n$ mount | column -t\n```\nAgain, use grep to filter out only those file systems that you want to see\n\n```bash\n$ mount | column -t | grep ext\n```\n\n## free - Check RAM\nCheck the amount of used, free and total amount of RAM on system with the free command.\n```bash\n$ free -m\n```\n\n## dmidecode\n\nThe dmidecode command is different from all other commands. It extracts hardware information by reading data from the SMBOIS data structures (also called DMI tables).\n\n```bash\n# display information about the processor/cpu\n$ sudo dmidecode -t processor\n# memory/ram information\n$ sudo dmidecode -t memory\n# bios details\n$ sudo dmidecode -t bios\n```\n\nCheck out the man page for more details.\n\n# /proc files\n\nMany of the virtual files in the /proc directory contain information about hardware and configurations. Here are some of them\n\nCPU/Memory information\n\n```bash\n# cpu information\n$ cat /proc/cpuinfo\n# memory information\n$ cat /proc/meminfo\n```\n\nLinux/kernel information\n\n```bash\n$ cat /proc/version\nLinux version 3.11.0-12-generic (buildd@allspice) (gcc version 4.8.1 (Ubuntu/Linaro 4.8.1-10ubuntu7) ) #19-Ubuntu SMP Wed Oct 9 16:20:46 UTC 2013\n```\n\nSCSI/Sata devices\n\n```bash\n$ cat /proc/scsi/scsi\n```\n\nPartitions\n\n```bash\n$ cat /proc/partitions\n```\n\n## hdparm\n\nThe hdparm command gets information about sata devices like hard disks.\n```bash\n$ sudo hdparm -i /dev/sda\n```\n\n","source":"_posts/linux.md","raw":"---\ntitle: linux basic commands and common tools\ndate: 2020-09-16 20:22:04\ntags:\n - Linux command\n---\n# Hardware Information\nThere are plenty of commands to check information about the hardware of Linux system. Some commands report only specific hardware components like CPU or memory while the rest cover multiple hardware units. This section will look at some of the most commonly used commands to check information and configuration details about various hardware peripherals and devices.\n\nThe list includes lscpu, hwinfo, lshw, dmidecode, lspci etc.\n\n## lscpu\nThe lscpu command reports information about the cpu and processing units. It does not have any further options or functionality.\n\n``` console\n$ lscpu\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              8\nOn-line CPU(s) list: 0-7\nThread(s) per core:  1\nCore(s) per socket:  8\nSocket(s):           1\nNUMA node(s):        1\nVendor ID:           GenuineIntel\nCPU family:          6\nModel:               158\nModel name:          Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\nStepping:            13\nCPU MHz:             3710.930\nCPU max MHz:         4700.0000\nCPU min MHz:         800.0000\nBogoMIPS:            6000.00\nVirtualization:      VT-x\nL1d cache:           32K\nL1i cache:           32K\nL2 cache:            256K\nL3 cache:            12288K\nNUMA node0 CPU(s):   0-7\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilities\n\n```\n\n## lshw - List Hardware\nA general purpose utility, that reports detailed and brief information about multiple different hardware units such as cpu, memory, disk, usb controllers, network adapters etc. Lshw extracts the information from different /proc files.\n\n### Display Full Information\nRunning lshw without any options would generate full information report about all detected hardware. It would generate a big output with quite a lot of technical details.\n\n``` bash\nsudo lshw\n```\n### Display information in short\nWith the \"-short\" the lshw command would generate a brief information report about the hardware devices that would quickly give an idea about the hardware profile of the system.\n\n``` console\nyanboyang713@boyang$ sudo lshw -short\nH/W path         Device    Class          Description\n=====================================================\n                           system         MS-7C22 (Default string)\n/0                         bus            Z390 PLUS (MS-7C22)\n/0/0                       memory         64KiB BIOS\n/0/39                      memory         16GiB System Memory\n/0/39/0                    memory         [empty]\n/0/39/1                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)\n/0/39/2                    memory         [empty]\n/0/39/3                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)\n/0/43                      memory         512KiB L1 cache\n/0/44                      memory         2MiB L2 cache\n/0/45                      memory         12MiB L3 cache\n/0/46                      processor      Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\n/0/100                     bridge         Intel Corporation\n/0/100/1                   bridge         Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Cont\n/0/100/1/0                 display        NVIDIA Corporation\n/0/100/1/0.1               multimedia     NVIDIA Corporation\n/0/100/1/0.2               bus            NVIDIA Corporation\n/0/100/1/0.2/0   usb3      bus            xHCI Host Controller\n/0/100/1/0.2/1   usb4      bus            xHCI Host Controller\n/0/100/1/0.3               bus            NVIDIA Corporation\n/0/100/8                   generic        Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th Gen Core Processo\n/0/100/12                  generic        Cannon Lake PCH Thermal Controller\n/0/100/14                  bus            Cannon Lake PCH USB 3.1 xHCI Host Controller\n/0/100/14/0      usb1      bus            xHCI Host Controller\n/0/100/14/0/2              input          HP Basic USB Keyboard\n/0/100/14/0/8              input          2.4G Mouse\n/0/100/14/1      usb2      bus            xHCI Host Controller\n/0/100/14.2                memory         RAM memory\n/0/100/16                  communication  Cannon Lake PCH HECI Controller\n/0/100/17                  storage        Cannon Lake PCH SATA AHCI Controller\n/0/100/1b                  bridge         Intel Corporation\n/0/100/1b.4                bridge         Cannon Lake PCH PCI Express Root Port 21\n/0/100/1b.4/0    enp3s0f0  network        I350 Gigabit Network Connection\n/0/100/1b.4/0.1  enp3s0f1  network        I350 Gigabit Network Connection\n/0/100/1b.4/0.2  enp3s0f2  network        I350 Gigabit Network Connection\n/0/100/1b.4/0.3  enp3s0f3  network        I350 Gigabit Network Connection\n/0/100/1c                  bridge         Intel Corporation\n/0/100/1c.4                bridge         Intel Corporation\n/0/100/1c.4/0    enp5s0    network        RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller\n/0/100/1d                  bridge         Cannon Lake PCH PCI Express Root Port 9\n/0/100/1d/0                storage        Micron/Crucial Technology\n/0/100/1f                  bridge         Intel Corporation\n/0/100/1f.3                multimedia     Cannon Lake PCH cAVS\n/0/100/1f.4                bus            Cannon Lake PCH SMBus Controller\n/0/100/1f.5                bus            Cannon Lake PCH SPI Controller\n/1                         power          To Be Filled By O.E.M.\n/2               docker0   network        Ethernet interface\n/3               br0       network        Ethernet interface\n```\n### Display only memory information\nTo display information about the memory, specify the memory class.\n\n``` console\nyanboyang713@boyang $ sudo lshw -short -class memory\nH/W path         Device    Class          Description\n=====================================================\n/0/0                       memory         64KiB BIOS\n/0/39                      memory         16GiB System Memory\n/0/39/0                    memory         [empty]\n/0/39/1                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)\n/0/39/2                    memory         [empty]\n/0/39/3                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)\n/0/43                      memory         512KiB L1 cache\n/0/44                      memory         2MiB L2 cache\n/0/45                      memory         12MiB L3 cache\n/0/100/14.2                memory         RAM memory\n```\n\n### Display processor information\nWith class processor, lshw would display information about the cpu. It is better to not use the short option and get full details about the processor.\n\n``` console\nyanboyang713@boyang$ sudo lshw -class processor\n  *-cpu                     \n       description: CPU\n       product: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\n       vendor: Intel Corp.\n       physical id: 46\n       bus info: cpu@0\n       version: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\n       serial: To Be Filled By O.E.M.\n       slot: U3E1\n       size: 4631MHz\n       capacity: 4700MHz\n       width: 64 bits\n       clock: 100MHz\n       capabilities: x86-64 fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilities cpufreq\n       configuration: cores=8 enabledcores=8 threads=8\n```\n\nIt should be noted that lshw does not accurately tell about the number of cores or processing units available. The above system for example is a quadcore processor with 4 processing units. Another command called lscpu gives more accurate information about the cpu.\n\n### Disk drives\nDisplay the disk drives with the disk class.\n\n``` bash\nsudo lshw -short -class disk\n```\n\nTo display information about the partitions and controllers also, specify the storage and volume class along with the disk class. Then it would give a more clear picture about the storage on the system.\n\n```bash\nsudo lshw -short -class disk -class storage -class volume\n```\n### Network adapter information\nUse the network class to display information about the network adapter/interface. Omitting the short option is a good idea to get detailed information about it.\n\n``` bash\nsudo lshw -class network\n```\nThe value of the \"serial\" field is same as the MAC address. The configuration field indicates that autonegotiation is turned on and the current operating speed is 100Mbit/s. These configurations can be modified with the ethtool command.\n\n### Display address details with businfo\n\nWith the businfo option lshw would output the address details of pci, usb, scsi and ide devices.\n\n```bash\nsudo lshw -businfo\n```\nThe output is similar to \"short\" option, with the first column replaced with Bus Info.\n\n### Generate report in html/xml format\nLshw is capable of producing reports in html, xml and json formats.\n```bash\n$ sudo lshw -html > hardware.html\n```\n\nFor xml format\n```bash\n$ sudo lshw -xml > hardware.xml\n```\n\n## lspci - List PCI\nThe lspci command lists out all the pci buses and details about the devices connected to them.\nThe vga adapter, graphics card, network adapter, usb ports, sata controllers, etc all fall under this category.\n\n``` console\nyanboyang713@boyang$ lspci\n00:00.0 Host bridge: Intel Corporation Device 3e30 (rev 0d)\n00:01.0 PCI bridge: Intel Corporation Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Controller (x16) (rev 0d)\n00:08.0 System peripheral: Intel Corporation Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th Gen Core Processor Gaussian Mixture Model\n00:12.0 Signal processing controller: Intel Corporation Cannon Lake PCH Thermal Controller (rev 10)\n00:14.0 USB controller: Intel Corporation Cannon Lake PCH USB 3.1 xHCI Host Controller (rev 10)\n00:14.2 RAM memory: Intel Corporation Cannon Lake PCH Shared SRAM (rev 10)\n00:16.0 Communication controller: Intel Corporation Cannon Lake PCH HECI Controller (rev 10)\n00:17.0 SATA controller: Intel Corporation Cannon Lake PCH SATA AHCI Controller (rev 10)\n00:1b.0 PCI bridge: Intel Corporation Device a340 (rev f0)\n00:1b.4 PCI bridge: Intel Corporation Cannon Lake PCH PCI Express Root Port 21 (rev f0)\n00:1c.0 PCI bridge: Intel Corporation Device a338 (rev f0)\n00:1c.4 PCI bridge: Intel Corporation Device a33c (rev f0)\n00:1d.0 PCI bridge: Intel Corporation Cannon Lake PCH PCI Express Root Port 9 (rev f0)\n00:1f.0 ISA bridge: Intel Corporation Device a305 (rev 10)\n00:1f.3 Audio device: Intel Corporation Cannon Lake PCH cAVS (rev 10)\n00:1f.4 SMBus: Intel Corporation Cannon Lake PCH SMBus Controller (rev 10)\n00:1f.5 Serial bus controller [0c80]: Intel Corporation Cannon Lake PCH SPI Controller (rev 10)\n01:00.0 VGA compatible controller: NVIDIA Corporation Device 1f02 (rev a1)\n01:00.1 Audio device: NVIDIA Corporation Device 10f9 (rev a1)\n01:00.2 USB controller: NVIDIA Corporation Device 1ada (rev a1)\n01:00.3 Serial bus controller [0c80]: NVIDIA Corporation Device 1adb (rev a1)\n03:00.0 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)\n03:00.1 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)\n03:00.2 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)\n03:00.3 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)\n05:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 15)\n06:00.0 Non-Volatile memory controller: Micron/Crucial Technology Device 2263 (rev 03)\n```\n\nFilter out specific device information with grep.\n\n```bash\n$ lspci -v | grep \"VGA\" -A 12\n```\n\n## lsscsi - List scsi devices\nLists out the scsi/sata devices like hard drives and optical drives.\n```bash\nsudo apt install lsscsi\n```\n\n## lsusb - List usb buses and device details\nThis command shows the USB controllers and details about devices connected to them. By default brief information is printed. Use the verbose option \"-v\" to print detailed information about each usb port\n\n```bash\n$ lsusb\n```\nOn the above system, 1 usb port is being used by the mouse.\n\n## Inxi\nInxi is a 10K line mega bash script that fetches hardware details from multiple different sources and commands on the system, and generates a beautiful looking report that non technical users can read easily.\n\n```bash\n$ inxi -Fx\n```\n## lsblk - List block devices\nList out information all block devices, which are the hard drive partitions and other storage devices like optical drives and flash drives\n```bash\n$ lsblk\n```\n\n## df - disk space of file systems\n\nReports various partitions, their mount points and the used and available space on each.\n```bash\n$ df -H\n```\n\n## Pydf - Python df\n\nAn improved df version written in python, that displays colored output that looks better than df\n```bash\n$ pydf\n```\n\n## fdisk\n\nFdisk is a utility to modify partitions on hard drives, and can be used to list out the partition information as well.\n```bash\n$ sudo fdisk -l\n```\n\n## mount\n\nThe mount is used to mount/unmount and view mounted file systems.\n```bash\n$ mount | column -t\n```\nAgain, use grep to filter out only those file systems that you want to see\n\n```bash\n$ mount | column -t | grep ext\n```\n\n## free - Check RAM\nCheck the amount of used, free and total amount of RAM on system with the free command.\n```bash\n$ free -m\n```\n\n## dmidecode\n\nThe dmidecode command is different from all other commands. It extracts hardware information by reading data from the SMBOIS data structures (also called DMI tables).\n\n```bash\n# display information about the processor/cpu\n$ sudo dmidecode -t processor\n# memory/ram information\n$ sudo dmidecode -t memory\n# bios details\n$ sudo dmidecode -t bios\n```\n\nCheck out the man page for more details.\n\n# /proc files\n\nMany of the virtual files in the /proc directory contain information about hardware and configurations. Here are some of them\n\nCPU/Memory information\n\n```bash\n# cpu information\n$ cat /proc/cpuinfo\n# memory information\n$ cat /proc/meminfo\n```\n\nLinux/kernel information\n\n```bash\n$ cat /proc/version\nLinux version 3.11.0-12-generic (buildd@allspice) (gcc version 4.8.1 (Ubuntu/Linaro 4.8.1-10ubuntu7) ) #19-Ubuntu SMP Wed Oct 9 16:20:46 UTC 2013\n```\n\nSCSI/Sata devices\n\n```bash\n$ cat /proc/scsi/scsi\n```\n\nPartitions\n\n```bash\n$ cat /proc/partitions\n```\n\n## hdparm\n\nThe hdparm command gets information about sata devices like hard disks.\n```bash\n$ sudo hdparm -i /dev/sda\n```\n\n","slug":"linux","published":1,"updated":"2020-09-24T10:52:21.897Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aiz000niiiy2s1dfcpd","content":"<h1 id=\"Hardware-Information\"><a href=\"#Hardware-Information\" class=\"headerlink\" title=\"Hardware Information\"></a>Hardware Information</h1><p>There are plenty of commands to check information about the hardware of Linux system. Some commands report only specific hardware components like CPU or memory while the rest cover multiple hardware units. This section will look at some of the most commonly used commands to check information and configuration details about various hardware peripherals and devices.</p>\n<p>The list includes lscpu, hwinfo, lshw, dmidecode, lspci etc.</p>\n<h2 id=\"lscpu\"><a href=\"#lscpu\" class=\"headerlink\" title=\"lscpu\"></a>lscpu</h2><p>The lscpu command reports information about the cpu and processing units. It does not have any further options or functionality.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> lscpu</span></span><br><span class=\"line\">Architecture:        x86_64</span><br><span class=\"line\">CPU op-mode(s):      32-bit, 64-bit</span><br><span class=\"line\">Byte Order:          Little Endian</span><br><span class=\"line\">CPU(s):              8</span><br><span class=\"line\">On-line CPU(s) list: 0-7</span><br><span class=\"line\">Thread(s) per core:  1</span><br><span class=\"line\">Core(s) per socket:  8</span><br><span class=\"line\">Socket(s):           1</span><br><span class=\"line\">NUMA node(s):        1</span><br><span class=\"line\">Vendor ID:           GenuineIntel</span><br><span class=\"line\">CPU family:          6</span><br><span class=\"line\">Model:               158</span><br><span class=\"line\">Model name:          Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</span><br><span class=\"line\">Stepping:            13</span><br><span class=\"line\">CPU MHz:             3710.930</span><br><span class=\"line\">CPU max MHz:         4700.0000</span><br><span class=\"line\">CPU min MHz:         800.0000</span><br><span class=\"line\">BogoMIPS:            6000.00</span><br><span class=\"line\">Virtualization:      VT-x</span><br><span class=\"line\">L1d cache:           32K</span><br><span class=\"line\">L1i cache:           32K</span><br><span class=\"line\">L2 cache:            256K</span><br><span class=\"line\">L3 cache:            12288K</span><br><span class=\"line\">NUMA node0 CPU(s):   0-7</span><br><span class=\"line\">Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilities</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"lshw-List-Hardware\"><a href=\"#lshw-List-Hardware\" class=\"headerlink\" title=\"lshw - List Hardware\"></a>lshw - List Hardware</h2><p>A general purpose utility, that reports detailed and brief information about multiple different hardware units such as cpu, memory, disk, usb controllers, network adapters etc. Lshw extracts the information from different /proc files.</p>\n<h3 id=\"Display-Full-Information\"><a href=\"#Display-Full-Information\" class=\"headerlink\" title=\"Display Full Information\"></a>Display Full Information</h3><p>Running lshw without any options would generate full information report about all detected hardware. It would generate a big output with quite a lot of technical details.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw</span><br></pre></td></tr></table></figure>\n<h3 id=\"Display-information-in-short\"><a href=\"#Display-information-in-short\" class=\"headerlink\" title=\"Display information in short\"></a>Display information in short</h3><p>With the “-short” the lshw command would generate a brief information report about the hardware devices that would quickly give an idea about the hardware profile of the system.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> sudo lshw -short</span></span><br><span class=\"line\">H/W path         Device    Class          Description</span><br><span class=\"line\">=====================================================</span><br><span class=\"line\">                           system         MS-7C22 (Default string)</span><br><span class=\"line\">/0                         bus            Z390 PLUS (MS-7C22)</span><br><span class=\"line\">/0/0                       memory         64KiB BIOS</span><br><span class=\"line\">/0/39                      memory         16GiB System Memory</span><br><span class=\"line\">/0/39/0                    memory         [empty]</span><br><span class=\"line\">/0/39/1                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)</span><br><span class=\"line\">/0/39/2                    memory         [empty]</span><br><span class=\"line\">/0/39/3                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)</span><br><span class=\"line\">/0/43                      memory         512KiB L1 cache</span><br><span class=\"line\">/0/44                      memory         2MiB L2 cache</span><br><span class=\"line\">/0/45                      memory         12MiB L3 cache</span><br><span class=\"line\">/0/46                      processor      Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</span><br><span class=\"line\">/0/100                     bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1                   bridge         Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Cont</span><br><span class=\"line\">/0/100/1/0                 display        NVIDIA Corporation</span><br><span class=\"line\">/0/100/1/0.1               multimedia     NVIDIA Corporation</span><br><span class=\"line\">/0/100/1/0.2               bus            NVIDIA Corporation</span><br><span class=\"line\">/0/100/1/0.2/0   usb3      bus            xHCI Host Controller</span><br><span class=\"line\">/0/100/1/0.2/1   usb4      bus            xHCI Host Controller</span><br><span class=\"line\">/0/100/1/0.3               bus            NVIDIA Corporation</span><br><span class=\"line\">/0/100/8                   generic        Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th Gen Core Processo</span><br><span class=\"line\">/0/100/12                  generic        Cannon Lake PCH Thermal Controller</span><br><span class=\"line\">/0/100/14                  bus            Cannon Lake PCH USB 3.1 xHCI Host Controller</span><br><span class=\"line\">/0/100/14/0      usb1      bus            xHCI Host Controller</span><br><span class=\"line\">/0/100/14/0/2              input          HP Basic USB Keyboard</span><br><span class=\"line\">/0/100/14/0/8              input          2.4G Mouse</span><br><span class=\"line\">/0/100/14/1      usb2      bus            xHCI Host Controller</span><br><span class=\"line\">/0/100/14.2                memory         RAM memory</span><br><span class=\"line\">/0/100/16                  communication  Cannon Lake PCH HECI Controller</span><br><span class=\"line\">/0/100/17                  storage        Cannon Lake PCH SATA AHCI Controller</span><br><span class=\"line\">/0/100/1b                  bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1b.4                bridge         Cannon Lake PCH PCI Express Root Port 21</span><br><span class=\"line\">/0/100/1b.4/0    enp3s0f0  network        I350 Gigabit Network Connection</span><br><span class=\"line\">/0/100/1b.4/0.1  enp3s0f1  network        I350 Gigabit Network Connection</span><br><span class=\"line\">/0/100/1b.4/0.2  enp3s0f2  network        I350 Gigabit Network Connection</span><br><span class=\"line\">/0/100/1b.4/0.3  enp3s0f3  network        I350 Gigabit Network Connection</span><br><span class=\"line\">/0/100/1c                  bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1c.4                bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1c.4/0    enp5s0    network        RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller</span><br><span class=\"line\">/0/100/1d                  bridge         Cannon Lake PCH PCI Express Root Port 9</span><br><span class=\"line\">/0/100/1d/0                storage        Micron/Crucial Technology</span><br><span class=\"line\">/0/100/1f                  bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1f.3                multimedia     Cannon Lake PCH cAVS</span><br><span class=\"line\">/0/100/1f.4                bus            Cannon Lake PCH SMBus Controller</span><br><span class=\"line\">/0/100/1f.5                bus            Cannon Lake PCH SPI Controller</span><br><span class=\"line\">/1                         power          To Be Filled By O.E.M.</span><br><span class=\"line\">/2               docker0   network        Ethernet interface</span><br><span class=\"line\">/3               br0       network        Ethernet interface</span><br></pre></td></tr></table></figure>\n<h3 id=\"Display-only-memory-information\"><a href=\"#Display-only-memory-information\" class=\"headerlink\" title=\"Display only memory information\"></a>Display only memory information</h3><p>To display information about the memory, specify the memory class.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yanboyang713@boyang $ sudo lshw -short -class memory</span><br><span class=\"line\">H/W path         Device    Class          Description</span><br><span class=\"line\">=====================================================</span><br><span class=\"line\">/0/0                       memory         64KiB BIOS</span><br><span class=\"line\">/0/39                      memory         16GiB System Memory</span><br><span class=\"line\">/0/39/0                    memory         [empty]</span><br><span class=\"line\">/0/39/1                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)</span><br><span class=\"line\">/0/39/2                    memory         [empty]</span><br><span class=\"line\">/0/39/3                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)</span><br><span class=\"line\">/0/43                      memory         512KiB L1 cache</span><br><span class=\"line\">/0/44                      memory         2MiB L2 cache</span><br><span class=\"line\">/0/45                      memory         12MiB L3 cache</span><br><span class=\"line\">/0/100/14.2                memory         RAM memory</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Display-processor-information\"><a href=\"#Display-processor-information\" class=\"headerlink\" title=\"Display processor information\"></a>Display processor information</h3><p>With class processor, lshw would display information about the cpu. It is better to not use the short option and get full details about the processor.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> sudo lshw -class processor</span></span><br><span class=\"line\">  *-cpu                     </span><br><span class=\"line\">       description: CPU</span><br><span class=\"line\">       product: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</span><br><span class=\"line\">       vendor: Intel Corp.</span><br><span class=\"line\">       physical id: 46</span><br><span class=\"line\">       bus info: cpu@0</span><br><span class=\"line\">       version: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</span><br><span class=\"line\">       serial: To Be Filled By O.E.M.</span><br><span class=\"line\">       slot: U3E1</span><br><span class=\"line\">       size: 4631MHz</span><br><span class=\"line\">       capacity: 4700MHz</span><br><span class=\"line\">       width: 64 bits</span><br><span class=\"line\">       clock: 100MHz</span><br><span class=\"line\">       capabilities: x86-64 fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilities cpufreq</span><br><span class=\"line\">       configuration: cores=8 enabledcores=8 threads=8</span><br></pre></td></tr></table></figure>\n\n<p>It should be noted that lshw does not accurately tell about the number of cores or processing units available. The above system for example is a quadcore processor with 4 processing units. Another command called lscpu gives more accurate information about the cpu.</p>\n<h3 id=\"Disk-drives\"><a href=\"#Disk-drives\" class=\"headerlink\" title=\"Disk drives\"></a>Disk drives</h3><p>Display the disk drives with the disk class.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw -short -class disk</span><br></pre></td></tr></table></figure>\n\n<p>To display information about the partitions and controllers also, specify the storage and volume class along with the disk class. Then it would give a more clear picture about the storage on the system.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw -short -class disk -class storage -class volume</span><br></pre></td></tr></table></figure>\n<h3 id=\"Network-adapter-information\"><a href=\"#Network-adapter-information\" class=\"headerlink\" title=\"Network adapter information\"></a>Network adapter information</h3><p>Use the network class to display information about the network adapter/interface. Omitting the short option is a good idea to get detailed information about it.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw -class network</span><br></pre></td></tr></table></figure>\n<p>The value of the “serial” field is same as the MAC address. The configuration field indicates that autonegotiation is turned on and the current operating speed is 100Mbit/s. These configurations can be modified with the ethtool command.</p>\n<h3 id=\"Display-address-details-with-businfo\"><a href=\"#Display-address-details-with-businfo\" class=\"headerlink\" title=\"Display address details with businfo\"></a>Display address details with businfo</h3><p>With the businfo option lshw would output the address details of pci, usb, scsi and ide devices.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw -businfo</span><br></pre></td></tr></table></figure>\n<p>The output is similar to “short” option, with the first column replaced with Bus Info.</p>\n<h3 id=\"Generate-report-in-html-xml-format\"><a href=\"#Generate-report-in-html-xml-format\" class=\"headerlink\" title=\"Generate report in html/xml format\"></a>Generate report in html/xml format</h3><p>Lshw is capable of producing reports in html, xml and json formats.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo lshw -html &gt; hardware.html</span><br></pre></td></tr></table></figure>\n\n<p>For xml format</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo lshw -xml &gt; hardware.xml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"lspci-List-PCI\"><a href=\"#lspci-List-PCI\" class=\"headerlink\" title=\"lspci - List PCI\"></a>lspci - List PCI</h2><p>The lspci command lists out all the pci buses and details about the devices connected to them.<br>The vga adapter, graphics card, network adapter, usb ports, sata controllers, etc all fall under this category.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> lspci</span></span><br><span class=\"line\">00:00.0 Host bridge: Intel Corporation Device 3e30 (rev 0d)</span><br><span class=\"line\">00:01.0 PCI bridge: Intel Corporation Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Controller (x16) (rev 0d)</span><br><span class=\"line\">00:08.0 System peripheral: Intel Corporation Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th Gen Core Processor Gaussian Mixture Model</span><br><span class=\"line\">00:12.0 Signal processing controller: Intel Corporation Cannon Lake PCH Thermal Controller (rev 10)</span><br><span class=\"line\">00:14.0 USB controller: Intel Corporation Cannon Lake PCH USB 3.1 xHCI Host Controller (rev 10)</span><br><span class=\"line\">00:14.2 RAM memory: Intel Corporation Cannon Lake PCH Shared SRAM (rev 10)</span><br><span class=\"line\">00:16.0 Communication controller: Intel Corporation Cannon Lake PCH HECI Controller (rev 10)</span><br><span class=\"line\">00:17.0 SATA controller: Intel Corporation Cannon Lake PCH SATA AHCI Controller (rev 10)</span><br><span class=\"line\">00:1b.0 PCI bridge: Intel Corporation Device a340 (rev f0)</span><br><span class=\"line\">00:1b.4 PCI bridge: Intel Corporation Cannon Lake PCH PCI Express Root Port 21 (rev f0)</span><br><span class=\"line\">00:1c.0 PCI bridge: Intel Corporation Device a338 (rev f0)</span><br><span class=\"line\">00:1c.4 PCI bridge: Intel Corporation Device a33c (rev f0)</span><br><span class=\"line\">00:1d.0 PCI bridge: Intel Corporation Cannon Lake PCH PCI Express Root Port 9 (rev f0)</span><br><span class=\"line\">00:1f.0 ISA bridge: Intel Corporation Device a305 (rev 10)</span><br><span class=\"line\">00:1f.3 Audio device: Intel Corporation Cannon Lake PCH cAVS (rev 10)</span><br><span class=\"line\">00:1f.4 SMBus: Intel Corporation Cannon Lake PCH SMBus Controller (rev 10)</span><br><span class=\"line\">00:1f.5 Serial bus controller [0c80]: Intel Corporation Cannon Lake PCH SPI Controller (rev 10)</span><br><span class=\"line\">01:00.0 VGA compatible controller: NVIDIA Corporation Device 1f02 (rev a1)</span><br><span class=\"line\">01:00.1 Audio device: NVIDIA Corporation Device 10f9 (rev a1)</span><br><span class=\"line\">01:00.2 USB controller: NVIDIA Corporation Device 1ada (rev a1)</span><br><span class=\"line\">01:00.3 Serial bus controller [0c80]: NVIDIA Corporation Device 1adb (rev a1)</span><br><span class=\"line\">03:00.0 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)</span><br><span class=\"line\">03:00.1 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)</span><br><span class=\"line\">03:00.2 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)</span><br><span class=\"line\">03:00.3 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)</span><br><span class=\"line\">05:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 15)</span><br><span class=\"line\">06:00.0 Non-Volatile memory controller: Micron/Crucial Technology Device 2263 (rev 03)</span><br></pre></td></tr></table></figure>\n\n<p>Filter out specific device information with grep.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lspci -v | grep <span class=\"string\">&quot;VGA&quot;</span> -A 12</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"lsscsi-List-scsi-devices\"><a href=\"#lsscsi-List-scsi-devices\" class=\"headerlink\" title=\"lsscsi - List scsi devices\"></a>lsscsi - List scsi devices</h2><p>Lists out the scsi/sata devices like hard drives and optical drives.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install lsscsi</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"lsusb-List-usb-buses-and-device-details\"><a href=\"#lsusb-List-usb-buses-and-device-details\" class=\"headerlink\" title=\"lsusb - List usb buses and device details\"></a>lsusb - List usb buses and device details</h2><p>This command shows the USB controllers and details about devices connected to them. By default brief information is printed. Use the verbose option “-v” to print detailed information about each usb port</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lsusb</span><br></pre></td></tr></table></figure>\n<p>On the above system, 1 usb port is being used by the mouse.</p>\n<h2 id=\"Inxi\"><a href=\"#Inxi\" class=\"headerlink\" title=\"Inxi\"></a>Inxi</h2><p>Inxi is a 10K line mega bash script that fetches hardware details from multiple different sources and commands on the system, and generates a beautiful looking report that non technical users can read easily.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ inxi -Fx</span><br></pre></td></tr></table></figure>\n<h2 id=\"lsblk-List-block-devices\"><a href=\"#lsblk-List-block-devices\" class=\"headerlink\" title=\"lsblk - List block devices\"></a>lsblk - List block devices</h2><p>List out information all block devices, which are the hard drive partitions and other storage devices like optical drives and flash drives</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lsblk</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"df-disk-space-of-file-systems\"><a href=\"#df-disk-space-of-file-systems\" class=\"headerlink\" title=\"df - disk space of file systems\"></a>df - disk space of file systems</h2><p>Reports various partitions, their mount points and the used and available space on each.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ df -H</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Pydf-Python-df\"><a href=\"#Pydf-Python-df\" class=\"headerlink\" title=\"Pydf - Python df\"></a>Pydf - Python df</h2><p>An improved df version written in python, that displays colored output that looks better than df</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pydf</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fdisk\"><a href=\"#fdisk\" class=\"headerlink\" title=\"fdisk\"></a>fdisk</h2><p>Fdisk is a utility to modify partitions on hard drives, and can be used to list out the partition information as well.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo fdisk -l</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"mount\"><a href=\"#mount\" class=\"headerlink\" title=\"mount\"></a>mount</h2><p>The mount is used to mount/unmount and view mounted file systems.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mount | column -t</span><br></pre></td></tr></table></figure>\n<p>Again, use grep to filter out only those file systems that you want to see</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mount | column -t | grep ext</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"free-Check-RAM\"><a href=\"#free-Check-RAM\" class=\"headerlink\" title=\"free - Check RAM\"></a>free - Check RAM</h2><p>Check the amount of used, free and total amount of RAM on system with the free command.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ free -m</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"dmidecode\"><a href=\"#dmidecode\" class=\"headerlink\" title=\"dmidecode\"></a>dmidecode</h2><p>The dmidecode command is different from all other commands. It extracts hardware information by reading data from the SMBOIS data structures (also called DMI tables).</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># display information about the processor/cpu</span></span><br><span class=\"line\">$ sudo dmidecode -t processor</span><br><span class=\"line\"><span class=\"comment\"># memory/ram information</span></span><br><span class=\"line\">$ sudo dmidecode -t memory</span><br><span class=\"line\"><span class=\"comment\"># bios details</span></span><br><span class=\"line\">$ sudo dmidecode -t bios</span><br></pre></td></tr></table></figure>\n\n<p>Check out the man page for more details.</p>\n<h1 id=\"proc-files\"><a href=\"#proc-files\" class=\"headerlink\" title=\"/proc files\"></a>/proc files</h1><p>Many of the virtual files in the /proc directory contain information about hardware and configurations. Here are some of them</p>\n<p>CPU/Memory information</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># cpu information</span></span><br><span class=\"line\">$ cat /proc/cpuinfo</span><br><span class=\"line\"><span class=\"comment\"># memory information</span></span><br><span class=\"line\">$ cat /proc/meminfo</span><br></pre></td></tr></table></figure>\n\n<p>Linux/kernel information</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat /proc/version</span><br><span class=\"line\">Linux version 3.11.0-12-generic (buildd@allspice) (gcc version 4.8.1 (Ubuntu/Linaro 4.8.1-10ubuntu7) ) <span class=\"comment\">#19-Ubuntu SMP Wed Oct 9 16:20:46 UTC 2013</span></span><br></pre></td></tr></table></figure>\n\n<p>SCSI/Sata devices</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat /proc/scsi/scsi</span><br></pre></td></tr></table></figure>\n\n<p>Partitions</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat /proc/partitions</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"hdparm\"><a href=\"#hdparm\" class=\"headerlink\" title=\"hdparm\"></a>hdparm</h2><p>The hdparm command gets information about sata devices like hard disks.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo hdparm -i /dev/sda</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Hardware-Information\"><a href=\"#Hardware-Information\" class=\"headerlink\" title=\"Hardware Information\"></a>Hardware Information</h1><p>There are plenty of commands to check information about the hardware of Linux system. Some commands report only specific hardware components like CPU or memory while the rest cover multiple hardware units. This section will look at some of the most commonly used commands to check information and configuration details about various hardware peripherals and devices.</p>\n<p>The list includes lscpu, hwinfo, lshw, dmidecode, lspci etc.</p>\n<h2 id=\"lscpu\"><a href=\"#lscpu\" class=\"headerlink\" title=\"lscpu\"></a>lscpu</h2><p>The lscpu command reports information about the cpu and processing units. It does not have any further options or functionality.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> lscpu</span></span><br><span class=\"line\">Architecture:        x86_64</span><br><span class=\"line\">CPU op-mode(s):      32-bit, 64-bit</span><br><span class=\"line\">Byte Order:          Little Endian</span><br><span class=\"line\">CPU(s):              8</span><br><span class=\"line\">On-line CPU(s) list: 0-7</span><br><span class=\"line\">Thread(s) per core:  1</span><br><span class=\"line\">Core(s) per socket:  8</span><br><span class=\"line\">Socket(s):           1</span><br><span class=\"line\">NUMA node(s):        1</span><br><span class=\"line\">Vendor ID:           GenuineIntel</span><br><span class=\"line\">CPU family:          6</span><br><span class=\"line\">Model:               158</span><br><span class=\"line\">Model name:          Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</span><br><span class=\"line\">Stepping:            13</span><br><span class=\"line\">CPU MHz:             3710.930</span><br><span class=\"line\">CPU max MHz:         4700.0000</span><br><span class=\"line\">CPU min MHz:         800.0000</span><br><span class=\"line\">BogoMIPS:            6000.00</span><br><span class=\"line\">Virtualization:      VT-x</span><br><span class=\"line\">L1d cache:           32K</span><br><span class=\"line\">L1i cache:           32K</span><br><span class=\"line\">L2 cache:            256K</span><br><span class=\"line\">L3 cache:            12288K</span><br><span class=\"line\">NUMA node0 CPU(s):   0-7</span><br><span class=\"line\">Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilities</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"lshw-List-Hardware\"><a href=\"#lshw-List-Hardware\" class=\"headerlink\" title=\"lshw - List Hardware\"></a>lshw - List Hardware</h2><p>A general purpose utility, that reports detailed and brief information about multiple different hardware units such as cpu, memory, disk, usb controllers, network adapters etc. Lshw extracts the information from different /proc files.</p>\n<h3 id=\"Display-Full-Information\"><a href=\"#Display-Full-Information\" class=\"headerlink\" title=\"Display Full Information\"></a>Display Full Information</h3><p>Running lshw without any options would generate full information report about all detected hardware. It would generate a big output with quite a lot of technical details.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw</span><br></pre></td></tr></table></figure>\n<h3 id=\"Display-information-in-short\"><a href=\"#Display-information-in-short\" class=\"headerlink\" title=\"Display information in short\"></a>Display information in short</h3><p>With the “-short” the lshw command would generate a brief information report about the hardware devices that would quickly give an idea about the hardware profile of the system.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> sudo lshw -short</span></span><br><span class=\"line\">H/W path         Device    Class          Description</span><br><span class=\"line\">=====================================================</span><br><span class=\"line\">                           system         MS-7C22 (Default string)</span><br><span class=\"line\">/0                         bus            Z390 PLUS (MS-7C22)</span><br><span class=\"line\">/0/0                       memory         64KiB BIOS</span><br><span class=\"line\">/0/39                      memory         16GiB System Memory</span><br><span class=\"line\">/0/39/0                    memory         [empty]</span><br><span class=\"line\">/0/39/1                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)</span><br><span class=\"line\">/0/39/2                    memory         [empty]</span><br><span class=\"line\">/0/39/3                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)</span><br><span class=\"line\">/0/43                      memory         512KiB L1 cache</span><br><span class=\"line\">/0/44                      memory         2MiB L2 cache</span><br><span class=\"line\">/0/45                      memory         12MiB L3 cache</span><br><span class=\"line\">/0/46                      processor      Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</span><br><span class=\"line\">/0/100                     bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1                   bridge         Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Cont</span><br><span class=\"line\">/0/100/1/0                 display        NVIDIA Corporation</span><br><span class=\"line\">/0/100/1/0.1               multimedia     NVIDIA Corporation</span><br><span class=\"line\">/0/100/1/0.2               bus            NVIDIA Corporation</span><br><span class=\"line\">/0/100/1/0.2/0   usb3      bus            xHCI Host Controller</span><br><span class=\"line\">/0/100/1/0.2/1   usb4      bus            xHCI Host Controller</span><br><span class=\"line\">/0/100/1/0.3               bus            NVIDIA Corporation</span><br><span class=\"line\">/0/100/8                   generic        Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th Gen Core Processo</span><br><span class=\"line\">/0/100/12                  generic        Cannon Lake PCH Thermal Controller</span><br><span class=\"line\">/0/100/14                  bus            Cannon Lake PCH USB 3.1 xHCI Host Controller</span><br><span class=\"line\">/0/100/14/0      usb1      bus            xHCI Host Controller</span><br><span class=\"line\">/0/100/14/0/2              input          HP Basic USB Keyboard</span><br><span class=\"line\">/0/100/14/0/8              input          2.4G Mouse</span><br><span class=\"line\">/0/100/14/1      usb2      bus            xHCI Host Controller</span><br><span class=\"line\">/0/100/14.2                memory         RAM memory</span><br><span class=\"line\">/0/100/16                  communication  Cannon Lake PCH HECI Controller</span><br><span class=\"line\">/0/100/17                  storage        Cannon Lake PCH SATA AHCI Controller</span><br><span class=\"line\">/0/100/1b                  bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1b.4                bridge         Cannon Lake PCH PCI Express Root Port 21</span><br><span class=\"line\">/0/100/1b.4/0    enp3s0f0  network        I350 Gigabit Network Connection</span><br><span class=\"line\">/0/100/1b.4/0.1  enp3s0f1  network        I350 Gigabit Network Connection</span><br><span class=\"line\">/0/100/1b.4/0.2  enp3s0f2  network        I350 Gigabit Network Connection</span><br><span class=\"line\">/0/100/1b.4/0.3  enp3s0f3  network        I350 Gigabit Network Connection</span><br><span class=\"line\">/0/100/1c                  bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1c.4                bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1c.4/0    enp5s0    network        RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller</span><br><span class=\"line\">/0/100/1d                  bridge         Cannon Lake PCH PCI Express Root Port 9</span><br><span class=\"line\">/0/100/1d/0                storage        Micron/Crucial Technology</span><br><span class=\"line\">/0/100/1f                  bridge         Intel Corporation</span><br><span class=\"line\">/0/100/1f.3                multimedia     Cannon Lake PCH cAVS</span><br><span class=\"line\">/0/100/1f.4                bus            Cannon Lake PCH SMBus Controller</span><br><span class=\"line\">/0/100/1f.5                bus            Cannon Lake PCH SPI Controller</span><br><span class=\"line\">/1                         power          To Be Filled By O.E.M.</span><br><span class=\"line\">/2               docker0   network        Ethernet interface</span><br><span class=\"line\">/3               br0       network        Ethernet interface</span><br></pre></td></tr></table></figure>\n<h3 id=\"Display-only-memory-information\"><a href=\"#Display-only-memory-information\" class=\"headerlink\" title=\"Display only memory information\"></a>Display only memory information</h3><p>To display information about the memory, specify the memory class.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yanboyang713@boyang $ sudo lshw -short -class memory</span><br><span class=\"line\">H/W path         Device    Class          Description</span><br><span class=\"line\">=====================================================</span><br><span class=\"line\">/0/0                       memory         64KiB BIOS</span><br><span class=\"line\">/0/39                      memory         16GiB System Memory</span><br><span class=\"line\">/0/39/0                    memory         [empty]</span><br><span class=\"line\">/0/39/1                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)</span><br><span class=\"line\">/0/39/2                    memory         [empty]</span><br><span class=\"line\">/0/39/3                    memory         8GiB DIMM DDR4 Synchronous 2667 MHz (0.4 ns)</span><br><span class=\"line\">/0/43                      memory         512KiB L1 cache</span><br><span class=\"line\">/0/44                      memory         2MiB L2 cache</span><br><span class=\"line\">/0/45                      memory         12MiB L3 cache</span><br><span class=\"line\">/0/100/14.2                memory         RAM memory</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Display-processor-information\"><a href=\"#Display-processor-information\" class=\"headerlink\" title=\"Display processor information\"></a>Display processor information</h3><p>With class processor, lshw would display information about the cpu. It is better to not use the short option and get full details about the processor.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> sudo lshw -class processor</span></span><br><span class=\"line\">  *-cpu                     </span><br><span class=\"line\">       description: CPU</span><br><span class=\"line\">       product: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</span><br><span class=\"line\">       vendor: Intel Corp.</span><br><span class=\"line\">       physical id: 46</span><br><span class=\"line\">       bus info: cpu@0</span><br><span class=\"line\">       version: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</span><br><span class=\"line\">       serial: To Be Filled By O.E.M.</span><br><span class=\"line\">       slot: U3E1</span><br><span class=\"line\">       size: 4631MHz</span><br><span class=\"line\">       capacity: 4700MHz</span><br><span class=\"line\">       width: 64 bits</span><br><span class=\"line\">       clock: 100MHz</span><br><span class=\"line\">       capabilities: x86-64 fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilities cpufreq</span><br><span class=\"line\">       configuration: cores=8 enabledcores=8 threads=8</span><br></pre></td></tr></table></figure>\n\n<p>It should be noted that lshw does not accurately tell about the number of cores or processing units available. The above system for example is a quadcore processor with 4 processing units. Another command called lscpu gives more accurate information about the cpu.</p>\n<h3 id=\"Disk-drives\"><a href=\"#Disk-drives\" class=\"headerlink\" title=\"Disk drives\"></a>Disk drives</h3><p>Display the disk drives with the disk class.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw -short -class disk</span><br></pre></td></tr></table></figure>\n\n<p>To display information about the partitions and controllers also, specify the storage and volume class along with the disk class. Then it would give a more clear picture about the storage on the system.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw -short -class disk -class storage -class volume</span><br></pre></td></tr></table></figure>\n<h3 id=\"Network-adapter-information\"><a href=\"#Network-adapter-information\" class=\"headerlink\" title=\"Network adapter information\"></a>Network adapter information</h3><p>Use the network class to display information about the network adapter/interface. Omitting the short option is a good idea to get detailed information about it.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw -class network</span><br></pre></td></tr></table></figure>\n<p>The value of the “serial” field is same as the MAC address. The configuration field indicates that autonegotiation is turned on and the current operating speed is 100Mbit/s. These configurations can be modified with the ethtool command.</p>\n<h3 id=\"Display-address-details-with-businfo\"><a href=\"#Display-address-details-with-businfo\" class=\"headerlink\" title=\"Display address details with businfo\"></a>Display address details with businfo</h3><p>With the businfo option lshw would output the address details of pci, usb, scsi and ide devices.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lshw -businfo</span><br></pre></td></tr></table></figure>\n<p>The output is similar to “short” option, with the first column replaced with Bus Info.</p>\n<h3 id=\"Generate-report-in-html-xml-format\"><a href=\"#Generate-report-in-html-xml-format\" class=\"headerlink\" title=\"Generate report in html/xml format\"></a>Generate report in html/xml format</h3><p>Lshw is capable of producing reports in html, xml and json formats.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo lshw -html &gt; hardware.html</span><br></pre></td></tr></table></figure>\n\n<p>For xml format</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo lshw -xml &gt; hardware.xml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"lspci-List-PCI\"><a href=\"#lspci-List-PCI\" class=\"headerlink\" title=\"lspci - List PCI\"></a>lspci - List PCI</h2><p>The lspci command lists out all the pci buses and details about the devices connected to them.<br>The vga adapter, graphics card, network adapter, usb ports, sata controllers, etc all fall under this category.</p>\n<figure class=\"highlight console\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">yanboyang713@boyang$</span><span class=\"bash\"> lspci</span></span><br><span class=\"line\">00:00.0 Host bridge: Intel Corporation Device 3e30 (rev 0d)</span><br><span class=\"line\">00:01.0 PCI bridge: Intel Corporation Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Controller (x16) (rev 0d)</span><br><span class=\"line\">00:08.0 System peripheral: Intel Corporation Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th Gen Core Processor Gaussian Mixture Model</span><br><span class=\"line\">00:12.0 Signal processing controller: Intel Corporation Cannon Lake PCH Thermal Controller (rev 10)</span><br><span class=\"line\">00:14.0 USB controller: Intel Corporation Cannon Lake PCH USB 3.1 xHCI Host Controller (rev 10)</span><br><span class=\"line\">00:14.2 RAM memory: Intel Corporation Cannon Lake PCH Shared SRAM (rev 10)</span><br><span class=\"line\">00:16.0 Communication controller: Intel Corporation Cannon Lake PCH HECI Controller (rev 10)</span><br><span class=\"line\">00:17.0 SATA controller: Intel Corporation Cannon Lake PCH SATA AHCI Controller (rev 10)</span><br><span class=\"line\">00:1b.0 PCI bridge: Intel Corporation Device a340 (rev f0)</span><br><span class=\"line\">00:1b.4 PCI bridge: Intel Corporation Cannon Lake PCH PCI Express Root Port 21 (rev f0)</span><br><span class=\"line\">00:1c.0 PCI bridge: Intel Corporation Device a338 (rev f0)</span><br><span class=\"line\">00:1c.4 PCI bridge: Intel Corporation Device a33c (rev f0)</span><br><span class=\"line\">00:1d.0 PCI bridge: Intel Corporation Cannon Lake PCH PCI Express Root Port 9 (rev f0)</span><br><span class=\"line\">00:1f.0 ISA bridge: Intel Corporation Device a305 (rev 10)</span><br><span class=\"line\">00:1f.3 Audio device: Intel Corporation Cannon Lake PCH cAVS (rev 10)</span><br><span class=\"line\">00:1f.4 SMBus: Intel Corporation Cannon Lake PCH SMBus Controller (rev 10)</span><br><span class=\"line\">00:1f.5 Serial bus controller [0c80]: Intel Corporation Cannon Lake PCH SPI Controller (rev 10)</span><br><span class=\"line\">01:00.0 VGA compatible controller: NVIDIA Corporation Device 1f02 (rev a1)</span><br><span class=\"line\">01:00.1 Audio device: NVIDIA Corporation Device 10f9 (rev a1)</span><br><span class=\"line\">01:00.2 USB controller: NVIDIA Corporation Device 1ada (rev a1)</span><br><span class=\"line\">01:00.3 Serial bus controller [0c80]: NVIDIA Corporation Device 1adb (rev a1)</span><br><span class=\"line\">03:00.0 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)</span><br><span class=\"line\">03:00.1 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)</span><br><span class=\"line\">03:00.2 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)</span><br><span class=\"line\">03:00.3 Ethernet controller: Intel Corporation I350 Gigabit Network Connection (rev 01)</span><br><span class=\"line\">05:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 15)</span><br><span class=\"line\">06:00.0 Non-Volatile memory controller: Micron/Crucial Technology Device 2263 (rev 03)</span><br></pre></td></tr></table></figure>\n\n<p>Filter out specific device information with grep.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lspci -v | grep <span class=\"string\">&quot;VGA&quot;</span> -A 12</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"lsscsi-List-scsi-devices\"><a href=\"#lsscsi-List-scsi-devices\" class=\"headerlink\" title=\"lsscsi - List scsi devices\"></a>lsscsi - List scsi devices</h2><p>Lists out the scsi/sata devices like hard drives and optical drives.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install lsscsi</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"lsusb-List-usb-buses-and-device-details\"><a href=\"#lsusb-List-usb-buses-and-device-details\" class=\"headerlink\" title=\"lsusb - List usb buses and device details\"></a>lsusb - List usb buses and device details</h2><p>This command shows the USB controllers and details about devices connected to them. By default brief information is printed. Use the verbose option “-v” to print detailed information about each usb port</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lsusb</span><br></pre></td></tr></table></figure>\n<p>On the above system, 1 usb port is being used by the mouse.</p>\n<h2 id=\"Inxi\"><a href=\"#Inxi\" class=\"headerlink\" title=\"Inxi\"></a>Inxi</h2><p>Inxi is a 10K line mega bash script that fetches hardware details from multiple different sources and commands on the system, and generates a beautiful looking report that non technical users can read easily.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ inxi -Fx</span><br></pre></td></tr></table></figure>\n<h2 id=\"lsblk-List-block-devices\"><a href=\"#lsblk-List-block-devices\" class=\"headerlink\" title=\"lsblk - List block devices\"></a>lsblk - List block devices</h2><p>List out information all block devices, which are the hard drive partitions and other storage devices like optical drives and flash drives</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lsblk</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"df-disk-space-of-file-systems\"><a href=\"#df-disk-space-of-file-systems\" class=\"headerlink\" title=\"df - disk space of file systems\"></a>df - disk space of file systems</h2><p>Reports various partitions, their mount points and the used and available space on each.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ df -H</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Pydf-Python-df\"><a href=\"#Pydf-Python-df\" class=\"headerlink\" title=\"Pydf - Python df\"></a>Pydf - Python df</h2><p>An improved df version written in python, that displays colored output that looks better than df</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pydf</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fdisk\"><a href=\"#fdisk\" class=\"headerlink\" title=\"fdisk\"></a>fdisk</h2><p>Fdisk is a utility to modify partitions on hard drives, and can be used to list out the partition information as well.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo fdisk -l</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"mount\"><a href=\"#mount\" class=\"headerlink\" title=\"mount\"></a>mount</h2><p>The mount is used to mount/unmount and view mounted file systems.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mount | column -t</span><br></pre></td></tr></table></figure>\n<p>Again, use grep to filter out only those file systems that you want to see</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mount | column -t | grep ext</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"free-Check-RAM\"><a href=\"#free-Check-RAM\" class=\"headerlink\" title=\"free - Check RAM\"></a>free - Check RAM</h2><p>Check the amount of used, free and total amount of RAM on system with the free command.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ free -m</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"dmidecode\"><a href=\"#dmidecode\" class=\"headerlink\" title=\"dmidecode\"></a>dmidecode</h2><p>The dmidecode command is different from all other commands. It extracts hardware information by reading data from the SMBOIS data structures (also called DMI tables).</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># display information about the processor/cpu</span></span><br><span class=\"line\">$ sudo dmidecode -t processor</span><br><span class=\"line\"><span class=\"comment\"># memory/ram information</span></span><br><span class=\"line\">$ sudo dmidecode -t memory</span><br><span class=\"line\"><span class=\"comment\"># bios details</span></span><br><span class=\"line\">$ sudo dmidecode -t bios</span><br></pre></td></tr></table></figure>\n\n<p>Check out the man page for more details.</p>\n<h1 id=\"proc-files\"><a href=\"#proc-files\" class=\"headerlink\" title=\"/proc files\"></a>/proc files</h1><p>Many of the virtual files in the /proc directory contain information about hardware and configurations. Here are some of them</p>\n<p>CPU/Memory information</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># cpu information</span></span><br><span class=\"line\">$ cat /proc/cpuinfo</span><br><span class=\"line\"><span class=\"comment\"># memory information</span></span><br><span class=\"line\">$ cat /proc/meminfo</span><br></pre></td></tr></table></figure>\n\n<p>Linux/kernel information</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat /proc/version</span><br><span class=\"line\">Linux version 3.11.0-12-generic (buildd@allspice) (gcc version 4.8.1 (Ubuntu/Linaro 4.8.1-10ubuntu7) ) <span class=\"comment\">#19-Ubuntu SMP Wed Oct 9 16:20:46 UTC 2013</span></span><br></pre></td></tr></table></figure>\n\n<p>SCSI/Sata devices</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat /proc/scsi/scsi</span><br></pre></td></tr></table></figure>\n\n<p>Partitions</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat /proc/partitions</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"hdparm\"><a href=\"#hdparm\" class=\"headerlink\" title=\"hdparm\"></a>hdparm</h2><p>The hdparm command gets information about sata devices like hard disks.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo hdparm -i /dev/sda</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Intellectual Property Foundation and Patent Mining","date":"2020-09-15T17:22:10.000Z","_content":"# Introduction\n\n# Scope of Intellectual Property\nIntellectual property\nAlso known as \"intellectual property rights\", it refers to the broad fields of industry, technology, science and art\nThe exclusive legal rights involved in intellectual creation, invention and innovation.\nIntellectual property rights include:\nCopyright (copyright), trademark, patent,\nTrade secrets, new plant varieties, semiconductor integrated circuit design, trade name (company name)\n\n# Patent Type\nTotal have three type of patent\n1. Invention\nNew technical solutions for products, methods or their combination.\nProducts: articles, devices, equipment, tools, materials, etc.\nMethod: manufacturing method, use method, communication method, processing method, etc.\n(Pure intellectual activity rules and methods cannot be granted patent rights.)\n2. Utility model\nNew practical technical solutions proposed for the shape, structure or combination of the product. (It can be directly observed from the definite spatial shape; it solves the technical problem, not just for more beautiful appearance.) Such as: the shape of the cup, the relative position relationship of the parts and the mechanical cooperation relationship, the relationship between the components that constitute the circuit Connection relationship, etc.\n3. Appearance design\nA new design that is aesthetically pleasing and suitable for industrial applications based on the shape, pattern or combination of the product and the combination of color, shape and pattern. Such as: the style of clothes, the outline of the product, the graphics on the surface, etc.\n\n# Patent Characteristics\n1. Exclusivity\nThe patent right for invention creation is unique, monopoly and exclusive.\n2. Timeliness\nTerm of protection: 20 years for invention, 10 years for utility model, and 10 years for appearance.\n3. Regional\nThe patent laws of each country are independent, and the patent right is only valid in the ratifying country.\n\n# Legal conditions for the establishment of a patent\n\n","source":"_posts/patent.md","raw":"---\ntitle: Intellectual Property Foundation and Patent Mining\ndate: 2020-09-15 17:22:10\ntags:\n - Patent\ncategories: Patent\n---\n# Introduction\n\n# Scope of Intellectual Property\nIntellectual property\nAlso known as \"intellectual property rights\", it refers to the broad fields of industry, technology, science and art\nThe exclusive legal rights involved in intellectual creation, invention and innovation.\nIntellectual property rights include:\nCopyright (copyright), trademark, patent,\nTrade secrets, new plant varieties, semiconductor integrated circuit design, trade name (company name)\n\n# Patent Type\nTotal have three type of patent\n1. Invention\nNew technical solutions for products, methods or their combination.\nProducts: articles, devices, equipment, tools, materials, etc.\nMethod: manufacturing method, use method, communication method, processing method, etc.\n(Pure intellectual activity rules and methods cannot be granted patent rights.)\n2. Utility model\nNew practical technical solutions proposed for the shape, structure or combination of the product. (It can be directly observed from the definite spatial shape; it solves the technical problem, not just for more beautiful appearance.) Such as: the shape of the cup, the relative position relationship of the parts and the mechanical cooperation relationship, the relationship between the components that constitute the circuit Connection relationship, etc.\n3. Appearance design\nA new design that is aesthetically pleasing and suitable for industrial applications based on the shape, pattern or combination of the product and the combination of color, shape and pattern. Such as: the style of clothes, the outline of the product, the graphics on the surface, etc.\n\n# Patent Characteristics\n1. Exclusivity\nThe patent right for invention creation is unique, monopoly and exclusive.\n2. Timeliness\nTerm of protection: 20 years for invention, 10 years for utility model, and 10 years for appearance.\n3. Regional\nThe patent laws of each country are independent, and the patent right is only valid in the ratifying country.\n\n# Legal conditions for the establishment of a patent\n\n","slug":"patent","published":1,"updated":"2020-09-16T11:46:31.622Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aj0000qiiiy413c0vsh","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><h1 id=\"Scope-of-Intellectual-Property\"><a href=\"#Scope-of-Intellectual-Property\" class=\"headerlink\" title=\"Scope of Intellectual Property\"></a>Scope of Intellectual Property</h1><p>Intellectual property<br>Also known as “intellectual property rights”, it refers to the broad fields of industry, technology, science and art<br>The exclusive legal rights involved in intellectual creation, invention and innovation.<br>Intellectual property rights include:<br>Copyright (copyright), trademark, patent,<br>Trade secrets, new plant varieties, semiconductor integrated circuit design, trade name (company name)</p>\n<h1 id=\"Patent-Type\"><a href=\"#Patent-Type\" class=\"headerlink\" title=\"Patent Type\"></a>Patent Type</h1><p>Total have three type of patent</p>\n<ol>\n<li>Invention<br>New technical solutions for products, methods or their combination.<br>Products: articles, devices, equipment, tools, materials, etc.<br>Method: manufacturing method, use method, communication method, processing method, etc.<br>(Pure intellectual activity rules and methods cannot be granted patent rights.)</li>\n<li>Utility model<br>New practical technical solutions proposed for the shape, structure or combination of the product. (It can be directly observed from the definite spatial shape; it solves the technical problem, not just for more beautiful appearance.) Such as: the shape of the cup, the relative position relationship of the parts and the mechanical cooperation relationship, the relationship between the components that constitute the circuit Connection relationship, etc.</li>\n<li>Appearance design<br>A new design that is aesthetically pleasing and suitable for industrial applications based on the shape, pattern or combination of the product and the combination of color, shape and pattern. Such as: the style of clothes, the outline of the product, the graphics on the surface, etc.</li>\n</ol>\n<h1 id=\"Patent-Characteristics\"><a href=\"#Patent-Characteristics\" class=\"headerlink\" title=\"Patent Characteristics\"></a>Patent Characteristics</h1><ol>\n<li>Exclusivity<br>The patent right for invention creation is unique, monopoly and exclusive.</li>\n<li>Timeliness<br>Term of protection: 20 years for invention, 10 years for utility model, and 10 years for appearance.</li>\n<li>Regional<br>The patent laws of each country are independent, and the patent right is only valid in the ratifying country.</li>\n</ol>\n<h1 id=\"Legal-conditions-for-the-establishment-of-a-patent\"><a href=\"#Legal-conditions-for-the-establishment-of-a-patent\" class=\"headerlink\" title=\"Legal conditions for the establishment of a patent\"></a>Legal conditions for the establishment of a patent</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><h1 id=\"Scope-of-Intellectual-Property\"><a href=\"#Scope-of-Intellectual-Property\" class=\"headerlink\" title=\"Scope of Intellectual Property\"></a>Scope of Intellectual Property</h1><p>Intellectual property<br>Also known as “intellectual property rights”, it refers to the broad fields of industry, technology, science and art<br>The exclusive legal rights involved in intellectual creation, invention and innovation.<br>Intellectual property rights include:<br>Copyright (copyright), trademark, patent,<br>Trade secrets, new plant varieties, semiconductor integrated circuit design, trade name (company name)</p>\n<h1 id=\"Patent-Type\"><a href=\"#Patent-Type\" class=\"headerlink\" title=\"Patent Type\"></a>Patent Type</h1><p>Total have three type of patent</p>\n<ol>\n<li>Invention<br>New technical solutions for products, methods or their combination.<br>Products: articles, devices, equipment, tools, materials, etc.<br>Method: manufacturing method, use method, communication method, processing method, etc.<br>(Pure intellectual activity rules and methods cannot be granted patent rights.)</li>\n<li>Utility model<br>New practical technical solutions proposed for the shape, structure or combination of the product. (It can be directly observed from the definite spatial shape; it solves the technical problem, not just for more beautiful appearance.) Such as: the shape of the cup, the relative position relationship of the parts and the mechanical cooperation relationship, the relationship between the components that constitute the circuit Connection relationship, etc.</li>\n<li>Appearance design<br>A new design that is aesthetically pleasing and suitable for industrial applications based on the shape, pattern or combination of the product and the combination of color, shape and pattern. Such as: the style of clothes, the outline of the product, the graphics on the surface, etc.</li>\n</ol>\n<h1 id=\"Patent-Characteristics\"><a href=\"#Patent-Characteristics\" class=\"headerlink\" title=\"Patent Characteristics\"></a>Patent Characteristics</h1><ol>\n<li>Exclusivity<br>The patent right for invention creation is unique, monopoly and exclusive.</li>\n<li>Timeliness<br>Term of protection: 20 years for invention, 10 years for utility model, and 10 years for appearance.</li>\n<li>Regional<br>The patent laws of each country are independent, and the patent right is only valid in the ratifying country.</li>\n</ol>\n<h1 id=\"Legal-conditions-for-the-establishment-of-a-patent\"><a href=\"#Legal-conditions-for-the-establishment-of-a-patent\" class=\"headerlink\" title=\"Legal conditions for the establishment of a patent\"></a>Legal conditions for the establishment of a patent</h1>"},{"title":"Getting started with UML (Unified Modeling Language)","subtitle":"based on Plantuml (UML Diagrams from simple textual description) integrate with Markdown and Emacs (Spacemacs)","date":"2020-09-21T11:33:31.000Z","_content":"# Introduction\nThis post document will brief introduct UML at the begining. After, will talk how using PlantUML for drawing UML diagrams. At the end, how does PlantUML integrate with Markdown and Emacs(Spacemacs).\n\n# UML Basics\n\n# PlantUML Basics\n\n## Reasons for using PlantUML\n\n# Markdown\n\n# Emacs (Spacemacs)\n\n# Summary\n\n","source":"_posts/plantuml.md","raw":"---\ntitle: Getting started with UML (Unified Modeling Language)\nsubtitle: based on Plantuml (UML Diagrams from simple textual description) integrate with Markdown and Emacs (Spacemacs)\ndate: 2020-09-21 11:33:31\ntags:\n - UML\n - plantuml\n - Markdown\n - Emacs\n - spacemacs\ncategories: UML\n---\n# Introduction\nThis post document will brief introduct UML at the begining. After, will talk how using PlantUML for drawing UML diagrams. At the end, how does PlantUML integrate with Markdown and Emacs(Spacemacs).\n\n# UML Basics\n\n# PlantUML Basics\n\n## Reasons for using PlantUML\n\n# Markdown\n\n# Emacs (Spacemacs)\n\n# Summary\n\n","slug":"plantuml","published":1,"updated":"2020-09-21T08:08:50.418Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aj1000viiiyblinca3r","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document will brief introduct UML at the begining. After, will talk how using PlantUML for drawing UML diagrams. At the end, how does PlantUML integrate with Markdown and Emacs(Spacemacs).</p>\n<h1 id=\"UML-Basics\"><a href=\"#UML-Basics\" class=\"headerlink\" title=\"UML Basics\"></a>UML Basics</h1><h1 id=\"PlantUML-Basics\"><a href=\"#PlantUML-Basics\" class=\"headerlink\" title=\"PlantUML Basics\"></a>PlantUML Basics</h1><h2 id=\"Reasons-for-using-PlantUML\"><a href=\"#Reasons-for-using-PlantUML\" class=\"headerlink\" title=\"Reasons for using PlantUML\"></a>Reasons for using PlantUML</h2><h1 id=\"Markdown\"><a href=\"#Markdown\" class=\"headerlink\" title=\"Markdown\"></a>Markdown</h1><h1 id=\"Emacs-Spacemacs\"><a href=\"#Emacs-Spacemacs\" class=\"headerlink\" title=\"Emacs (Spacemacs)\"></a>Emacs (Spacemacs)</h1><h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document will brief introduct UML at the begining. After, will talk how using PlantUML for drawing UML diagrams. At the end, how does PlantUML integrate with Markdown and Emacs(Spacemacs).</p>\n<h1 id=\"UML-Basics\"><a href=\"#UML-Basics\" class=\"headerlink\" title=\"UML Basics\"></a>UML Basics</h1><h1 id=\"PlantUML-Basics\"><a href=\"#PlantUML-Basics\" class=\"headerlink\" title=\"PlantUML Basics\"></a>PlantUML Basics</h1><h2 id=\"Reasons-for-using-PlantUML\"><a href=\"#Reasons-for-using-PlantUML\" class=\"headerlink\" title=\"Reasons for using PlantUML\"></a>Reasons for using PlantUML</h2><h1 id=\"Markdown\"><a href=\"#Markdown\" class=\"headerlink\" title=\"Markdown\"></a>Markdown</h1><h1 id=\"Emacs-Spacemacs\"><a href=\"#Emacs-Spacemacs\" class=\"headerlink\" title=\"Emacs (Spacemacs)\"></a>Emacs (Spacemacs)</h1><h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1>"},{"title":"SSH server set-up with multi-user and Security Practices","date":"2020-09-08T13:14:59.000Z","_content":"# Introduction\nThis post document is about how to set-up SSH server base on Ubuntu OS. A lots of users have some concerns about SSH security, especially when multi-user or multi-group share to use with same SSH tunnel. So, this article will fouce on SSH server security practices with multi-user. In this article, first I will talk Linux User and Group Management.\n\n**TIPS:**\nWhen you using SSH connect with a host, CLI Text Editor is importance for editing some of config file. I recommand you using VIM, if you don't know how to use VIM, please have a look {% post_link vim %}\n\n# User Scenario\n1. Multi-user connect to cloud Virtual Machine(VM) using SSH is the most used scenario.\n2. Using SSH configure Edge Devices \n\n# Linux user and group management\nSince Linux is a multi-user operating system, several people may be logged in and actively working on a given machine at the same time. Security-wise, it is never a good idea to allow users to share the credentials of the same account. In fact, best practices dictate the use of as many user accounts as people needing access to the machine.\n\nAt the same time, it is to be expected that two or more users may need to share access to certain system resources, such as directories and files. User and group management in Linux allows us to accomplish both objectives.\n\n","source":"_posts/ssh.md","raw":"---\ntitle: SSH server set-up with multi-user and Security Practices\ndate: 2020-09-08 13:14:59\ntags:\n - Networking\n - SSH\ncategories: Networking\n---\n# Introduction\nThis post document is about how to set-up SSH server base on Ubuntu OS. A lots of users have some concerns about SSH security, especially when multi-user or multi-group share to use with same SSH tunnel. So, this article will fouce on SSH server security practices with multi-user. In this article, first I will talk Linux User and Group Management.\n\n**TIPS:**\nWhen you using SSH connect with a host, CLI Text Editor is importance for editing some of config file. I recommand you using VIM, if you don't know how to use VIM, please have a look {% post_link vim %}\n\n# User Scenario\n1. Multi-user connect to cloud Virtual Machine(VM) using SSH is the most used scenario.\n2. Using SSH configure Edge Devices \n\n# Linux user and group management\nSince Linux is a multi-user operating system, several people may be logged in and actively working on a given machine at the same time. Security-wise, it is never a good idea to allow users to share the credentials of the same account. In fact, best practices dictate the use of as many user accounts as people needing access to the machine.\n\nAt the same time, it is to be expected that two or more users may need to share access to certain system resources, such as directories and files. User and group management in Linux allows us to accomplish both objectives.\n\n","slug":"ssh","published":1,"updated":"2020-09-24T13:22:26.356Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aj1000xiiiyd9gfbfcz","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about how to set-up SSH server base on Ubuntu OS. A lots of users have some concerns about SSH security, especially when multi-user or multi-group share to use with same SSH tunnel. So, this article will fouce on SSH server security practices with multi-user. In this article, first I will talk Linux User and Group Management.</p>\n<p><strong>TIPS:</strong><br>When you using SSH connect with a host, CLI Text Editor is importance for editing some of config file. I recommand you using VIM, if you don’t know how to use VIM, please have a look <a href=\"/2020/09/07/vim/\" title=\"VIM Keyboard Shortcuts Cheatsheet\">VIM Keyboard Shortcuts Cheatsheet</a></p>\n<h1 id=\"User-Scenario\"><a href=\"#User-Scenario\" class=\"headerlink\" title=\"User Scenario\"></a>User Scenario</h1><ol>\n<li>Multi-user connect to cloud Virtual Machine(VM) using SSH is the most used scenario.</li>\n<li>Using SSH configure Edge Devices </li>\n</ol>\n<h1 id=\"Linux-user-and-group-management\"><a href=\"#Linux-user-and-group-management\" class=\"headerlink\" title=\"Linux user and group management\"></a>Linux user and group management</h1><p>Since Linux is a multi-user operating system, several people may be logged in and actively working on a given machine at the same time. Security-wise, it is never a good idea to allow users to share the credentials of the same account. In fact, best practices dictate the use of as many user accounts as people needing access to the machine.</p>\n<p>At the same time, it is to be expected that two or more users may need to share access to certain system resources, such as directories and files. User and group management in Linux allows us to accomplish both objectives.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about how to set-up SSH server base on Ubuntu OS. A lots of users have some concerns about SSH security, especially when multi-user or multi-group share to use with same SSH tunnel. So, this article will fouce on SSH server security practices with multi-user. In this article, first I will talk Linux User and Group Management.</p>\n<p><strong>TIPS:</strong><br>When you using SSH connect with a host, CLI Text Editor is importance for editing some of config file. I recommand you using VIM, if you don’t know how to use VIM, please have a look <a href=\"/2020/09/07/vim/\" title=\"VIM Keyboard Shortcuts Cheatsheet\">VIM Keyboard Shortcuts Cheatsheet</a></p>\n<h1 id=\"User-Scenario\"><a href=\"#User-Scenario\" class=\"headerlink\" title=\"User Scenario\"></a>User Scenario</h1><ol>\n<li>Multi-user connect to cloud Virtual Machine(VM) using SSH is the most used scenario.</li>\n<li>Using SSH configure Edge Devices </li>\n</ol>\n<h1 id=\"Linux-user-and-group-management\"><a href=\"#Linux-user-and-group-management\" class=\"headerlink\" title=\"Linux user and group management\"></a>Linux user and group management</h1><p>Since Linux is a multi-user operating system, several people may be logged in and actively working on a given machine at the same time. Security-wise, it is never a good idea to allow users to share the credentials of the same account. In fact, best practices dictate the use of as many user accounts as people needing access to the machine.</p>\n<p>At the same time, it is to be expected that two or more users may need to share access to certain system resources, such as directories and files. User and group management in Linux allows us to accomplish both objectives.</p>\n"},{"title":"Install Tensorflow 2.1 on Ubuntu 18.04 LTS with GPU support","subtitle":"Nvidia Drivers, CUDA 10 and cuDNN","date":"2020-09-15T11:08:05.000Z","_content":"# Introduction\nThis post document is about how to build GPU support environment for Tensorflow 2.1. This document will include install Nvidia driver, CUDA Toolkit, cuDNN on Ubuntu 18.04.\n\n# Hardware Environment\n\n","source":"_posts/tensorflowGPUsupport.md","raw":"---\ntitle: Install Tensorflow 2.1 on Ubuntu 18.04 LTS with GPU support\nsubtitle: Nvidia Drivers, CUDA 10 and cuDNN\ndate: 2020-09-15 11:08:05\ntags:\n - Tensorflow\n - Machine Learning\n - Nvidia GPU\ncategories: GPU\n---\n# Introduction\nThis post document is about how to build GPU support environment for Tensorflow 2.1. This document will include install Nvidia driver, CUDA Toolkit, cuDNN on Ubuntu 18.04.\n\n# Hardware Environment\n\n","slug":"tensorflowGPUsupport","published":1,"updated":"2020-09-16T12:21:52.731Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aj20011iiiyc53efllz","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about how to build GPU support environment for Tensorflow 2.1. This document will include install Nvidia driver, CUDA Toolkit, cuDNN on Ubuntu 18.04.</p>\n<h1 id=\"Hardware-Environment\"><a href=\"#Hardware-Environment\" class=\"headerlink\" title=\"Hardware Environment\"></a>Hardware Environment</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about how to build GPU support environment for Tensorflow 2.1. This document will include install Nvidia driver, CUDA Toolkit, cuDNN on Ubuntu 18.04.</p>\n<h1 id=\"Hardware-Environment\"><a href=\"#Hardware-Environment\" class=\"headerlink\" title=\"Hardware Environment\"></a>Hardware Environment</h1>"},{"title":"Setting up an ubuntu Router with bridge","date":"2020-09-04T16:43:13.000Z","_content":"\n# Introduction\nThis post document is about how to build a Linux gateway base on Ubuntu OS. The gateway connects an internal network to an external network. Basically, performing Network Address Translation (NAT) for hosts on the internal network. It is exceptionally similar to what your home router does.\n\n# User Scenario\n1. Acting as a router at home or in office as a local area network.\n2. Connecting multi-network cameras to Ubuntu Server for transfer image data.\n\n# Terminology\n1. **interface** is used to mean the operating system's name for a place which sends or receives data packets. It is often, but not necessarily, the same as a device. An interface may have several devices associated (e.g. a bridge), or a single device may have several interfaces. device will refer here to the bit of hardware dealing with your network connections. \n2. A **network adapter** is the component of a computer’s internal hardware that is used for communicating over a network with another computer. It enable a computer to connect with another computer, server or any networking device over an LAN connection. A network adapter can be used over a wired or wireless network.\n3. A **gateway** is a piece of networking hardware used in telecommunications for telecommunications networks that allows data to flow from one discrete network to another. Gateways are distinct from routers or switches in that they communicate using more than one protocol to connect a bunch of networks and can operate at any of the seven layers of the open systems interconnection model (OSI). \n\n# Hardware Requirments\nIn our scenario, we need one multi-port network adapters with your desktop PC at the less. One port for connect with external network. Others for connect internal network. Because, we have muti-devices need to connect to internal network, So I recommand, we can using monther-board wired adapter connect with external network and one multi-port PCIE network card connect with internal network. All of PCIE network card can be connect to a bridge. The details how to set-up, I will talk at the below.\n\n**Tips, there are two type of PCIE adapters can be use in our project. First type have POE (Power over Ethernet) support and another type does not support POE. I recommend you buy a PoE support card because when you want to connect a network camera or access point (AP), which can be power by PCIE card directly, you need not unnecessary power cable and power supply to power cameras or APs, this will convience for you. 4 port Gigabit POE network card about 120 US dollars.**\n\n# Settings\n## Configuring the bridge and Network file settings\nLinux supports the implementation of a software network bridge to reproduce the function of a network bridge, a networking device that interconnects two or more communication networks or network segments providing a way for them to work as a single network.\nIt acts almost like a network switch, and in a software sense, it is used to implement the concept of a “virtual network switch”.\n\nIn our scenario, we will use software network bridging to connect all of ports for PCIE network card directly to the host server network.\nIf you want to you also can add your virtual machines(VMs) to this bridge.\nThis way, the all of PCIE ports are deployed on the same subnet as the host and can access services such as DHCP and much more.\n\n### Installing Network Bridge Utilities\nBegin by installing the bridge-utils package which contains utilities for configuring the Ubuntu ethernet bridge using the apt package manager as shown.\n\n```bash\nsudo apt-get update\nsudo apt-get install bridge-utils\n```\n\n### Distinguish External and Internal Interfaces' Name\nIdentify the interface name for your ethernet device using the IP command as shown.\n\n```bash\n$ ip ad\nOR\n$ ip add\n```\n\n![ip add](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599389099/setting%20up%20an%20ubuntu%20router%20with%20bridge%20-%20ip%20addr.png)\n\nFrom this screenshot, as you can see:\n1. **enp5s0 interface** is my monther-board wired adapter(only have one port) connect with external network\n2. **enp3s0f0 interface**, **enp3s0f1 interface**, **enp3s0f2 interface** and **enp3s0f3 interface** are my PCIE network card (4 ports)\n3. **br0** is my bridge, which connect with all of PCIE ports. The bridge will as internal network. This interface have not yet. Please following the next creating the bridge section.\n\n### Creating and Setting the Bridge at Start-up\nWe need to edit the /etc/network/interfaces file. This file shows an example of a bridge configure.\n\nSample /etc/network/interfaces file\n```\nauto lo\niface lo inet loopback\n\n#External Interface\nauto enp5s0\niface enp5s0 inet dhcp\n\n#bridge\nauto br0\niface br0 inet static\n    address 192.168.1.1\n    network 192.168.1.0\n    netmask 255.255.255.0\n    broadcast 192.168.1.255\n    bridge-ports enp3s0f0 enp3s0f1 enp3s0f2 enp3s0f3\n\n```\n\n** TIPS: please run the below command backup your interfaces file first.\n```bash\ncp /etc/network/interfaces /etc/network/interfaces.backup\n```\nFrom this interface configure file, you can see:\n1. External interface will use Dynamic Host Configuration Protocol (DHCP), whereby external network DHCP server will dynamically assigns an IP adress and other network configuration paprameters to this external interface.\n2. Created a new interface, names *br0*. Using static settings, I manuelly assign IP address 192.168.1.1 to this bridge, when you set-up internal network clients 192.168.1.1 should be the gateway. internal network IP should be 192.168.1.x(x minimum valu is 2, the maxmum value is 255)\n3. All of my PCIE ports connected with this bridge.\n\n** When you finished settings for this section, please restart networking. The command at the below **\n\n```bash\nsudo /etc/init.d/networking restart \n```\n## Enable IP forwarding and Masquerading\nDoing the above might not be enough to make the Ubuntu machine a real router which does NAT (Network Address Translation) and IP Forwarding. The following script configures the Kernel IPTable and IP forwarding. You will have to configure at least the script's 2 variables; the 1st is the external network interface; the 2nd is the internal network interface.\n\n```bash\necho -e \"\\n\\nLoading simple rc.firewall-iptables version $FWVER..\\n\"\nDEPMOD=/sbin/depmod\nMODPROBE=/sbin/modprobe\n\nEXTIF=\"eth0\" # Change eth0 as your External Network Interface Name\nINTIF=\"eth1\" # Change eth1 as bridge name (Internal Network Interface)\n\necho \"   External Interface:  $EXTIF\"\necho \"   Internal Interface:  $INTIF\"\n\n#======================================================================\n#== No editing beyond this line is required for initial MASQ testing == \necho -en \"   loading modules: \"\necho \"  - Verifying that all kernel modules are ok\"\n$DEPMOD -a\necho \"----------------------------------------------------------------------\"\necho -en \"ip_tables, \"\n$MODPROBE ip_tables\necho -en \"nf_conntrack, \" \n$MODPROBE nf_conntrack\necho -en \"nf_conntrack_ftp, \" \n$MODPROBE nf_conntrack_ftp\necho -en \"nf_conntrack_irc, \" \n$MODPROBE nf_conntrack_irc\necho -en \"iptable_nat, \"\n$MODPROBE iptable_nat\necho -en \"nf_nat_ftp, \"\n$MODPROBE nf_nat_ftp\necho \"----------------------------------------------------------------------\"\necho -e \"   Done loading modules.\\n\"\necho \"   Enabling forwarding..\"\necho \"1\" > /proc/sys/net/ipv4/ip_forward\necho \"   Enabling DynamicAddr..\"\necho \"1\" > /proc/sys/net/ipv4/ip_dynaddr \necho \"   Clearing any existing rules and setting default policy..\"\n\niptables-restore <<-EOF\n*nat\n-A POSTROUTING -o \"$EXTIF\" -j MASQUERADE\nCOMMIT\n*filter\n:INPUT ACCEPT [0:0]\n:FORWARD DROP [0:0]\n:OUTPUT ACCEPT [0:0]\n-A FORWARD -i \"$EXTIF\" -o \"$INTIF\" -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT \n-A FORWARD -i \"$INTIF\" -o \"$EXTIF\" -j ACCEPT\n-A FORWARD -j LOG\nCOMMIT\nEOF\n\necho -e \"\\nrc.firewall-iptables v$FWVER done.\\n\"\n```\n\nAfter configuring the 2 variables, save the script below as nat.sh and make it executable by doing\n\n```bash\nchmod a+x nat.sh\n```\n\nNow, test the script by running as root\n\n```bash\nsudo sh nat.sh\n```\n\n## Clients network settings\nEach clients at the less MUST setting the corrent IP address, netmask, gateway and DNS.\n\n** TIPS:\nIf you using the above bridge settings, you can following the below list to set-up your client network interface.\n1. The bridge IP is 192.168.1.1, so your clent IP should be 192.168.1.x (x minimum valu is 2, the maxmum value is 255), all of clients IP must be unique within this internal network(subnet).\n2. netmask should be 255.255.255.0\n3. gateway should be 192.168.1.1, which is bridge's IP address\n4. DNS can be setting as your ISP DNS or public DNS, such as Google's DNS 8.8.8.8, 8.8.4.4\n**\n\n### For Linux\n#### Using ifconfig\nSetting up IP address and Netmask command line\n```bash\nsudo ifconfig eth0 192.168.1.2 netmask 255.255.255.0\n```\n** TIPS: **\n1. eth0 is network interface name, you need change this.\n2. 192.168.1.2 is client IP address you want to set.\n3. netmask 255.255.255.0 is good.\n\nSetting up gateway command line\n```bash\nsudo route add default gw 192.168.1.1 eth0\n```\n\n** TIPS: **\n1. eth0 is network interface name, you need change this.\n2. *gw xxx.xxx.xxx.xxx* is your gateway IP address \n\n#### Ubuntu GUI\n\n![Editing wired connection](https://i0.wp.com/www.opensourceforu.com/wp-content/uploads/2015/03/fig5.png?resize=350%2C374&ssl=1)\n\n### For Mac\n1. On your Mac, choose Apple menu > System Preferences, then click Network.\n2. Select the network connection you want to use (such as Ethernet) in the list.\n3. Choose Manually and enter the address in the IP Address field. Also, subnet mask, gateway, and Domain Name System (DNS) server address.\n\n### For Windows\n1. Open Start on Windows 10.\n2. Search for Command Prompt, right-click the result and select the Run as administrator option to open the console.\n3. Type the following command to see your current networking configuration and press Enter:\n```bash\nipconfig /all\n```\n4. Type the following command to assign a static IP address and press Enter:\n```bash\nnetsh interface ip set address name=\"Ethernet0\" static 192.168.1.2 255.255.255.0 192.168.1.1\n```\nIn the above command make sure to change Ethernet0 for the name of your network adapter, and you must change 192.168.1.2 255.255.255.0 192.168.1.1 with the device IP address, subnet mask, and default gateway address that corresponds to your network configuration.\n\n5. Type the following command to set a DNS server address and press Enter:\n```bash\nnetsh interface ip set dns name=\"Ethernet0\" static 10.1.2.1\n```\nIn the above command make sure to change Ethernet0 with the name of your adapter and 10.1.2.1 with the DNS server address of your network.\n6. Type the following command to set an alternate DNS server address and press Enter:\n```bash\nnetsh interface ip add dns name=\"Ethernet0\" 8.8.8.8 index=2\n```\nIn the above command make sure to change Ethernet0 with the name of your adapter and 8.8.8.8 with an alternate DNS server address.\n\n** After you complete the steps, you can test the new configuration using the ping command (for example, ping google.com) to see if the internet is working. Alternatively, you can simply open your web browser and try to navigate to a website to see if the configuration works. **\n\n# Troubleshooting\n\n\n","source":"_posts/ubuntuRouter.md","raw":"---\ntitle: Setting up an ubuntu Router with bridge\ndate: 2020-09-04 16:43:13\ntags:\n - Networking\ncategories: Networking\n---\n\n# Introduction\nThis post document is about how to build a Linux gateway base on Ubuntu OS. The gateway connects an internal network to an external network. Basically, performing Network Address Translation (NAT) for hosts on the internal network. It is exceptionally similar to what your home router does.\n\n# User Scenario\n1. Acting as a router at home or in office as a local area network.\n2. Connecting multi-network cameras to Ubuntu Server for transfer image data.\n\n# Terminology\n1. **interface** is used to mean the operating system's name for a place which sends or receives data packets. It is often, but not necessarily, the same as a device. An interface may have several devices associated (e.g. a bridge), or a single device may have several interfaces. device will refer here to the bit of hardware dealing with your network connections. \n2. A **network adapter** is the component of a computer’s internal hardware that is used for communicating over a network with another computer. It enable a computer to connect with another computer, server or any networking device over an LAN connection. A network adapter can be used over a wired or wireless network.\n3. A **gateway** is a piece of networking hardware used in telecommunications for telecommunications networks that allows data to flow from one discrete network to another. Gateways are distinct from routers or switches in that they communicate using more than one protocol to connect a bunch of networks and can operate at any of the seven layers of the open systems interconnection model (OSI). \n\n# Hardware Requirments\nIn our scenario, we need one multi-port network adapters with your desktop PC at the less. One port for connect with external network. Others for connect internal network. Because, we have muti-devices need to connect to internal network, So I recommand, we can using monther-board wired adapter connect with external network and one multi-port PCIE network card connect with internal network. All of PCIE network card can be connect to a bridge. The details how to set-up, I will talk at the below.\n\n**Tips, there are two type of PCIE adapters can be use in our project. First type have POE (Power over Ethernet) support and another type does not support POE. I recommend you buy a PoE support card because when you want to connect a network camera or access point (AP), which can be power by PCIE card directly, you need not unnecessary power cable and power supply to power cameras or APs, this will convience for you. 4 port Gigabit POE network card about 120 US dollars.**\n\n# Settings\n## Configuring the bridge and Network file settings\nLinux supports the implementation of a software network bridge to reproduce the function of a network bridge, a networking device that interconnects two or more communication networks or network segments providing a way for them to work as a single network.\nIt acts almost like a network switch, and in a software sense, it is used to implement the concept of a “virtual network switch”.\n\nIn our scenario, we will use software network bridging to connect all of ports for PCIE network card directly to the host server network.\nIf you want to you also can add your virtual machines(VMs) to this bridge.\nThis way, the all of PCIE ports are deployed on the same subnet as the host and can access services such as DHCP and much more.\n\n### Installing Network Bridge Utilities\nBegin by installing the bridge-utils package which contains utilities for configuring the Ubuntu ethernet bridge using the apt package manager as shown.\n\n```bash\nsudo apt-get update\nsudo apt-get install bridge-utils\n```\n\n### Distinguish External and Internal Interfaces' Name\nIdentify the interface name for your ethernet device using the IP command as shown.\n\n```bash\n$ ip ad\nOR\n$ ip add\n```\n\n![ip add](https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599389099/setting%20up%20an%20ubuntu%20router%20with%20bridge%20-%20ip%20addr.png)\n\nFrom this screenshot, as you can see:\n1. **enp5s0 interface** is my monther-board wired adapter(only have one port) connect with external network\n2. **enp3s0f0 interface**, **enp3s0f1 interface**, **enp3s0f2 interface** and **enp3s0f3 interface** are my PCIE network card (4 ports)\n3. **br0** is my bridge, which connect with all of PCIE ports. The bridge will as internal network. This interface have not yet. Please following the next creating the bridge section.\n\n### Creating and Setting the Bridge at Start-up\nWe need to edit the /etc/network/interfaces file. This file shows an example of a bridge configure.\n\nSample /etc/network/interfaces file\n```\nauto lo\niface lo inet loopback\n\n#External Interface\nauto enp5s0\niface enp5s0 inet dhcp\n\n#bridge\nauto br0\niface br0 inet static\n    address 192.168.1.1\n    network 192.168.1.0\n    netmask 255.255.255.0\n    broadcast 192.168.1.255\n    bridge-ports enp3s0f0 enp3s0f1 enp3s0f2 enp3s0f3\n\n```\n\n** TIPS: please run the below command backup your interfaces file first.\n```bash\ncp /etc/network/interfaces /etc/network/interfaces.backup\n```\nFrom this interface configure file, you can see:\n1. External interface will use Dynamic Host Configuration Protocol (DHCP), whereby external network DHCP server will dynamically assigns an IP adress and other network configuration paprameters to this external interface.\n2. Created a new interface, names *br0*. Using static settings, I manuelly assign IP address 192.168.1.1 to this bridge, when you set-up internal network clients 192.168.1.1 should be the gateway. internal network IP should be 192.168.1.x(x minimum valu is 2, the maxmum value is 255)\n3. All of my PCIE ports connected with this bridge.\n\n** When you finished settings for this section, please restart networking. The command at the below **\n\n```bash\nsudo /etc/init.d/networking restart \n```\n## Enable IP forwarding and Masquerading\nDoing the above might not be enough to make the Ubuntu machine a real router which does NAT (Network Address Translation) and IP Forwarding. The following script configures the Kernel IPTable and IP forwarding. You will have to configure at least the script's 2 variables; the 1st is the external network interface; the 2nd is the internal network interface.\n\n```bash\necho -e \"\\n\\nLoading simple rc.firewall-iptables version $FWVER..\\n\"\nDEPMOD=/sbin/depmod\nMODPROBE=/sbin/modprobe\n\nEXTIF=\"eth0\" # Change eth0 as your External Network Interface Name\nINTIF=\"eth1\" # Change eth1 as bridge name (Internal Network Interface)\n\necho \"   External Interface:  $EXTIF\"\necho \"   Internal Interface:  $INTIF\"\n\n#======================================================================\n#== No editing beyond this line is required for initial MASQ testing == \necho -en \"   loading modules: \"\necho \"  - Verifying that all kernel modules are ok\"\n$DEPMOD -a\necho \"----------------------------------------------------------------------\"\necho -en \"ip_tables, \"\n$MODPROBE ip_tables\necho -en \"nf_conntrack, \" \n$MODPROBE nf_conntrack\necho -en \"nf_conntrack_ftp, \" \n$MODPROBE nf_conntrack_ftp\necho -en \"nf_conntrack_irc, \" \n$MODPROBE nf_conntrack_irc\necho -en \"iptable_nat, \"\n$MODPROBE iptable_nat\necho -en \"nf_nat_ftp, \"\n$MODPROBE nf_nat_ftp\necho \"----------------------------------------------------------------------\"\necho -e \"   Done loading modules.\\n\"\necho \"   Enabling forwarding..\"\necho \"1\" > /proc/sys/net/ipv4/ip_forward\necho \"   Enabling DynamicAddr..\"\necho \"1\" > /proc/sys/net/ipv4/ip_dynaddr \necho \"   Clearing any existing rules and setting default policy..\"\n\niptables-restore <<-EOF\n*nat\n-A POSTROUTING -o \"$EXTIF\" -j MASQUERADE\nCOMMIT\n*filter\n:INPUT ACCEPT [0:0]\n:FORWARD DROP [0:0]\n:OUTPUT ACCEPT [0:0]\n-A FORWARD -i \"$EXTIF\" -o \"$INTIF\" -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT \n-A FORWARD -i \"$INTIF\" -o \"$EXTIF\" -j ACCEPT\n-A FORWARD -j LOG\nCOMMIT\nEOF\n\necho -e \"\\nrc.firewall-iptables v$FWVER done.\\n\"\n```\n\nAfter configuring the 2 variables, save the script below as nat.sh and make it executable by doing\n\n```bash\nchmod a+x nat.sh\n```\n\nNow, test the script by running as root\n\n```bash\nsudo sh nat.sh\n```\n\n## Clients network settings\nEach clients at the less MUST setting the corrent IP address, netmask, gateway and DNS.\n\n** TIPS:\nIf you using the above bridge settings, you can following the below list to set-up your client network interface.\n1. The bridge IP is 192.168.1.1, so your clent IP should be 192.168.1.x (x minimum valu is 2, the maxmum value is 255), all of clients IP must be unique within this internal network(subnet).\n2. netmask should be 255.255.255.0\n3. gateway should be 192.168.1.1, which is bridge's IP address\n4. DNS can be setting as your ISP DNS or public DNS, such as Google's DNS 8.8.8.8, 8.8.4.4\n**\n\n### For Linux\n#### Using ifconfig\nSetting up IP address and Netmask command line\n```bash\nsudo ifconfig eth0 192.168.1.2 netmask 255.255.255.0\n```\n** TIPS: **\n1. eth0 is network interface name, you need change this.\n2. 192.168.1.2 is client IP address you want to set.\n3. netmask 255.255.255.0 is good.\n\nSetting up gateway command line\n```bash\nsudo route add default gw 192.168.1.1 eth0\n```\n\n** TIPS: **\n1. eth0 is network interface name, you need change this.\n2. *gw xxx.xxx.xxx.xxx* is your gateway IP address \n\n#### Ubuntu GUI\n\n![Editing wired connection](https://i0.wp.com/www.opensourceforu.com/wp-content/uploads/2015/03/fig5.png?resize=350%2C374&ssl=1)\n\n### For Mac\n1. On your Mac, choose Apple menu > System Preferences, then click Network.\n2. Select the network connection you want to use (such as Ethernet) in the list.\n3. Choose Manually and enter the address in the IP Address field. Also, subnet mask, gateway, and Domain Name System (DNS) server address.\n\n### For Windows\n1. Open Start on Windows 10.\n2. Search for Command Prompt, right-click the result and select the Run as administrator option to open the console.\n3. Type the following command to see your current networking configuration and press Enter:\n```bash\nipconfig /all\n```\n4. Type the following command to assign a static IP address and press Enter:\n```bash\nnetsh interface ip set address name=\"Ethernet0\" static 192.168.1.2 255.255.255.0 192.168.1.1\n```\nIn the above command make sure to change Ethernet0 for the name of your network adapter, and you must change 192.168.1.2 255.255.255.0 192.168.1.1 with the device IP address, subnet mask, and default gateway address that corresponds to your network configuration.\n\n5. Type the following command to set a DNS server address and press Enter:\n```bash\nnetsh interface ip set dns name=\"Ethernet0\" static 10.1.2.1\n```\nIn the above command make sure to change Ethernet0 with the name of your adapter and 10.1.2.1 with the DNS server address of your network.\n6. Type the following command to set an alternate DNS server address and press Enter:\n```bash\nnetsh interface ip add dns name=\"Ethernet0\" 8.8.8.8 index=2\n```\nIn the above command make sure to change Ethernet0 with the name of your adapter and 8.8.8.8 with an alternate DNS server address.\n\n** After you complete the steps, you can test the new configuration using the ping command (for example, ping google.com) to see if the internet is working. Alternatively, you can simply open your web browser and try to navigate to a website to see if the configuration works. **\n\n# Troubleshooting\n\n\n","slug":"ubuntuRouter","published":1,"updated":"2020-09-26T06:54:05.366Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1aj30013iiiy9m6re4o8","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about how to build a Linux gateway base on Ubuntu OS. The gateway connects an internal network to an external network. Basically, performing Network Address Translation (NAT) for hosts on the internal network. It is exceptionally similar to what your home router does.</p>\n<h1 id=\"User-Scenario\"><a href=\"#User-Scenario\" class=\"headerlink\" title=\"User Scenario\"></a>User Scenario</h1><ol>\n<li>Acting as a router at home or in office as a local area network.</li>\n<li>Connecting multi-network cameras to Ubuntu Server for transfer image data.</li>\n</ol>\n<h1 id=\"Terminology\"><a href=\"#Terminology\" class=\"headerlink\" title=\"Terminology\"></a>Terminology</h1><ol>\n<li><strong>interface</strong> is used to mean the operating system’s name for a place which sends or receives data packets. It is often, but not necessarily, the same as a device. An interface may have several devices associated (e.g. a bridge), or a single device may have several interfaces. device will refer here to the bit of hardware dealing with your network connections. </li>\n<li>A <strong>network adapter</strong> is the component of a computer’s internal hardware that is used for communicating over a network with another computer. It enable a computer to connect with another computer, server or any networking device over an LAN connection. A network adapter can be used over a wired or wireless network.</li>\n<li>A <strong>gateway</strong> is a piece of networking hardware used in telecommunications for telecommunications networks that allows data to flow from one discrete network to another. Gateways are distinct from routers or switches in that they communicate using more than one protocol to connect a bunch of networks and can operate at any of the seven layers of the open systems interconnection model (OSI). </li>\n</ol>\n<h1 id=\"Hardware-Requirments\"><a href=\"#Hardware-Requirments\" class=\"headerlink\" title=\"Hardware Requirments\"></a>Hardware Requirments</h1><p>In our scenario, we need one multi-port network adapters with your desktop PC at the less. One port for connect with external network. Others for connect internal network. Because, we have muti-devices need to connect to internal network, So I recommand, we can using monther-board wired adapter connect with external network and one multi-port PCIE network card connect with internal network. All of PCIE network card can be connect to a bridge. The details how to set-up, I will talk at the below.</p>\n<p><strong>Tips, there are two type of PCIE adapters can be use in our project. First type have POE (Power over Ethernet) support and another type does not support POE. I recommend you buy a PoE support card because when you want to connect a network camera or access point (AP), which can be power by PCIE card directly, you need not unnecessary power cable and power supply to power cameras or APs, this will convience for you. 4 port Gigabit POE network card about 120 US dollars.</strong></p>\n<h1 id=\"Settings\"><a href=\"#Settings\" class=\"headerlink\" title=\"Settings\"></a>Settings</h1><h2 id=\"Configuring-the-bridge-and-Network-file-settings\"><a href=\"#Configuring-the-bridge-and-Network-file-settings\" class=\"headerlink\" title=\"Configuring the bridge and Network file settings\"></a>Configuring the bridge and Network file settings</h2><p>Linux supports the implementation of a software network bridge to reproduce the function of a network bridge, a networking device that interconnects two or more communication networks or network segments providing a way for them to work as a single network.<br>It acts almost like a network switch, and in a software sense, it is used to implement the concept of a “virtual network switch”.</p>\n<p>In our scenario, we will use software network bridging to connect all of ports for PCIE network card directly to the host server network.<br>If you want to you also can add your virtual machines(VMs) to this bridge.<br>This way, the all of PCIE ports are deployed on the same subnet as the host and can access services such as DHCP and much more.</p>\n<h3 id=\"Installing-Network-Bridge-Utilities\"><a href=\"#Installing-Network-Bridge-Utilities\" class=\"headerlink\" title=\"Installing Network Bridge Utilities\"></a>Installing Network Bridge Utilities</h3><p>Begin by installing the bridge-utils package which contains utilities for configuring the Ubuntu ethernet bridge using the apt package manager as shown.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install bridge-utils</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Distinguish-External-and-Internal-Interfaces’-Name\"><a href=\"#Distinguish-External-and-Internal-Interfaces’-Name\" class=\"headerlink\" title=\"Distinguish External and Internal Interfaces’ Name\"></a>Distinguish External and Internal Interfaces’ Name</h3><p>Identify the interface name for your ethernet device using the IP command as shown.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip ad</span><br><span class=\"line\">OR</span><br><span class=\"line\">$ ip add</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599389099/setting%20up%20an%20ubuntu%20router%20with%20bridge%20-%20ip%20addr.png\" alt=\"ip add\"></p>\n<p>From this screenshot, as you can see:</p>\n<ol>\n<li><strong>enp5s0 interface</strong> is my monther-board wired adapter(only have one port) connect with external network</li>\n<li><strong>enp3s0f0 interface</strong>, <strong>enp3s0f1 interface</strong>, <strong>enp3s0f2 interface</strong> and <strong>enp3s0f3 interface</strong> are my PCIE network card (4 ports)</li>\n<li><strong>br0</strong> is my bridge, which connect with all of PCIE ports. The bridge will as internal network. This interface have not yet. Please following the next creating the bridge section.</li>\n</ol>\n<h3 id=\"Creating-and-Setting-the-Bridge-at-Start-up\"><a href=\"#Creating-and-Setting-the-Bridge-at-Start-up\" class=\"headerlink\" title=\"Creating and Setting the Bridge at Start-up\"></a>Creating and Setting the Bridge at Start-up</h3><p>We need to edit the /etc/network/interfaces file. This file shows an example of a bridge configure.</p>\n<p>Sample /etc/network/interfaces file</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto lo</span><br><span class=\"line\">iface lo inet loopback</span><br><span class=\"line\"></span><br><span class=\"line\">#External Interface</span><br><span class=\"line\">auto enp5s0</span><br><span class=\"line\">iface enp5s0 inet dhcp</span><br><span class=\"line\"></span><br><span class=\"line\">#bridge</span><br><span class=\"line\">auto br0</span><br><span class=\"line\">iface br0 inet static</span><br><span class=\"line\">    address 192.168.1.1</span><br><span class=\"line\">    network 192.168.1.0</span><br><span class=\"line\">    netmask 255.255.255.0</span><br><span class=\"line\">    broadcast 192.168.1.255</span><br><span class=\"line\">    bridge-ports enp3s0f0 enp3s0f1 enp3s0f2 enp3s0f3</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>** TIPS: please run the below command backup your interfaces file first.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp /etc/network/interfaces /etc/network/interfaces.backup</span><br></pre></td></tr></table></figure>\n<p>From this interface configure file, you can see:</p>\n<ol>\n<li>External interface will use Dynamic Host Configuration Protocol (DHCP), whereby external network DHCP server will dynamically assigns an IP adress and other network configuration paprameters to this external interface.</li>\n<li>Created a new interface, names <em>br0</em>. Using static settings, I manuelly assign IP address 192.168.1.1 to this bridge, when you set-up internal network clients 192.168.1.1 should be the gateway. internal network IP should be 192.168.1.x(x minimum valu is 2, the maxmum value is 255)</li>\n<li>All of my PCIE ports connected with this bridge.</li>\n</ol>\n<p>** When you finished settings for this section, please restart networking. The command at the below **</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo /etc/init.d/networking restart </span><br></pre></td></tr></table></figure>\n<h2 id=\"Enable-IP-forwarding-and-Masquerading\"><a href=\"#Enable-IP-forwarding-and-Masquerading\" class=\"headerlink\" title=\"Enable IP forwarding and Masquerading\"></a>Enable IP forwarding and Masquerading</h2><p>Doing the above might not be enough to make the Ubuntu machine a real router which does NAT (Network Address Translation) and IP Forwarding. The following script configures the Kernel IPTable and IP forwarding. You will have to configure at least the script’s 2 variables; the 1st is the external network interface; the 2nd is the internal network interface.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\n\\nLoading simple rc.firewall-iptables version <span class=\"variable\">$FWVER</span>..\\n&quot;</span></span><br><span class=\"line\">DEPMOD=/sbin/depmod</span><br><span class=\"line\">MODPROBE=/sbin/modprobe</span><br><span class=\"line\"></span><br><span class=\"line\">EXTIF=<span class=\"string\">&quot;eth0&quot;</span> <span class=\"comment\"># Change eth0 as your External Network Interface Name</span></span><br><span class=\"line\">INTIF=<span class=\"string\">&quot;eth1&quot;</span> <span class=\"comment\"># Change eth1 as bridge name (Internal Network Interface)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   External Interface:  <span class=\"variable\">$EXTIF</span>&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   Internal Interface:  <span class=\"variable\">$INTIF</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#======================================================================</span></span><br><span class=\"line\"><span class=\"comment\">#== No editing beyond this line is required for initial MASQ testing == </span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;   loading modules: &quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;  - Verifying that all kernel modules are ok&quot;</span></span><br><span class=\"line\"><span class=\"variable\">$DEPMOD</span> -a</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;----------------------------------------------------------------------&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;ip_tables, &quot;</span></span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> ip_tables</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;nf_conntrack, &quot;</span> </span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> nf_conntrack</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;nf_conntrack_ftp, &quot;</span> </span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> nf_conntrack_ftp</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;nf_conntrack_irc, &quot;</span> </span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> nf_conntrack_irc</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;iptable_nat, &quot;</span></span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> iptable_nat</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;nf_nat_ftp, &quot;</span></span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> nf_nat_ftp</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;----------------------------------------------------------------------&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;   Done loading modules.\\n&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   Enabling forwarding..&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;1&quot;</span> &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   Enabling DynamicAddr..&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;1&quot;</span> &gt; /proc/sys/net/ipv4/ip_dynaddr </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   Clearing any existing rules and setting default policy..&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">iptables-restore &lt;&lt;-EOF</span><br><span class=\"line\">*nat</span><br><span class=\"line\">-A POSTROUTING -o <span class=\"string\">&quot;<span class=\"variable\">$EXTIF</span>&quot;</span> -j MASQUERADE</span><br><span class=\"line\">COMMIT</span><br><span class=\"line\">*filter</span><br><span class=\"line\">:INPUT ACCEPT [0:0]</span><br><span class=\"line\">:FORWARD DROP [0:0]</span><br><span class=\"line\">:OUTPUT ACCEPT [0:0]</span><br><span class=\"line\">-A FORWARD -i <span class=\"string\">&quot;<span class=\"variable\">$EXTIF</span>&quot;</span> -o <span class=\"string\">&quot;<span class=\"variable\">$INTIF</span>&quot;</span> -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT </span><br><span class=\"line\">-A FORWARD -i <span class=\"string\">&quot;<span class=\"variable\">$INTIF</span>&quot;</span> -o <span class=\"string\">&quot;<span class=\"variable\">$EXTIF</span>&quot;</span> -j ACCEPT</span><br><span class=\"line\">-A FORWARD -j LOG</span><br><span class=\"line\">COMMIT</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\nrc.firewall-iptables v<span class=\"variable\">$FWVER</span> done.\\n&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>After configuring the 2 variables, save the script below as nat.sh and make it executable by doing</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x nat.sh</span><br></pre></td></tr></table></figure>\n\n<p>Now, test the script by running as root</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sh nat.sh</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Clients-network-settings\"><a href=\"#Clients-network-settings\" class=\"headerlink\" title=\"Clients network settings\"></a>Clients network settings</h2><p>Each clients at the less MUST setting the corrent IP address, netmask, gateway and DNS.</p>\n<p>** TIPS:<br>If you using the above bridge settings, you can following the below list to set-up your client network interface.</p>\n<ol>\n<li>The bridge IP is 192.168.1.1, so your clent IP should be 192.168.1.x (x minimum valu is 2, the maxmum value is 255), all of clients IP must be unique within this internal network(subnet).</li>\n<li>netmask should be 255.255.255.0</li>\n<li>gateway should be 192.168.1.1, which is bridge’s IP address</li>\n<li>DNS can be setting as your ISP DNS or public DNS, such as Google’s DNS 8.8.8.8, 8.8.4.4</li>\n</ol>\n<p>**</p>\n<h3 id=\"For-Linux\"><a href=\"#For-Linux\" class=\"headerlink\" title=\"For Linux\"></a>For Linux</h3><h4 id=\"Using-ifconfig\"><a href=\"#Using-ifconfig\" class=\"headerlink\" title=\"Using ifconfig\"></a>Using ifconfig</h4><p>Setting up IP address and Netmask command line</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ifconfig eth0 192.168.1.2 netmask 255.255.255.0</span><br></pre></td></tr></table></figure>\n<p>** TIPS: **</p>\n<ol>\n<li>eth0 is network interface name, you need change this.</li>\n<li>192.168.1.2 is client IP address you want to set.</li>\n<li>netmask 255.255.255.0 is good.</li>\n</ol>\n<p>Setting up gateway command line</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo route add default gw 192.168.1.1 eth0</span><br></pre></td></tr></table></figure>\n\n<p>** TIPS: **</p>\n<ol>\n<li>eth0 is network interface name, you need change this.</li>\n<li><em>gw xxx.xxx.xxx.xxx</em> is your gateway IP address </li>\n</ol>\n<h4 id=\"Ubuntu-GUI\"><a href=\"#Ubuntu-GUI\" class=\"headerlink\" title=\"Ubuntu GUI\"></a>Ubuntu GUI</h4><p><img src=\"https://i0.wp.com/www.opensourceforu.com/wp-content/uploads/2015/03/fig5.png?resize=350,374&ssl=1\" alt=\"Editing wired connection\"></p>\n<h3 id=\"For-Mac\"><a href=\"#For-Mac\" class=\"headerlink\" title=\"For Mac\"></a>For Mac</h3><ol>\n<li>On your Mac, choose Apple menu &gt; System Preferences, then click Network.</li>\n<li>Select the network connection you want to use (such as Ethernet) in the list.</li>\n<li>Choose Manually and enter the address in the IP Address field. Also, subnet mask, gateway, and Domain Name System (DNS) server address.</li>\n</ol>\n<h3 id=\"For-Windows\"><a href=\"#For-Windows\" class=\"headerlink\" title=\"For Windows\"></a>For Windows</h3><ol>\n<li><p>Open Start on Windows 10.</p>\n</li>\n<li><p>Search for Command Prompt, right-click the result and select the Run as administrator option to open the console.</p>\n</li>\n<li><p>Type the following command to see your current networking configuration and press Enter:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ipconfig /all</span><br></pre></td></tr></table></figure></li>\n<li><p>Type the following command to assign a static IP address and press Enter:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">netsh interface ip <span class=\"built_in\">set</span> address name=<span class=\"string\">&quot;Ethernet0&quot;</span> static 192.168.1.2 255.255.255.0 192.168.1.1</span><br></pre></td></tr></table></figure>\n<p>In the above command make sure to change Ethernet0 for the name of your network adapter, and you must change 192.168.1.2 255.255.255.0 192.168.1.1 with the device IP address, subnet mask, and default gateway address that corresponds to your network configuration.</p>\n</li>\n<li><p>Type the following command to set a DNS server address and press Enter:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">netsh interface ip <span class=\"built_in\">set</span> dns name=<span class=\"string\">&quot;Ethernet0&quot;</span> static 10.1.2.1</span><br></pre></td></tr></table></figure>\n<p>In the above command make sure to change Ethernet0 with the name of your adapter and 10.1.2.1 with the DNS server address of your network.</p>\n</li>\n<li><p>Type the following command to set an alternate DNS server address and press Enter:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">netsh interface ip add dns name=<span class=\"string\">&quot;Ethernet0&quot;</span> 8.8.8.8 index=2</span><br></pre></td></tr></table></figure>\n<p>In the above command make sure to change Ethernet0 with the name of your adapter and 8.8.8.8 with an alternate DNS server address.</p>\n</li>\n</ol>\n<p>** After you complete the steps, you can test the new configuration using the ping command (for example, ping google.com) to see if the internet is working. Alternatively, you can simply open your web browser and try to navigate to a website to see if the configuration works. **</p>\n<h1 id=\"Troubleshooting\"><a href=\"#Troubleshooting\" class=\"headerlink\" title=\"Troubleshooting\"></a>Troubleshooting</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about how to build a Linux gateway base on Ubuntu OS. The gateway connects an internal network to an external network. Basically, performing Network Address Translation (NAT) for hosts on the internal network. It is exceptionally similar to what your home router does.</p>\n<h1 id=\"User-Scenario\"><a href=\"#User-Scenario\" class=\"headerlink\" title=\"User Scenario\"></a>User Scenario</h1><ol>\n<li>Acting as a router at home or in office as a local area network.</li>\n<li>Connecting multi-network cameras to Ubuntu Server for transfer image data.</li>\n</ol>\n<h1 id=\"Terminology\"><a href=\"#Terminology\" class=\"headerlink\" title=\"Terminology\"></a>Terminology</h1><ol>\n<li><strong>interface</strong> is used to mean the operating system’s name for a place which sends or receives data packets. It is often, but not necessarily, the same as a device. An interface may have several devices associated (e.g. a bridge), or a single device may have several interfaces. device will refer here to the bit of hardware dealing with your network connections. </li>\n<li>A <strong>network adapter</strong> is the component of a computer’s internal hardware that is used for communicating over a network with another computer. It enable a computer to connect with another computer, server or any networking device over an LAN connection. A network adapter can be used over a wired or wireless network.</li>\n<li>A <strong>gateway</strong> is a piece of networking hardware used in telecommunications for telecommunications networks that allows data to flow from one discrete network to another. Gateways are distinct from routers or switches in that they communicate using more than one protocol to connect a bunch of networks and can operate at any of the seven layers of the open systems interconnection model (OSI). </li>\n</ol>\n<h1 id=\"Hardware-Requirments\"><a href=\"#Hardware-Requirments\" class=\"headerlink\" title=\"Hardware Requirments\"></a>Hardware Requirments</h1><p>In our scenario, we need one multi-port network adapters with your desktop PC at the less. One port for connect with external network. Others for connect internal network. Because, we have muti-devices need to connect to internal network, So I recommand, we can using monther-board wired adapter connect with external network and one multi-port PCIE network card connect with internal network. All of PCIE network card can be connect to a bridge. The details how to set-up, I will talk at the below.</p>\n<p><strong>Tips, there are two type of PCIE adapters can be use in our project. First type have POE (Power over Ethernet) support and another type does not support POE. I recommend you buy a PoE support card because when you want to connect a network camera or access point (AP), which can be power by PCIE card directly, you need not unnecessary power cable and power supply to power cameras or APs, this will convience for you. 4 port Gigabit POE network card about 120 US dollars.</strong></p>\n<h1 id=\"Settings\"><a href=\"#Settings\" class=\"headerlink\" title=\"Settings\"></a>Settings</h1><h2 id=\"Configuring-the-bridge-and-Network-file-settings\"><a href=\"#Configuring-the-bridge-and-Network-file-settings\" class=\"headerlink\" title=\"Configuring the bridge and Network file settings\"></a>Configuring the bridge and Network file settings</h2><p>Linux supports the implementation of a software network bridge to reproduce the function of a network bridge, a networking device that interconnects two or more communication networks or network segments providing a way for them to work as a single network.<br>It acts almost like a network switch, and in a software sense, it is used to implement the concept of a “virtual network switch”.</p>\n<p>In our scenario, we will use software network bridging to connect all of ports for PCIE network card directly to the host server network.<br>If you want to you also can add your virtual machines(VMs) to this bridge.<br>This way, the all of PCIE ports are deployed on the same subnet as the host and can access services such as DHCP and much more.</p>\n<h3 id=\"Installing-Network-Bridge-Utilities\"><a href=\"#Installing-Network-Bridge-Utilities\" class=\"headerlink\" title=\"Installing Network Bridge Utilities\"></a>Installing Network Bridge Utilities</h3><p>Begin by installing the bridge-utils package which contains utilities for configuring the Ubuntu ethernet bridge using the apt package manager as shown.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install bridge-utils</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Distinguish-External-and-Internal-Interfaces’-Name\"><a href=\"#Distinguish-External-and-Internal-Interfaces’-Name\" class=\"headerlink\" title=\"Distinguish External and Internal Interfaces’ Name\"></a>Distinguish External and Internal Interfaces’ Name</h3><p>Identify the interface name for your ethernet device using the IP command as shown.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip ad</span><br><span class=\"line\">OR</span><br><span class=\"line\">$ ip add</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://res.cloudinary.com/dkvj6mo4c/image/upload/v1599389099/setting%20up%20an%20ubuntu%20router%20with%20bridge%20-%20ip%20addr.png\" alt=\"ip add\"></p>\n<p>From this screenshot, as you can see:</p>\n<ol>\n<li><strong>enp5s0 interface</strong> is my monther-board wired adapter(only have one port) connect with external network</li>\n<li><strong>enp3s0f0 interface</strong>, <strong>enp3s0f1 interface</strong>, <strong>enp3s0f2 interface</strong> and <strong>enp3s0f3 interface</strong> are my PCIE network card (4 ports)</li>\n<li><strong>br0</strong> is my bridge, which connect with all of PCIE ports. The bridge will as internal network. This interface have not yet. Please following the next creating the bridge section.</li>\n</ol>\n<h3 id=\"Creating-and-Setting-the-Bridge-at-Start-up\"><a href=\"#Creating-and-Setting-the-Bridge-at-Start-up\" class=\"headerlink\" title=\"Creating and Setting the Bridge at Start-up\"></a>Creating and Setting the Bridge at Start-up</h3><p>We need to edit the /etc/network/interfaces file. This file shows an example of a bridge configure.</p>\n<p>Sample /etc/network/interfaces file</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto lo</span><br><span class=\"line\">iface lo inet loopback</span><br><span class=\"line\"></span><br><span class=\"line\">#External Interface</span><br><span class=\"line\">auto enp5s0</span><br><span class=\"line\">iface enp5s0 inet dhcp</span><br><span class=\"line\"></span><br><span class=\"line\">#bridge</span><br><span class=\"line\">auto br0</span><br><span class=\"line\">iface br0 inet static</span><br><span class=\"line\">    address 192.168.1.1</span><br><span class=\"line\">    network 192.168.1.0</span><br><span class=\"line\">    netmask 255.255.255.0</span><br><span class=\"line\">    broadcast 192.168.1.255</span><br><span class=\"line\">    bridge-ports enp3s0f0 enp3s0f1 enp3s0f2 enp3s0f3</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>** TIPS: please run the below command backup your interfaces file first.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp /etc/network/interfaces /etc/network/interfaces.backup</span><br></pre></td></tr></table></figure>\n<p>From this interface configure file, you can see:</p>\n<ol>\n<li>External interface will use Dynamic Host Configuration Protocol (DHCP), whereby external network DHCP server will dynamically assigns an IP adress and other network configuration paprameters to this external interface.</li>\n<li>Created a new interface, names <em>br0</em>. Using static settings, I manuelly assign IP address 192.168.1.1 to this bridge, when you set-up internal network clients 192.168.1.1 should be the gateway. internal network IP should be 192.168.1.x(x minimum valu is 2, the maxmum value is 255)</li>\n<li>All of my PCIE ports connected with this bridge.</li>\n</ol>\n<p>** When you finished settings for this section, please restart networking. The command at the below **</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo /etc/init.d/networking restart </span><br></pre></td></tr></table></figure>\n<h2 id=\"Enable-IP-forwarding-and-Masquerading\"><a href=\"#Enable-IP-forwarding-and-Masquerading\" class=\"headerlink\" title=\"Enable IP forwarding and Masquerading\"></a>Enable IP forwarding and Masquerading</h2><p>Doing the above might not be enough to make the Ubuntu machine a real router which does NAT (Network Address Translation) and IP Forwarding. The following script configures the Kernel IPTable and IP forwarding. You will have to configure at least the script’s 2 variables; the 1st is the external network interface; the 2nd is the internal network interface.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\n\\nLoading simple rc.firewall-iptables version <span class=\"variable\">$FWVER</span>..\\n&quot;</span></span><br><span class=\"line\">DEPMOD=/sbin/depmod</span><br><span class=\"line\">MODPROBE=/sbin/modprobe</span><br><span class=\"line\"></span><br><span class=\"line\">EXTIF=<span class=\"string\">&quot;eth0&quot;</span> <span class=\"comment\"># Change eth0 as your External Network Interface Name</span></span><br><span class=\"line\">INTIF=<span class=\"string\">&quot;eth1&quot;</span> <span class=\"comment\"># Change eth1 as bridge name (Internal Network Interface)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   External Interface:  <span class=\"variable\">$EXTIF</span>&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   Internal Interface:  <span class=\"variable\">$INTIF</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#======================================================================</span></span><br><span class=\"line\"><span class=\"comment\">#== No editing beyond this line is required for initial MASQ testing == </span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;   loading modules: &quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;  - Verifying that all kernel modules are ok&quot;</span></span><br><span class=\"line\"><span class=\"variable\">$DEPMOD</span> -a</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;----------------------------------------------------------------------&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;ip_tables, &quot;</span></span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> ip_tables</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;nf_conntrack, &quot;</span> </span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> nf_conntrack</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;nf_conntrack_ftp, &quot;</span> </span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> nf_conntrack_ftp</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;nf_conntrack_irc, &quot;</span> </span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> nf_conntrack_irc</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;iptable_nat, &quot;</span></span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> iptable_nat</span><br><span class=\"line\"><span class=\"built_in\">echo</span> -en <span class=\"string\">&quot;nf_nat_ftp, &quot;</span></span><br><span class=\"line\"><span class=\"variable\">$MODPROBE</span> nf_nat_ftp</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;----------------------------------------------------------------------&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;   Done loading modules.\\n&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   Enabling forwarding..&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;1&quot;</span> &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   Enabling DynamicAddr..&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;1&quot;</span> &gt; /proc/sys/net/ipv4/ip_dynaddr </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;   Clearing any existing rules and setting default policy..&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">iptables-restore &lt;&lt;-EOF</span><br><span class=\"line\">*nat</span><br><span class=\"line\">-A POSTROUTING -o <span class=\"string\">&quot;<span class=\"variable\">$EXTIF</span>&quot;</span> -j MASQUERADE</span><br><span class=\"line\">COMMIT</span><br><span class=\"line\">*filter</span><br><span class=\"line\">:INPUT ACCEPT [0:0]</span><br><span class=\"line\">:FORWARD DROP [0:0]</span><br><span class=\"line\">:OUTPUT ACCEPT [0:0]</span><br><span class=\"line\">-A FORWARD -i <span class=\"string\">&quot;<span class=\"variable\">$EXTIF</span>&quot;</span> -o <span class=\"string\">&quot;<span class=\"variable\">$INTIF</span>&quot;</span> -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT </span><br><span class=\"line\">-A FORWARD -i <span class=\"string\">&quot;<span class=\"variable\">$INTIF</span>&quot;</span> -o <span class=\"string\">&quot;<span class=\"variable\">$EXTIF</span>&quot;</span> -j ACCEPT</span><br><span class=\"line\">-A FORWARD -j LOG</span><br><span class=\"line\">COMMIT</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\nrc.firewall-iptables v<span class=\"variable\">$FWVER</span> done.\\n&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>After configuring the 2 variables, save the script below as nat.sh and make it executable by doing</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod a+x nat.sh</span><br></pre></td></tr></table></figure>\n\n<p>Now, test the script by running as root</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sh nat.sh</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Clients-network-settings\"><a href=\"#Clients-network-settings\" class=\"headerlink\" title=\"Clients network settings\"></a>Clients network settings</h2><p>Each clients at the less MUST setting the corrent IP address, netmask, gateway and DNS.</p>\n<p>** TIPS:<br>If you using the above bridge settings, you can following the below list to set-up your client network interface.</p>\n<ol>\n<li>The bridge IP is 192.168.1.1, so your clent IP should be 192.168.1.x (x minimum valu is 2, the maxmum value is 255), all of clients IP must be unique within this internal network(subnet).</li>\n<li>netmask should be 255.255.255.0</li>\n<li>gateway should be 192.168.1.1, which is bridge’s IP address</li>\n<li>DNS can be setting as your ISP DNS or public DNS, such as Google’s DNS 8.8.8.8, 8.8.4.4</li>\n</ol>\n<p>**</p>\n<h3 id=\"For-Linux\"><a href=\"#For-Linux\" class=\"headerlink\" title=\"For Linux\"></a>For Linux</h3><h4 id=\"Using-ifconfig\"><a href=\"#Using-ifconfig\" class=\"headerlink\" title=\"Using ifconfig\"></a>Using ifconfig</h4><p>Setting up IP address and Netmask command line</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ifconfig eth0 192.168.1.2 netmask 255.255.255.0</span><br></pre></td></tr></table></figure>\n<p>** TIPS: **</p>\n<ol>\n<li>eth0 is network interface name, you need change this.</li>\n<li>192.168.1.2 is client IP address you want to set.</li>\n<li>netmask 255.255.255.0 is good.</li>\n</ol>\n<p>Setting up gateway command line</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo route add default gw 192.168.1.1 eth0</span><br></pre></td></tr></table></figure>\n\n<p>** TIPS: **</p>\n<ol>\n<li>eth0 is network interface name, you need change this.</li>\n<li><em>gw xxx.xxx.xxx.xxx</em> is your gateway IP address </li>\n</ol>\n<h4 id=\"Ubuntu-GUI\"><a href=\"#Ubuntu-GUI\" class=\"headerlink\" title=\"Ubuntu GUI\"></a>Ubuntu GUI</h4><p><img src=\"https://i0.wp.com/www.opensourceforu.com/wp-content/uploads/2015/03/fig5.png?resize=350,374&ssl=1\" alt=\"Editing wired connection\"></p>\n<h3 id=\"For-Mac\"><a href=\"#For-Mac\" class=\"headerlink\" title=\"For Mac\"></a>For Mac</h3><ol>\n<li>On your Mac, choose Apple menu &gt; System Preferences, then click Network.</li>\n<li>Select the network connection you want to use (such as Ethernet) in the list.</li>\n<li>Choose Manually and enter the address in the IP Address field. Also, subnet mask, gateway, and Domain Name System (DNS) server address.</li>\n</ol>\n<h3 id=\"For-Windows\"><a href=\"#For-Windows\" class=\"headerlink\" title=\"For Windows\"></a>For Windows</h3><ol>\n<li><p>Open Start on Windows 10.</p>\n</li>\n<li><p>Search for Command Prompt, right-click the result and select the Run as administrator option to open the console.</p>\n</li>\n<li><p>Type the following command to see your current networking configuration and press Enter:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ipconfig /all</span><br></pre></td></tr></table></figure></li>\n<li><p>Type the following command to assign a static IP address and press Enter:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">netsh interface ip <span class=\"built_in\">set</span> address name=<span class=\"string\">&quot;Ethernet0&quot;</span> static 192.168.1.2 255.255.255.0 192.168.1.1</span><br></pre></td></tr></table></figure>\n<p>In the above command make sure to change Ethernet0 for the name of your network adapter, and you must change 192.168.1.2 255.255.255.0 192.168.1.1 with the device IP address, subnet mask, and default gateway address that corresponds to your network configuration.</p>\n</li>\n<li><p>Type the following command to set a DNS server address and press Enter:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">netsh interface ip <span class=\"built_in\">set</span> dns name=<span class=\"string\">&quot;Ethernet0&quot;</span> static 10.1.2.1</span><br></pre></td></tr></table></figure>\n<p>In the above command make sure to change Ethernet0 with the name of your adapter and 10.1.2.1 with the DNS server address of your network.</p>\n</li>\n<li><p>Type the following command to set an alternate DNS server address and press Enter:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">netsh interface ip add dns name=<span class=\"string\">&quot;Ethernet0&quot;</span> 8.8.8.8 index=2</span><br></pre></td></tr></table></figure>\n<p>In the above command make sure to change Ethernet0 with the name of your adapter and 8.8.8.8 with an alternate DNS server address.</p>\n</li>\n</ol>\n<p>** After you complete the steps, you can test the new configuration using the ping command (for example, ping google.com) to see if the internet is working. Alternatively, you can simply open your web browser and try to navigate to a website to see if the configuration works. **</p>\n<h1 id=\"Troubleshooting\"><a href=\"#Troubleshooting\" class=\"headerlink\" title=\"Troubleshooting\"></a>Troubleshooting</h1>"},{"title":"VIM Keyboard Shortcuts Cheatsheet","date":"2020-09-07T11:26:32.000Z","_content":"\n# Introduction\nThis post document is brief introduction about how to use VIM/VI text editor and help you remember the shortcuts. The Vim editor is a command-line based tool that’s an enhanced version of the venerable vi editor. Despite the abundance of graphical rich text editors, familiarity with Vim will help every Linux user – from an experienced system administrator to a newbie Raspberry Pi user.\n\nOne important thing to note when using Vim, is that the function of a key depends on the “mode” the editor is in. For example, pressing the alphabet “j” will move the cursor down one line in the “command mode”. You’ll have to switch to the “insert mode” to make the keys input the character they represent.\n\n**TIPS:**\n1. ![Book reference - Learning the Vi and Vim Editors](http://gen.lib.rus.ec/book/index.php?md5=BC6FB75F968BCC39E4446C29BF04D2D1)\n2. I recommend you using [Spacemacs](https://github.com/syl20bnr/spacemacs), which is a new way to experience Emacs, you can use VI's editing styles with emacs' extendibility.\n\n# User Scenario\n1. Most of Embedded system have not GUI avabliable. Nowadays, edge computing become poplar, using command-line text editor can be inportance for configure Edge Devices.\n2. Cloud Virual Machine(VM) - marjor of VM only support using SSH login, when you login the cloud VM, CLI will be the only way.\n\n# Cheatsheet\nHere’s a cheatsheet to help you get the most out of Vim.\n\n| **Shortcut Keys** | **Function** |\n| ----------------- |:------------:|\n| **Main (Change Mode)**\t    |\t\t   |\n| Escape key\t    | Gets out of the current mode into the “command mode”. All keys are bound of commands.|\n| i\t\t    | \"Insert mode\" for inserting text. Keys behave as expected.|\n| :\t\t    | \"Last-line mode\" where Vim expects you to enter a command such as to save the document.|\n| v\t\t    | Enter \"visual mode\" |\n| **Navigation keys (used in command mode)** |\t|\n|h\t|moves the cursor one character to the left|\n|j or Ctrl + J\t|moves the cursor down one line|\n|k or Ctrl + P\t|moves the cursor up one line|\n|l\t|moves the cursor one character to the right|\n|0\t|moves the cursor to the beginning of the line|\n|$\t|moves the cursor to the end of the line|\n|^\t|moves the cursor to the first non-empty character of the line|\n|w\t|move forward one word (next alphanumeric word)|\n|W\t|move forward one word (delimited by a white space)|\n|5w\t|move forward five words|\n|b\t|move backward one word (previous alphanumeric word)|\n|B\t|move backward one word (delimited by a white space)|\n|5b\t|move backward five words|\n|G\t|move to the end of the file|\n|gg\t|move to the beginning of the file|\n| **Navigate around the document** |\t|\n|(\t|jumps to the previous sentence|\n|)\t|jumps to the next sentence|\n|{\t|jumps to the previous paragraph|\n|}\t|jumps to the next paragraph|\n|[[\t|jumps to the previous section|\n|]]\t|jumps to the next section|\n|[]\t|jump to the end of the previous section|\n|][\t|jump to the end of the next section|\n| **Insert text** |\t|\n|a\t|Insert text after the cursor|\n|A\t|Insert text at the end of the line|\n|i\t|Insert text before the cursor|\n|o\t|Begin a new line below the cursor|\n|O\t|Begin a new line above the cursor|\n| **Special inserts** |\t\t|\n|:r [filename]\t|Insert the file [filename] below the cursor|\n|:r ![command]\t|Execute [command] and insert its output below the cursor|\n| **Delete text** |\t|\n|x\t|delete character at cursor|\n|dw\t|delete a word|\n|d0\t|delete to the beginning of a line|\n|d$\t|delete to the end of a line|\n|d)\t|delete to the end of sentence|\n|dgg\t|delete to the beginning of the file|\n|dG\t|delete to the end of the file|\n|dd\t|delete line|\n|3dd\t|delete three lines|\n| **Simple replace text** |\t|\n|r{text}\t|Replace the character under the cursor with {text}|\n|R\t|Replace characters instead of inserting them|\n| **Copy/Paste text** |\t\t|\n|yy\t|copy current line into storage buffer|\n|[\"x]yy\t|Copy the current lines into register x|\n|p\t|paste storage buffer after current line|\n|P\t|paste storage buffer before current line|\n|[\"x]p\t|paste from register x after current line|\n|[\"x]P\t|paste from register x before current line|\n| **Undo/Redo operation** |\t|\n|u\t|undo the last operation|\n|Ctrl+r\t|redo the last undo|\n| **Search and Replace keys** |\t\t|\n|/search_text\t|search document for search_text going forward|\n|?search_text\t|search document for search_text going backward|\n|n\t|move to the next instance of the result from the search|\n|N\t|move to the previous instance of the result|\n|:%s/original/replacement\t|Search for the first occurrence of the string \"original\" and replace it with \"replacement\"|\n|:%s/original/replacement/g\t|Search and replace all occurrences of the string \"original\" with \"replacement\"|\n|:%s/original/replacement/gc\t|Search for all occurrences of the string “original” but ask for confirmation before replacing them with \"replacement\"|\n| **Bookmarks** |\t|\n|m {a-z A-Z}\t|Set bookmark {a-z A-Z} at the current cursor position|\n|:marks\t\t|List all bookmarks|\n|`{a-z A-Z}\t|Jumps to the bookmark {a-z A-Z}|\n| **Select text** |\t|\n|v\t|Enter visual mode per character|\n|V\t|Enter visual mode per line|\n|Esc\t|Exit visual mode|\n| **Modify selected text (used in visual mode)** |\t|\n|~\t|Switch case|\n|d\t|delete a word|\n|c\t|change|\n|y\t|yank|\n|>\t|shift right|\n|<\t|shift left|\n|!\t|filter through an external command|\n| **Save and quit** |\t\t|\n|:q\t|Quits Vim but fails when file has been changed|\n|:w\t|Save the file|\n|:w new_name\t|Save the file with the new_name filename|\n|:wq\t|Save the file and quit Vim|\n|:q!\t|Quit Vim without saving the changes to the file|\n|ZZ\t|Write file, if modified, and quit Vim|\n|ZQ\t|Same as :q! Quits Vim without writing changes|\n\n","source":"_posts/vim.md","raw":"---\ntitle: VIM Keyboard Shortcuts Cheatsheet\ndate: 2020-09-07 11:26:32\ntags:\n - vim\ncategories: editor\n---\n\n# Introduction\nThis post document is brief introduction about how to use VIM/VI text editor and help you remember the shortcuts. The Vim editor is a command-line based tool that’s an enhanced version of the venerable vi editor. Despite the abundance of graphical rich text editors, familiarity with Vim will help every Linux user – from an experienced system administrator to a newbie Raspberry Pi user.\n\nOne important thing to note when using Vim, is that the function of a key depends on the “mode” the editor is in. For example, pressing the alphabet “j” will move the cursor down one line in the “command mode”. You’ll have to switch to the “insert mode” to make the keys input the character they represent.\n\n**TIPS:**\n1. ![Book reference - Learning the Vi and Vim Editors](http://gen.lib.rus.ec/book/index.php?md5=BC6FB75F968BCC39E4446C29BF04D2D1)\n2. I recommend you using [Spacemacs](https://github.com/syl20bnr/spacemacs), which is a new way to experience Emacs, you can use VI's editing styles with emacs' extendibility.\n\n# User Scenario\n1. Most of Embedded system have not GUI avabliable. Nowadays, edge computing become poplar, using command-line text editor can be inportance for configure Edge Devices.\n2. Cloud Virual Machine(VM) - marjor of VM only support using SSH login, when you login the cloud VM, CLI will be the only way.\n\n# Cheatsheet\nHere’s a cheatsheet to help you get the most out of Vim.\n\n| **Shortcut Keys** | **Function** |\n| ----------------- |:------------:|\n| **Main (Change Mode)**\t    |\t\t   |\n| Escape key\t    | Gets out of the current mode into the “command mode”. All keys are bound of commands.|\n| i\t\t    | \"Insert mode\" for inserting text. Keys behave as expected.|\n| :\t\t    | \"Last-line mode\" where Vim expects you to enter a command such as to save the document.|\n| v\t\t    | Enter \"visual mode\" |\n| **Navigation keys (used in command mode)** |\t|\n|h\t|moves the cursor one character to the left|\n|j or Ctrl + J\t|moves the cursor down one line|\n|k or Ctrl + P\t|moves the cursor up one line|\n|l\t|moves the cursor one character to the right|\n|0\t|moves the cursor to the beginning of the line|\n|$\t|moves the cursor to the end of the line|\n|^\t|moves the cursor to the first non-empty character of the line|\n|w\t|move forward one word (next alphanumeric word)|\n|W\t|move forward one word (delimited by a white space)|\n|5w\t|move forward five words|\n|b\t|move backward one word (previous alphanumeric word)|\n|B\t|move backward one word (delimited by a white space)|\n|5b\t|move backward five words|\n|G\t|move to the end of the file|\n|gg\t|move to the beginning of the file|\n| **Navigate around the document** |\t|\n|(\t|jumps to the previous sentence|\n|)\t|jumps to the next sentence|\n|{\t|jumps to the previous paragraph|\n|}\t|jumps to the next paragraph|\n|[[\t|jumps to the previous section|\n|]]\t|jumps to the next section|\n|[]\t|jump to the end of the previous section|\n|][\t|jump to the end of the next section|\n| **Insert text** |\t|\n|a\t|Insert text after the cursor|\n|A\t|Insert text at the end of the line|\n|i\t|Insert text before the cursor|\n|o\t|Begin a new line below the cursor|\n|O\t|Begin a new line above the cursor|\n| **Special inserts** |\t\t|\n|:r [filename]\t|Insert the file [filename] below the cursor|\n|:r ![command]\t|Execute [command] and insert its output below the cursor|\n| **Delete text** |\t|\n|x\t|delete character at cursor|\n|dw\t|delete a word|\n|d0\t|delete to the beginning of a line|\n|d$\t|delete to the end of a line|\n|d)\t|delete to the end of sentence|\n|dgg\t|delete to the beginning of the file|\n|dG\t|delete to the end of the file|\n|dd\t|delete line|\n|3dd\t|delete three lines|\n| **Simple replace text** |\t|\n|r{text}\t|Replace the character under the cursor with {text}|\n|R\t|Replace characters instead of inserting them|\n| **Copy/Paste text** |\t\t|\n|yy\t|copy current line into storage buffer|\n|[\"x]yy\t|Copy the current lines into register x|\n|p\t|paste storage buffer after current line|\n|P\t|paste storage buffer before current line|\n|[\"x]p\t|paste from register x after current line|\n|[\"x]P\t|paste from register x before current line|\n| **Undo/Redo operation** |\t|\n|u\t|undo the last operation|\n|Ctrl+r\t|redo the last undo|\n| **Search and Replace keys** |\t\t|\n|/search_text\t|search document for search_text going forward|\n|?search_text\t|search document for search_text going backward|\n|n\t|move to the next instance of the result from the search|\n|N\t|move to the previous instance of the result|\n|:%s/original/replacement\t|Search for the first occurrence of the string \"original\" and replace it with \"replacement\"|\n|:%s/original/replacement/g\t|Search and replace all occurrences of the string \"original\" with \"replacement\"|\n|:%s/original/replacement/gc\t|Search for all occurrences of the string “original” but ask for confirmation before replacing them with \"replacement\"|\n| **Bookmarks** |\t|\n|m {a-z A-Z}\t|Set bookmark {a-z A-Z} at the current cursor position|\n|:marks\t\t|List all bookmarks|\n|`{a-z A-Z}\t|Jumps to the bookmark {a-z A-Z}|\n| **Select text** |\t|\n|v\t|Enter visual mode per character|\n|V\t|Enter visual mode per line|\n|Esc\t|Exit visual mode|\n| **Modify selected text (used in visual mode)** |\t|\n|~\t|Switch case|\n|d\t|delete a word|\n|c\t|change|\n|y\t|yank|\n|>\t|shift right|\n|<\t|shift left|\n|!\t|filter through an external command|\n| **Save and quit** |\t\t|\n|:q\t|Quits Vim but fails when file has been changed|\n|:w\t|Save the file|\n|:w new_name\t|Save the file with the new_name filename|\n|:wq\t|Save the file and quit Vim|\n|:q!\t|Quit Vim without saving the changes to the file|\n|ZZ\t|Write file, if modified, and quit Vim|\n|ZQ\t|Same as :q! Quits Vim without writing changes|\n\n","slug":"vim","published":1,"updated":"2020-09-07T08:43:30.232Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1ajd002siiiycqnh9bbm","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is brief introduction about how to use VIM/VI text editor and help you remember the shortcuts. The Vim editor is a command-line based tool that’s an enhanced version of the venerable vi editor. Despite the abundance of graphical rich text editors, familiarity with Vim will help every Linux user – from an experienced system administrator to a newbie Raspberry Pi user.</p>\n<p>One important thing to note when using Vim, is that the function of a key depends on the “mode” the editor is in. For example, pressing the alphabet “j” will move the cursor down one line in the “command mode”. You’ll have to switch to the “insert mode” to make the keys input the character they represent.</p>\n<p><strong>TIPS:</strong></p>\n<ol>\n<li><img src=\"http://gen.lib.rus.ec/book/index.php?md5=BC6FB75F968BCC39E4446C29BF04D2D1\" alt=\"Book reference - Learning the Vi and Vim Editors\"></li>\n<li>I recommend you using <a href=\"https://github.com/syl20bnr/spacemacs\">Spacemacs</a>, which is a new way to experience Emacs, you can use VI’s editing styles with emacs’ extendibility.</li>\n</ol>\n<h1 id=\"User-Scenario\"><a href=\"#User-Scenario\" class=\"headerlink\" title=\"User Scenario\"></a>User Scenario</h1><ol>\n<li>Most of Embedded system have not GUI avabliable. Nowadays, edge computing become poplar, using command-line text editor can be inportance for configure Edge Devices.</li>\n<li>Cloud Virual Machine(VM) - marjor of VM only support using SSH login, when you login the cloud VM, CLI will be the only way.</li>\n</ol>\n<h1 id=\"Cheatsheet\"><a href=\"#Cheatsheet\" class=\"headerlink\" title=\"Cheatsheet\"></a>Cheatsheet</h1><p>Here’s a cheatsheet to help you get the most out of Vim.</p>\n<table>\n<thead>\n<tr>\n<th><strong>Shortcut Keys</strong></th>\n<th align=\"center\"><strong>Function</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Main (Change Mode)</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>Escape key</td>\n<td align=\"center\">Gets out of the current mode into the “command mode”. All keys are bound of commands.</td>\n</tr>\n<tr>\n<td>i</td>\n<td align=\"center\">“Insert mode” for inserting text. Keys behave as expected.</td>\n</tr>\n<tr>\n<td>:</td>\n<td align=\"center\">“Last-line mode” where Vim expects you to enter a command such as to save the document.</td>\n</tr>\n<tr>\n<td>v</td>\n<td align=\"center\">Enter “visual mode”</td>\n</tr>\n<tr>\n<td><strong>Navigation keys (used in command mode)</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>h</td>\n<td align=\"center\">moves the cursor one character to the left</td>\n</tr>\n<tr>\n<td>j or Ctrl + J</td>\n<td align=\"center\">moves the cursor down one line</td>\n</tr>\n<tr>\n<td>k or Ctrl + P</td>\n<td align=\"center\">moves the cursor up one line</td>\n</tr>\n<tr>\n<td>l</td>\n<td align=\"center\">moves the cursor one character to the right</td>\n</tr>\n<tr>\n<td>0</td>\n<td align=\"center\">moves the cursor to the beginning of the line</td>\n</tr>\n<tr>\n<td>$</td>\n<td align=\"center\">moves the cursor to the end of the line</td>\n</tr>\n<tr>\n<td>^</td>\n<td align=\"center\">moves the cursor to the first non-empty character of the line</td>\n</tr>\n<tr>\n<td>w</td>\n<td align=\"center\">move forward one word (next alphanumeric word)</td>\n</tr>\n<tr>\n<td>W</td>\n<td align=\"center\">move forward one word (delimited by a white space)</td>\n</tr>\n<tr>\n<td>5w</td>\n<td align=\"center\">move forward five words</td>\n</tr>\n<tr>\n<td>b</td>\n<td align=\"center\">move backward one word (previous alphanumeric word)</td>\n</tr>\n<tr>\n<td>B</td>\n<td align=\"center\">move backward one word (delimited by a white space)</td>\n</tr>\n<tr>\n<td>5b</td>\n<td align=\"center\">move backward five words</td>\n</tr>\n<tr>\n<td>G</td>\n<td align=\"center\">move to the end of the file</td>\n</tr>\n<tr>\n<td>gg</td>\n<td align=\"center\">move to the beginning of the file</td>\n</tr>\n<tr>\n<td><strong>Navigate around the document</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>(</td>\n<td align=\"center\">jumps to the previous sentence</td>\n</tr>\n<tr>\n<td>)</td>\n<td align=\"center\">jumps to the next sentence</td>\n</tr>\n<tr>\n<td>{</td>\n<td align=\"center\">jumps to the previous paragraph</td>\n</tr>\n<tr>\n<td>}</td>\n<td align=\"center\">jumps to the next paragraph</td>\n</tr>\n<tr>\n<td>[[</td>\n<td align=\"center\">jumps to the previous section</td>\n</tr>\n<tr>\n<td>]]</td>\n<td align=\"center\">jumps to the next section</td>\n</tr>\n<tr>\n<td>[]</td>\n<td align=\"center\">jump to the end of the previous section</td>\n</tr>\n<tr>\n<td>][</td>\n<td align=\"center\">jump to the end of the next section</td>\n</tr>\n<tr>\n<td><strong>Insert text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>a</td>\n<td align=\"center\">Insert text after the cursor</td>\n</tr>\n<tr>\n<td>A</td>\n<td align=\"center\">Insert text at the end of the line</td>\n</tr>\n<tr>\n<td>i</td>\n<td align=\"center\">Insert text before the cursor</td>\n</tr>\n<tr>\n<td>o</td>\n<td align=\"center\">Begin a new line below the cursor</td>\n</tr>\n<tr>\n<td>O</td>\n<td align=\"center\">Begin a new line above the cursor</td>\n</tr>\n<tr>\n<td><strong>Special inserts</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>:r [filename]</td>\n<td align=\"center\">Insert the file [filename] below the cursor</td>\n</tr>\n<tr>\n<td>:r ![command]</td>\n<td align=\"center\">Execute [command] and insert its output below the cursor</td>\n</tr>\n<tr>\n<td><strong>Delete text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>x</td>\n<td align=\"center\">delete character at cursor</td>\n</tr>\n<tr>\n<td>dw</td>\n<td align=\"center\">delete a word</td>\n</tr>\n<tr>\n<td>d0</td>\n<td align=\"center\">delete to the beginning of a line</td>\n</tr>\n<tr>\n<td>d$</td>\n<td align=\"center\">delete to the end of a line</td>\n</tr>\n<tr>\n<td>d)</td>\n<td align=\"center\">delete to the end of sentence</td>\n</tr>\n<tr>\n<td>dgg</td>\n<td align=\"center\">delete to the beginning of the file</td>\n</tr>\n<tr>\n<td>dG</td>\n<td align=\"center\">delete to the end of the file</td>\n</tr>\n<tr>\n<td>dd</td>\n<td align=\"center\">delete line</td>\n</tr>\n<tr>\n<td>3dd</td>\n<td align=\"center\">delete three lines</td>\n</tr>\n<tr>\n<td><strong>Simple replace text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>r{text}</td>\n<td align=\"center\">Replace the character under the cursor with {text}</td>\n</tr>\n<tr>\n<td>R</td>\n<td align=\"center\">Replace characters instead of inserting them</td>\n</tr>\n<tr>\n<td><strong>Copy/Paste text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>yy</td>\n<td align=\"center\">copy current line into storage buffer</td>\n</tr>\n<tr>\n<td>[“x]yy</td>\n<td align=\"center\">Copy the current lines into register x</td>\n</tr>\n<tr>\n<td>p</td>\n<td align=\"center\">paste storage buffer after current line</td>\n</tr>\n<tr>\n<td>P</td>\n<td align=\"center\">paste storage buffer before current line</td>\n</tr>\n<tr>\n<td>[“x]p</td>\n<td align=\"center\">paste from register x after current line</td>\n</tr>\n<tr>\n<td>[“x]P</td>\n<td align=\"center\">paste from register x before current line</td>\n</tr>\n<tr>\n<td><strong>Undo/Redo operation</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>u</td>\n<td align=\"center\">undo the last operation</td>\n</tr>\n<tr>\n<td>Ctrl+r</td>\n<td align=\"center\">redo the last undo</td>\n</tr>\n<tr>\n<td><strong>Search and Replace keys</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>/search_text</td>\n<td align=\"center\">search document for search_text going forward</td>\n</tr>\n<tr>\n<td>?search_text</td>\n<td align=\"center\">search document for search_text going backward</td>\n</tr>\n<tr>\n<td>n</td>\n<td align=\"center\">move to the next instance of the result from the search</td>\n</tr>\n<tr>\n<td>N</td>\n<td align=\"center\">move to the previous instance of the result</td>\n</tr>\n<tr>\n<td>:%s/original/replacement</td>\n<td align=\"center\">Search for the first occurrence of the string “original” and replace it with “replacement”</td>\n</tr>\n<tr>\n<td>:%s/original/replacement/g</td>\n<td align=\"center\">Search and replace all occurrences of the string “original” with “replacement”</td>\n</tr>\n<tr>\n<td>:%s/original/replacement/gc</td>\n<td align=\"center\">Search for all occurrences of the string “original” but ask for confirmation before replacing them with “replacement”</td>\n</tr>\n<tr>\n<td><strong>Bookmarks</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>m {a-z A-Z}</td>\n<td align=\"center\">Set bookmark {a-z A-Z} at the current cursor position</td>\n</tr>\n<tr>\n<td>:marks</td>\n<td align=\"center\">List all bookmarks</td>\n</tr>\n<tr>\n<td>`{a-z A-Z}</td>\n<td align=\"center\">Jumps to the bookmark {a-z A-Z}</td>\n</tr>\n<tr>\n<td><strong>Select text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>v</td>\n<td align=\"center\">Enter visual mode per character</td>\n</tr>\n<tr>\n<td>V</td>\n<td align=\"center\">Enter visual mode per line</td>\n</tr>\n<tr>\n<td>Esc</td>\n<td align=\"center\">Exit visual mode</td>\n</tr>\n<tr>\n<td><strong>Modify selected text (used in visual mode)</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>~</td>\n<td align=\"center\">Switch case</td>\n</tr>\n<tr>\n<td>d</td>\n<td align=\"center\">delete a word</td>\n</tr>\n<tr>\n<td>c</td>\n<td align=\"center\">change</td>\n</tr>\n<tr>\n<td>y</td>\n<td align=\"center\">yank</td>\n</tr>\n<tr>\n<td>&gt;</td>\n<td align=\"center\">shift right</td>\n</tr>\n<tr>\n<td>&lt;</td>\n<td align=\"center\">shift left</td>\n</tr>\n<tr>\n<td>!</td>\n<td align=\"center\">filter through an external command</td>\n</tr>\n<tr>\n<td><strong>Save and quit</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>:q</td>\n<td align=\"center\">Quits Vim but fails when file has been changed</td>\n</tr>\n<tr>\n<td>:w</td>\n<td align=\"center\">Save the file</td>\n</tr>\n<tr>\n<td>:w new_name</td>\n<td align=\"center\">Save the file with the new_name filename</td>\n</tr>\n<tr>\n<td>:wq</td>\n<td align=\"center\">Save the file and quit Vim</td>\n</tr>\n<tr>\n<td>:q!</td>\n<td align=\"center\">Quit Vim without saving the changes to the file</td>\n</tr>\n<tr>\n<td>ZZ</td>\n<td align=\"center\">Write file, if modified, and quit Vim</td>\n</tr>\n<tr>\n<td>ZQ</td>\n<td align=\"center\">Same as :q! Quits Vim without writing changes</td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is brief introduction about how to use VIM/VI text editor and help you remember the shortcuts. The Vim editor is a command-line based tool that’s an enhanced version of the venerable vi editor. Despite the abundance of graphical rich text editors, familiarity with Vim will help every Linux user – from an experienced system administrator to a newbie Raspberry Pi user.</p>\n<p>One important thing to note when using Vim, is that the function of a key depends on the “mode” the editor is in. For example, pressing the alphabet “j” will move the cursor down one line in the “command mode”. You’ll have to switch to the “insert mode” to make the keys input the character they represent.</p>\n<p><strong>TIPS:</strong></p>\n<ol>\n<li><img src=\"http://gen.lib.rus.ec/book/index.php?md5=BC6FB75F968BCC39E4446C29BF04D2D1\" alt=\"Book reference - Learning the Vi and Vim Editors\"></li>\n<li>I recommend you using <a href=\"https://github.com/syl20bnr/spacemacs\">Spacemacs</a>, which is a new way to experience Emacs, you can use VI’s editing styles with emacs’ extendibility.</li>\n</ol>\n<h1 id=\"User-Scenario\"><a href=\"#User-Scenario\" class=\"headerlink\" title=\"User Scenario\"></a>User Scenario</h1><ol>\n<li>Most of Embedded system have not GUI avabliable. Nowadays, edge computing become poplar, using command-line text editor can be inportance for configure Edge Devices.</li>\n<li>Cloud Virual Machine(VM) - marjor of VM only support using SSH login, when you login the cloud VM, CLI will be the only way.</li>\n</ol>\n<h1 id=\"Cheatsheet\"><a href=\"#Cheatsheet\" class=\"headerlink\" title=\"Cheatsheet\"></a>Cheatsheet</h1><p>Here’s a cheatsheet to help you get the most out of Vim.</p>\n<table>\n<thead>\n<tr>\n<th><strong>Shortcut Keys</strong></th>\n<th align=\"center\"><strong>Function</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Main (Change Mode)</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>Escape key</td>\n<td align=\"center\">Gets out of the current mode into the “command mode”. All keys are bound of commands.</td>\n</tr>\n<tr>\n<td>i</td>\n<td align=\"center\">“Insert mode” for inserting text. Keys behave as expected.</td>\n</tr>\n<tr>\n<td>:</td>\n<td align=\"center\">“Last-line mode” where Vim expects you to enter a command such as to save the document.</td>\n</tr>\n<tr>\n<td>v</td>\n<td align=\"center\">Enter “visual mode”</td>\n</tr>\n<tr>\n<td><strong>Navigation keys (used in command mode)</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>h</td>\n<td align=\"center\">moves the cursor one character to the left</td>\n</tr>\n<tr>\n<td>j or Ctrl + J</td>\n<td align=\"center\">moves the cursor down one line</td>\n</tr>\n<tr>\n<td>k or Ctrl + P</td>\n<td align=\"center\">moves the cursor up one line</td>\n</tr>\n<tr>\n<td>l</td>\n<td align=\"center\">moves the cursor one character to the right</td>\n</tr>\n<tr>\n<td>0</td>\n<td align=\"center\">moves the cursor to the beginning of the line</td>\n</tr>\n<tr>\n<td>$</td>\n<td align=\"center\">moves the cursor to the end of the line</td>\n</tr>\n<tr>\n<td>^</td>\n<td align=\"center\">moves the cursor to the first non-empty character of the line</td>\n</tr>\n<tr>\n<td>w</td>\n<td align=\"center\">move forward one word (next alphanumeric word)</td>\n</tr>\n<tr>\n<td>W</td>\n<td align=\"center\">move forward one word (delimited by a white space)</td>\n</tr>\n<tr>\n<td>5w</td>\n<td align=\"center\">move forward five words</td>\n</tr>\n<tr>\n<td>b</td>\n<td align=\"center\">move backward one word (previous alphanumeric word)</td>\n</tr>\n<tr>\n<td>B</td>\n<td align=\"center\">move backward one word (delimited by a white space)</td>\n</tr>\n<tr>\n<td>5b</td>\n<td align=\"center\">move backward five words</td>\n</tr>\n<tr>\n<td>G</td>\n<td align=\"center\">move to the end of the file</td>\n</tr>\n<tr>\n<td>gg</td>\n<td align=\"center\">move to the beginning of the file</td>\n</tr>\n<tr>\n<td><strong>Navigate around the document</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>(</td>\n<td align=\"center\">jumps to the previous sentence</td>\n</tr>\n<tr>\n<td>)</td>\n<td align=\"center\">jumps to the next sentence</td>\n</tr>\n<tr>\n<td>{</td>\n<td align=\"center\">jumps to the previous paragraph</td>\n</tr>\n<tr>\n<td>}</td>\n<td align=\"center\">jumps to the next paragraph</td>\n</tr>\n<tr>\n<td>[[</td>\n<td align=\"center\">jumps to the previous section</td>\n</tr>\n<tr>\n<td>]]</td>\n<td align=\"center\">jumps to the next section</td>\n</tr>\n<tr>\n<td>[]</td>\n<td align=\"center\">jump to the end of the previous section</td>\n</tr>\n<tr>\n<td>][</td>\n<td align=\"center\">jump to the end of the next section</td>\n</tr>\n<tr>\n<td><strong>Insert text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>a</td>\n<td align=\"center\">Insert text after the cursor</td>\n</tr>\n<tr>\n<td>A</td>\n<td align=\"center\">Insert text at the end of the line</td>\n</tr>\n<tr>\n<td>i</td>\n<td align=\"center\">Insert text before the cursor</td>\n</tr>\n<tr>\n<td>o</td>\n<td align=\"center\">Begin a new line below the cursor</td>\n</tr>\n<tr>\n<td>O</td>\n<td align=\"center\">Begin a new line above the cursor</td>\n</tr>\n<tr>\n<td><strong>Special inserts</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>:r [filename]</td>\n<td align=\"center\">Insert the file [filename] below the cursor</td>\n</tr>\n<tr>\n<td>:r ![command]</td>\n<td align=\"center\">Execute [command] and insert its output below the cursor</td>\n</tr>\n<tr>\n<td><strong>Delete text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>x</td>\n<td align=\"center\">delete character at cursor</td>\n</tr>\n<tr>\n<td>dw</td>\n<td align=\"center\">delete a word</td>\n</tr>\n<tr>\n<td>d0</td>\n<td align=\"center\">delete to the beginning of a line</td>\n</tr>\n<tr>\n<td>d$</td>\n<td align=\"center\">delete to the end of a line</td>\n</tr>\n<tr>\n<td>d)</td>\n<td align=\"center\">delete to the end of sentence</td>\n</tr>\n<tr>\n<td>dgg</td>\n<td align=\"center\">delete to the beginning of the file</td>\n</tr>\n<tr>\n<td>dG</td>\n<td align=\"center\">delete to the end of the file</td>\n</tr>\n<tr>\n<td>dd</td>\n<td align=\"center\">delete line</td>\n</tr>\n<tr>\n<td>3dd</td>\n<td align=\"center\">delete three lines</td>\n</tr>\n<tr>\n<td><strong>Simple replace text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>r{text}</td>\n<td align=\"center\">Replace the character under the cursor with {text}</td>\n</tr>\n<tr>\n<td>R</td>\n<td align=\"center\">Replace characters instead of inserting them</td>\n</tr>\n<tr>\n<td><strong>Copy/Paste text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>yy</td>\n<td align=\"center\">copy current line into storage buffer</td>\n</tr>\n<tr>\n<td>[“x]yy</td>\n<td align=\"center\">Copy the current lines into register x</td>\n</tr>\n<tr>\n<td>p</td>\n<td align=\"center\">paste storage buffer after current line</td>\n</tr>\n<tr>\n<td>P</td>\n<td align=\"center\">paste storage buffer before current line</td>\n</tr>\n<tr>\n<td>[“x]p</td>\n<td align=\"center\">paste from register x after current line</td>\n</tr>\n<tr>\n<td>[“x]P</td>\n<td align=\"center\">paste from register x before current line</td>\n</tr>\n<tr>\n<td><strong>Undo/Redo operation</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>u</td>\n<td align=\"center\">undo the last operation</td>\n</tr>\n<tr>\n<td>Ctrl+r</td>\n<td align=\"center\">redo the last undo</td>\n</tr>\n<tr>\n<td><strong>Search and Replace keys</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>/search_text</td>\n<td align=\"center\">search document for search_text going forward</td>\n</tr>\n<tr>\n<td>?search_text</td>\n<td align=\"center\">search document for search_text going backward</td>\n</tr>\n<tr>\n<td>n</td>\n<td align=\"center\">move to the next instance of the result from the search</td>\n</tr>\n<tr>\n<td>N</td>\n<td align=\"center\">move to the previous instance of the result</td>\n</tr>\n<tr>\n<td>:%s/original/replacement</td>\n<td align=\"center\">Search for the first occurrence of the string “original” and replace it with “replacement”</td>\n</tr>\n<tr>\n<td>:%s/original/replacement/g</td>\n<td align=\"center\">Search and replace all occurrences of the string “original” with “replacement”</td>\n</tr>\n<tr>\n<td>:%s/original/replacement/gc</td>\n<td align=\"center\">Search for all occurrences of the string “original” but ask for confirmation before replacing them with “replacement”</td>\n</tr>\n<tr>\n<td><strong>Bookmarks</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>m {a-z A-Z}</td>\n<td align=\"center\">Set bookmark {a-z A-Z} at the current cursor position</td>\n</tr>\n<tr>\n<td>:marks</td>\n<td align=\"center\">List all bookmarks</td>\n</tr>\n<tr>\n<td>`{a-z A-Z}</td>\n<td align=\"center\">Jumps to the bookmark {a-z A-Z}</td>\n</tr>\n<tr>\n<td><strong>Select text</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>v</td>\n<td align=\"center\">Enter visual mode per character</td>\n</tr>\n<tr>\n<td>V</td>\n<td align=\"center\">Enter visual mode per line</td>\n</tr>\n<tr>\n<td>Esc</td>\n<td align=\"center\">Exit visual mode</td>\n</tr>\n<tr>\n<td><strong>Modify selected text (used in visual mode)</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>~</td>\n<td align=\"center\">Switch case</td>\n</tr>\n<tr>\n<td>d</td>\n<td align=\"center\">delete a word</td>\n</tr>\n<tr>\n<td>c</td>\n<td align=\"center\">change</td>\n</tr>\n<tr>\n<td>y</td>\n<td align=\"center\">yank</td>\n</tr>\n<tr>\n<td>&gt;</td>\n<td align=\"center\">shift right</td>\n</tr>\n<tr>\n<td>&lt;</td>\n<td align=\"center\">shift left</td>\n</tr>\n<tr>\n<td>!</td>\n<td align=\"center\">filter through an external command</td>\n</tr>\n<tr>\n<td><strong>Save and quit</strong></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>:q</td>\n<td align=\"center\">Quits Vim but fails when file has been changed</td>\n</tr>\n<tr>\n<td>:w</td>\n<td align=\"center\">Save the file</td>\n</tr>\n<tr>\n<td>:w new_name</td>\n<td align=\"center\">Save the file with the new_name filename</td>\n</tr>\n<tr>\n<td>:wq</td>\n<td align=\"center\">Save the file and quit Vim</td>\n</tr>\n<tr>\n<td>:q!</td>\n<td align=\"center\">Quit Vim without saving the changes to the file</td>\n</tr>\n<tr>\n<td>ZZ</td>\n<td align=\"center\">Write file, if modified, and quit Vim</td>\n</tr>\n<tr>\n<td>ZQ</td>\n<td align=\"center\">Same as :q! Quits Vim without writing changes</td>\n</tr>\n</tbody></table>\n"},{"title":"Getting started with Basler Camera With Opencv on Python","date":"2020-09-23T14:26:06.000Z","_content":"# Introduction\nThis post document is about using Basler Camera with Opencv on Python. At the beginning of this guide I will introduct how to set-up development environment with Pylon and opencv within Conda virual environment. Seconly, I will talk about how to check and set some of basic Basler feature base on pypylon. At the end, I will give a example about using Opencv read Basler Camera data stream.\n\n# Hardware and Software Testing Environment\n## Hardware Environment\n+ Camera: Basler (a2A1920 - 51gcPRO)\n+ Network Adapter: Intel I350 Gigabit Network adapter (POE)\n+ CPU: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\n+ RAM: 16GiB system memory\n## Software Environment\n+ Ubuntu 18.04 (Linux version 5.4.0-48-generic)\n+ Need set-up Network exchange environment, the document link: {% post_link ubuntuRouter %}\n\n# Development Environment Set-up\n\n## Creating conda environment\nYou can follow the below steps to create the conda environment. If you want to know more details about Conda, please have a look link: {% post_link conda %}\n\n```bash\nconda create -n baslerOpencv python=3.7.7\nconda activate baslerOpencv\nconda install notebook ipykernel\nipython kernel install --user --name baslerOpencv --display-name \"Python (Basler with Opencv)\"\n```\n## Installing Pylon\n1. Go to [Pylon Official Website](https://www.baslerweb.com/en/products/software/basler-pylon-camera-software-suite/).\n2. Go to Downloads Section\n3. Click link: pylon 6.1.1 Camera Software Suite Linux x86 (64 Bit) - Debian Installer Package\n4. Filling in your personal INFOs and click \"Start the Download!\"\n5. Goto you download directory(Using cd command)\n6. You can use the apt command for install deb file\n```bash\nsudo apt install xxxx.deb\n```\nWhen you done, you can see there are three applications be installed, which are Pylon IP Configurator, pylon viewer and Basler Product Documention.\n\n## Installing pypylon binary wheel file to conda environment\n[pypylon](https://github.com/basler/pypylon)\n## For the Impatient\n+ Download a binary wheel from the [releases](https://github.com/Basler/pypylon/releases) page.\nhttps://github.com/basler/pypylon/releases/download/1.6.0/pypylon-1.6.0-cp37-cp37m-linux_x86_64.whl\n+ Install the wheel using pip3 install <your downloaded wheel>.whl\n+ Look at samples/grab.py in this repository\n\n**TIPS:**\n```bash\nTraceback (most recent call last):\n  File \"opencv.py\", line 6, in <module>\n    from pypylon import pylon\n  File \"/home/yanboyang713/miniconda3/envs/baslerOpencv/lib/python3.7/site-packages/pypylon/pylon.py\", line 40, in <module>\n    from . import _pylon\nImportError: libpython3.7m.so.1.0: cannot open shared object file: No such file or directory\n```\n\n```bash\nexport LD_LIBRARY_PATH=/home/yanboyang713/miniconda3/envs/front/lib\necho $LD_LIBRARY_PATH\n```\n\n## Set-up pypylon-opencv-viewer(Option)\npip install pypylon-opencv-viewer\n\n## Installing Opencv to conda environment\npip install opencv-python==3.4.2.17\npip install opencv-contrib-python==3.4.2.17 \n\n# Image Control\n## Image ROI (Area of Insterest)\n### Getting the width of the maximum value and the height of the maximum value\n```python\nprint (\"MaxWidth: \", camera.Width.GetMax())\nprint (\"MaxHeight: \", camera.Height.GetMax())\n```\n\n### Setting the width of the image ROI and the height of the image ROI\n```python\n# Set the width to 1920\ncamera.Width.SetValue(1920);\n\n# Set the height to 1080\ncamera.Height.SetValue(1080)\n```\n\n### Center the image ROI\n+ To enable Center X, set the CenterX parameter to true.\nThe camera adjusts the OffsetX parameter value to center the image ROI horizontally. When you change the width of the image ROI, the OffsetX parameter value automatically adapts. The OffsetX parameter becomes read-only.\n+ To enable Center Y, set the CenterY parameter to true.\nThe camera adjusts the OffsetY parameter value to center the image ROI vertically. When you change the height of the image ROI, the OffsetY parameter value automatically adapts. The OffsetY parameter becomes read-only.\n\n```python\ncamera.BslCenterX.Execute();\ncamera.BslCenterY.Execute();\n```\n\n### Setting the offset of image ROI\nIf you already center the image ROI, offset parameter becomes read-only. You cannot set offset value again.\n```python\ncamera.OffsetX.SetValue(0);\ncamera.OffsetY.SetValue(0);\n```\n'''\n\n### Print the ROI INFOs\n```python\nprint (\"camera Width increment: \", camera.Width.GetInc())\nprint (\"camera Height increment: \", camera.Height.GetInc())\nprint (\"camera Minimum Width: \", camera.Width.GetMin())\nprint (\"camera Minimum Height: \", camera.Height.GetMin())\n\nprint (\"camera Width: \", camera.Width.GetValue())\nprint (\"Camera offsetX: \", camera.OffsetX.GetValue())\n\nprint (\"camera Height: \", camera.Height.GetValue())\nprint (\"Camera offsetY: \", camera.OffsetY.GetValue() )\n\nassert camera.Width.GetValue() + camera.OffsetX.GetValue() <= camera.Width.GetMax()\nassert camera.Height.GetValue() + camera.OffsetY.GetValue() <= camera.Height.GetMax()\n```\n\n## Image/Pixel Format Control\nThe offical [Pixel Formats](https://docs.baslerweb.com/pixel-format)\n+ list your camera available Pixel Formats\n```python\nprint(camera.PixelFormat.Symbolics)\n```\n+ show your current Pixel Formats in used\n```python\nprint (\"camera.PixelFormat.GetValue: \", camera.PixelFormat.GetValue())\n```\n### Mono Formats\nIf a monochrome camera uses one of the mono pixel formats, it outputs 8, 10, or 12 bits of data per pixel.\n\nIf a color camera uses the Mono 8 pixel format, the values for each pixel are first converted to the YUV color model. The Y component of this model represents a brightness value and is equivalent to the value that would be derived from a pixel in a monochrome image. So in essence, when a color camera is set to Mono 8, it outputs an 8-bit monochrome image. This type of output is sometimes referred to as \"Y Mono 8\".\n\n```python\ncamera.PixelFormat.SetValue(\"Mono8\")\ncamera.PixelFormat.SetValue(\"Mono12\")\ncamera.PixelFormat.SetValue(\"Mono12p\")\n```\n\n### Bayer Formats\nColor cameras are equipped with a Bayer color filter and can output color images based on the Bayer pixel formats given below.\n\nIf a color camera uses one of these Bayer pixel formats, it outputs 8, 10, or 12 bits of data per pixel. The pixel data is not processed or interpolated in any way. For each pixel covered with a red filter, you get 8, 10, or 12 bits of red data. For each pixel covered with a green filter, you get 8, 10, or 12 bits of green data. For each pixel covered with a blue filter, you get 8, 10, or 12 bits of blue data. This type of pixel data is sometimes referred to as \"raw\" output.\n\n```python\ncamera.PixelFormat.SetValue(\"BayerRG8\")\ncamera.PixelFormat.SetValue(\"BayerRG12\")\ncamera.PixelFormat.SetValue(\"BayerRG12p\")\n```\n\n### RGB and BGR Formats\nWhen a color camera uses the RGB 8 or BGR 8 pixel format, the camera outputs 8 bit of red data, 8 bit of green data, and 8 bit of blue data for each pixel in the acquired frame.\n\nThe pixel formats differ by the output sequences for the color data (red, green, blue or blue, green, red).\n\n```python\ncamera.PixelFormat.SetValue(\"RGB8\")\ncamera.PixelFormat.SetValue(\"BGR8\")\n```\n\n### YUV Formats\nColor cameras can also output color images based on pixel data in YUV (or YCbCr) format.\n\nIf a color camera uses this format, each pixel value in the captured image goes through a conversion process as it exits the sensor and passes through the camera. This process yields Y, U, and V color information for each pixel value.\n\n**Info**\n\nThe values for U and V normally range from -128 to +127. Because the camera transfers U values and V values with unsigned integers, 128 is added to each U value and V value before they are transferred from the camera. This way, values from 0 to 255 can be transferred.\n\n```python\ncamera.PixelFormat.SetValue(\"YCbCr422_8\")\n```\n\n## Black Level\n\nThe Black Level camera feature allows you to change the overall brightness of an image. All gray values of the pixels are changed by a specified amount.\n\nFor example, you can increase the gray value of each pixel in the image by 3.\n\nAdjusting the Black Level\n\nTo adjust the black level, enter a value for the BlackLevel parameter.\n\nThe minimum black level setting is 0. The maximum setting depends on the camera model.\n\nThe change in the gray value resulting from the BlackLevel parameter value also depends on the camera model.\n\n**INFO**\nBasler recommends setting the black level to 0 before using any of the color enhancement features, e.g., Balance White, Color Transformation, or Gamma. After the color enhancements have been applied, you can change the black level as desired. However, increasing the black level will decrease the color accuracy.\n\n```python\ncamera.BlackLevel.SetValue(0)\nprint (\"camera.BlackLevel.GetValue()\", camera.BlackLevel.GetValue())\n```\n\n## Gamma\n\n![Gamma correction](https://en.wikipedia.org/wiki/Gamma_correction)\n\nThe Gamma camera feature allows you to optimize the brightness of acquired images for display on a monitor.\n\nUsing the Feature\n\n### How It Works\n\nThe camera applies a gamma correction value (γ) to the brightness value of each pixel according to the following formula (red pixel value (R) of a color camera shown as an example):\n$R_{corrected} = (\\frac{ R_{uncorrected} }{ R_{max} }) ^ γ * R_{max} $\n\nThe maximum pixel value (Rmax) equals, e.g., 255 for 8-bit pixel formats or 1 023 for 10-bit pixel formats.\n\n### Enabling Gamma Correction\n\nTo enable gamma correction:\n\n1. Set the GammaEnable parameter to true (if available).\n2. For best results, set the BlackLevel parameter to 0.\n3. Set the Gamma parameter to the desired value. The parameter's value range is 0 to ≈4.\n    + Gamma = 1: The overall brightness remains unchanged.\n    + Gamma < 1: The overall brightness increases.\n    + Gamma > 1: The overall brightness decreases.\n\nIn all cases, black pixels (brightness = 0) and white pixels (brightness = maximum) will not be adjusted.\n\n**INFO**\nIf you enable gamma correction and the pixel format is set to a 12-bit pixel format, some image information will be lost. Pixel data output will still be 12-bit, but the pixel values will be interpolated during the gamma correction process.\n\n### Additional Parameters\n\nDepending on your camera model, the following additional parameters are available:\n\n+ GammaEnable: Enables or disables gamma correction.\n+ GammaSelector: Allows you to select one of the following gamma correction modes:\n    + User: The gamma correction value can be set as desired. (Default.)\n    + sRGB: The camera automatically sets a gamma correction value of approximately 0.4. This value is optimized for image display on sRGB monitors.\n\n+ BslColorSpaceMode or BslColorSpace: Allows you to select one of the following gamma correction modes:\n    + RGB: No additional gamma correction value is applied.\n    + sRGB: The image brightness is optimized for display on an sRGB monitor. A gamma correction value of approximately 0.4 is applied. For more information, see the footnotes in the Specifics section.\n\n```python\n# Set the Gamma value to 1.2\ncamera.Gamma.SetValue(1.2)\nprint (\"camera.Gamma.GetValue()\", camera.Gamma.GetValue())\n# Set the color space to sRGB\ncamera.BslColorSpace.SetValue(\"sRgb\");\nprint (\"camera.BslColorSpace.GetValue(): \", camera.BslColorSpace.GetValue())\n```\n\n## Auto Function ROI\n\nThe Auto Function ROI camera feature allows you to specify the part of the sensor array with which you want to control the camera's auto functions.\n\nROI is short for region of interest (formerly AOI = area of interest).\n\nYou can create several auto function ROIs, each occupying different parts of the sensor array.\n\nThe settings for the Auto Function ROI feature are independent of the settings for the Image ROI feature.\n\n### Changing Position and Size of an Auto Function ROI\n\nBy default, all auto function ROIs are set to the same size as the camera's image ROI. You can change their positions and sizes to suit your needs.\n\nTo change the position and size of an auto function ROI:\n\n1. Set the AutoFunctionROISelector parameter to one of the available auto function ROIs, e.g., ROI1.\n2. Enter values for the following parameters to specify the position of the auto function ROI selected:\n    + AutoFunctionROIOffsetX\n    + AutoFunctionROIOffsetY\n3. Enter values for the following parameters to specify the size of the auto function ROI selected:\n    + AutoFunctionROIWidth\n    + AutoFunctionROIHeight\n\nThe position of an auto function ROI is specified based on the lines and rows of the sensor array.\n\nExample: Assume that you have selected auto function ROI 1 and specified the following settings:\n\n    AutoFunctionROIOffsetX = 14\n    AutoFunctionROIOffsetY = 7\n    AutoFunctionROIWidth = 5\n    AutoFunctionROIHeight = 6\n\nThis creates the following auto function ROI 1:\n![](https://docs.baslerweb.com/images/drawing-af-aoi.svg)\nOnly the pixel data from the area of overlap between the auto function ROI and the image ROI will be used by the auto function assigned to it.\n**Info**\n\n+ On color cameras, Basler recommends setting the parameters for position and size to even values (multiples of 2). This matches the auto function ROI to the color filter pattern of the sensor.\n+ If the Binning feature is enabled, the auto function ROI settings refer to the binned lines and columns and not to the physical lines in the sensor.\n+ If the Reverse X or Reverse Y feature or both are enabled, the position of the auto function ROI relative to the sensor remains the same. As a consequence, different regions of the image will be controlled depending on whether or not Reverse X, Reverse Y or both are enabled.\n\n### Auto Function ROI Highlighting\nIf highlighting is supported by your camera model, you can highlight one or multiple Auto Function ROIs in the pylon Viewer. Areas that don't belong to the Auto Function ROIs appear darker:\n![](https://docs.baslerweb.com/images/image-auto-function-roi-highlight.jpg)\n\nTo highlight an Auto Function ROI:\n\n1. Set the AutoFunctionROISelector parameter to the desired auto function ROI, e.g., ROI1.\n2. Set the AutoFunctionROIHighlight parameter to true.\n\n### Assigning Auto Functions\n\nBy default, each auto function ROI is assigned to a specific auto function. For example, the pixel data from auto function ROI 2 is used to control the Balance White Auto auto function.\n\nOn some camera models, the default assignments can be changed. To do so:\n\nSet the AutoFunctionROISelector parameter to one of the available auto function ROIs, e.g., ROI1.\n\nAssign the desired auto function(s) to the auto function ROI selected:\n\n+ If you want to assign Balance White Auto, set the AutoFunctionROIUseWhiteBalance parameter to true.\n+ If you want to assign Exposure Auto and gain auto, set the AutoFunctionROIUseBrightness parameter to true. (Exposure Auto and Gain Auto always work together.)\n+ If you want to assign Tonal Range Auto, set the AutoFunctionROIUseTonalRange parameter to true.\n\n**Info**\n\n+ If you assign one auto function to multiple auto function ROIs, the pixel data from all selected auto function ROIs will be used for the auto function.\n+ If you assign multiple auto functions to one auto function ROI, the pixel data from the auto function ROI will be used for all auto functions selected.\n\nExposure Auto and Gain Auto Assignments Work Together\nWhen making auto function ROI assignments, the Gain Auto auto function and the exposure auto auto function always work together. they are considered as a single auto function named \"intensity\" or \"brightness\", depending on your camera model.\n\nThis does not imply, however, that Gain Auto and Exposure Auto must always be enabled at the same time.\n\n### Guidelines\n\nWhen you are setting an auto function ROI, you must follow these guidelines:\n\n| Guideline | Example|\n| --------- |:------:|\n| AutoFunctionROIOffsetX + AutoFunctionROIWidth ≤ Width of camera sensor | Camera with a 1920 x 1080 pixel sensor: AutoFunctionROIOffsetX + AutoFunctionROIWidth ≤ 1920 |\n| AutoFunctionROIOffsetY + AutoFunctionROIHeight ≤ Height of camera sensor | Camera with a 1920 x 1080 pixel sensor: AutoFunctionROIOffsetY + AutoFunctionROIHeight ≤ 1080 |\n\n### Overlap Between Auto Function ROI and Image ROI\n\nThe size and position of an auto function ROI can be identical to the size and position of the image ROI, but this is not a requirement. For an auto function to work, it is sufficient if both ROIs overlap each other partially.\n\nThe overlap between auto function ROI and image ROI determines whether and to what extent the auto function will control the related image property. Only the pixel data from the areas of overlap will be used by the auto function to control the image property of the entire image.\n\n+ If the auto function ROI is completely contained in the image ROI, the pixel data from the auto function ROI will be used to control the image property.\n![](https://docs.baslerweb.com/images/drawing-af-aoi-with-full-effect.svg)\n\n+ If the image ROI is completely contained in the auto function ROI, only the pixel data from the image ROI will be used to control the image property.\n![](https://docs.baslerweb.com/images/drawing-af-aoi-all-encompassing.svg)\n\n+ If the auto function ROI overlaps the image ROI only partially, only the pixel data from the area of partial overlap will be used to control the image property.\n![](https://docs.baslerweb.com/images/drawing-af-aoi-with-partial-effect.svg)\n\n+ If the auto function ROI does not overlap the image ROI, the related auto function will not work.\n![](https://docs.baslerweb.com/images/drawing-af-aoi-with-no-effect.svg)\n**Info**\n\nBasler strongly recommends completely including the auto function ROI within the image ROI or choosing identical positions and sizes for auto function ROI and image ROI.\n\n```python\n# Select auto function ROI 1\ncamera.AutoFunctionROISelector.SetValue(\"ROI1\")\n\n# Specify position and size of the auto function ROI selected\ncamera.AutoFunctionROIOffsetX.SetValue(camera.OffsetX.GetValue())\ncamera.AutoFunctionROIOffsetY.SetValue(camera.OffsetY.GetValue())\ncamera.AutoFunctionROIWidth.SetValue(camera.Width.GetValue())\ncamera.AutoFunctionROIHeight.SetValue(camera.Height.GetValue())\n\nprint (\"camera.AutoFunctionROIOffsetX.GetValue(): \", camera.AutoFunctionROIOffsetX.GetValue())\nprint (\"camera.AutoFunctionROIOffsetY.GetValue(): \", camera.AutoFunctionROIOffsetY.GetValue())\n\nprint (\"camera.AutoFunctionROIWidth.GetValue(): \", camera.AutoFunctionROIWidth.GetValue())\nprint (\"camera.AutoFunctionROIHeight.GetValue(): \", camera.AutoFunctionROIHeight.GetValue())\n\n\nassert camera.AutoFunctionROIOffsetX.GetValue() + camera.AutoFunctionROIWidth.GetValue() <= camera.Width.GetMax()\nassert camera.AutoFunctionROIOffsetY.GetValue() + camera.AutoFunctionROIHeight.GetValue() <= camera.Height.GetMax()\n\n# Enable the 'Brightness' auto function (Gain Auto + Exposure Auto)\n# for the auto function ROI selected\ncamera.AutoFunctionROIUseBrightness.SetValue(True)\n# Highlight the auto function ROI selected\ncamera.AutoFunctionROIHighlight.SetValue(False)\n```\n## Auto Function Profile\nThe Auto Function Profile camera feature allows you to specify how gain and exposure time are balanced when the camera is making automatic adjustments.\n\n### Setting the Auto Function Profile\n\nTo set the auto function profile:\n\n1. Set the Gain Auto auto function and the Exposure Auto auto function to Continuous.\n2. Set the AutoFunctionProfile parameter to one of the following values (if available):\n    + MinimizeGain\n    + MinimizeExposureTime\n    + MinimizeGainQuick\n    + MinimizeExposureTimeQuick\n    + Smart\n    + AntiFlicker50Hz\n    + AntiFlicker60Hz\n\n### Available Auto Function Profiles\n#### Minimize Gain (= Gain Minimum)\n\nThe gain is kept as low as possible during the automatic adjustment process. If the exposure time is at its upper limit and the target brightness value has not been reached yet, the gain will be increased in order to reach the target.\n\n#### Minimize Exposure Time (= Exposure Minimum)\n\nThe exposure time is kept as low as possible during the automatic adjustment process. If the gain is at its upper limit and the target brightness value has not been reached yet, the exposure time will be increased in order to reach the target.\n\n#### Minimize Gain Quick (= Gain Minimum Quick)\n\nThis profile works the same as the Minimize Gain profile. The difference is that it reacts more quickly in situations with extreme changes in brightness or where the image brightness changes rapidly. This situation occurs, for example, when microscope objective lenses are changed using the objective turret.\n\n#### Minimize Exposure Time Quick (= Exposure Minimum Quick)\n\nThis profile works the same as the Minimize Exposure Time profile. The difference is that it reacts more quickly in situations with extreme changes in brightness or where the image brightness changes rapidly. This situation occurs, for example, when microscope objective lenses are changed using the objective turret.\n\n#### Smart\n\nGain is kept as low as possible and the frame rate will be kept as high as possible during automatic adjustments.\n\nThis is a four-step process:\n\n1. The camera adjusts the exposure time to achieve the target brightness value.\n2. If the exposure time must be increased to achieve the target brightness value, the camera does so until the frame rate drops.\n3. If the frame rate drops, the camera stops increasing the exposure time and increases the gain until the AutoGainUpperLimit value is reached.\n4. When the AutoGainUpperLimit value has been reached, the camera stops increasing the gain and increases the exposure time until the target brightness value is reached. Increasing the exposure time results in a lower frame rate.\n\n#### Anti-Flicker 50 Hz / 60 Hz\n\nGain and exposure time are optimized to reduce flickering. If the camera is operating in an environment where the lighting flickers at a 50-Hz or a 60-Hz rate, the flickering lights can cause significant changes in brightness from image to image. Enabling the anti-flicker profile may reduce the effect of the flickering in the captured images.\n\nChoose the frequency (50 Hz or 60 Hz) according your local power line frequency (e.g., North America: 60 Hz, Europe: 50 Hz).\n\n```python\n# Set the auto function profile to Exposure Minimum\ncamera.AutoFunctionProfile.SetValue(\"MinimizeExposureTime\");\nprint (\"camera.AutoFunctionProfile.GetValue(): \", camera.AutoFunctionProfile.GetValue())\n\n# Set the auto function profile to Gain Minimum\ncamera.AutoFunctionProfile.SetValue(\"MinimizeGain\")\nprint (\"camera.AutoFunctionProfile.GetValue(): \", camera.AutoFunctionProfile.GetValue())\n\n# Enable Gain and Exposure Auto auto functions and set the operating mode to Continuous\n\ncamera.GainAuto.SetValue(\"Continuous\")\nprint (\"camera.GainAuto.GetValue(): \", camera.GainAuto.GetValue())\n\ncamera.ExposureAuto.SetValue(\"Continuous\")\nprint (\"camera.ExposureAuto.GetValue(): \", camera.ExposureAuto.GetValue())\n```\n\n## Balance White Auto\n\nThe Balance White Auto camera feature automatically corrects color shifts in images acquired.\n\nThe pixel data for the auto function can come from one or multiple auto function ROIs.\n\nTo correct color shifts manually, use the Balance White feature.\n\n### Enabling or Disabling Balance White Auto\n\nTo enable or disable the Balance White Auto auto function:\n\n1. Assign at least one auto function ROI to the Balance White Auto auto function.\n    Make sure the auto function ROI overlaps the image ROI, either partially or completely.\n2. Set the BalanceWhiteAuto parameter to one of the following operating modes:\n    + Once: The camera adjusts the white balance until the average gray values for red, green, and blue are identical. When this has been achieved, or after a maximum of 30 calculation cycles, the camera sets the auto function to Off and applies the balance ratios resulting from the last calculation to all following images.\n    + Continuous: The camera adjusts the white balance continuously while images are being acquired. The adjustment process continues until the operating mode is set to Once or Off.\n    + Off: Disables the Balance White Auto auto function. The BalanceRatio parameters remain at the values resulting from the last automatic or manual adjustment.\n\n### How It Works\n\nAutomatic white balancing is a two-step process:\n\n1. The camera compares the average gray values of the red, green, and blue pixels. It determines the color with the highest average gray value (i.e., the brightest color) and sets the BalanceRatio parameter value for this color to 1.\n2. The camera automatically adjusts the BalanceRatio parameter values of the other two colors until the average gray values for red, green, and blue are identical.\n\nAs a result, the BalanceRatio parameter is set to 1 for one color and to a value between 1 and ≈15.98 for the other two colors.\n\nExample: Assume the green pixels in your image have the highest average gray value. If you enable the Balance White Auto auto function, the camera sets the BalanceRatio parameter value for green to 1. Then, the camera automatically adjusts the BalanceRatio parameter values for red and blue until the average gray values for red, green, and blue are identical. The new balance ratios could be, e.g., green = 1, red = 1.08789, and blue = 2.19678.\n\n**Info**\n\n+ To view the BalanceRatio parameter values for red, green, or blue, switch to the respective color channel using the BalanceRatioSelector.\n+ When the camera is capturing images continuously, the auto function takes effect with a short delay. The first few images may not be affected by the auto function.\n\n```python\ncamera.AutoFunctionROISelector.SetValue(\"ROI1\")\n\ncamera.AutoFunctionROIUseWhiteBalance.SetValue(True)\nprint (\"camera.AutoFunctionROIUseWhiteBalance.GetValue(): \", camera.AutoFunctionROIUseWhiteBalance.GetValue())\ncamera.BalanceWhiteAuto.SetValue(\"Continuous\")\nprint (\"camera.BalanceWhiteAuto.GetValue(): \", camera.BalanceWhiteAuto.GetValue())\n```\n\n## Light Source Preset\n![](https://docs.baslerweb.com/light-source-preset)\n\nThe Light Source Preset camera feature allows you to correct color shifts caused by certain light sources.\n\nDepending on its specific color temperature, the light used for image acquisition can cause color shifts in the image. You can correct these color shifts by selecting the related light source preset.\n\nSelecting a Light Source Preset\n\nTo select a light source preset, set the BslLightSourcePreset parameter to one of the following values (if available):\n\n    Off: No light source preset is selected.\n    Daylight5000K: The camera corrects color shifts caused by daylight lighting that has a color temperature of about 5 000 K.\n    Daylight6500K: The camera corrects color shifts caused by daylight lighting that has a color temperature of about 6 500 K.\n    Tungsten2800K: The camera corrects color shifts caused by tungsten lighting that has a color temperature of about 2 500 to 3 000 K.\n    MicroscopeLED4500K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 4 500 K.\n    MicroscopeLED5500K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 5 500 K.\n    MicroscopeLED6000K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 6 000 K.\n    Fluorescent4000K: The camera corrects color shifts caused by fluorescent lighting that has a color temperature of about 4 000 K.\n    Custom: Selecting this preset enables the Color Transformation feature which allows you to customize the light source settings. You should only select this preset if you are thoroughly familiar with matrix color transformations. The camera also adjusts the Balance White and Color Adjustment settings so that they have neutral values that do not change the appearance of the colors.\n\nThe default light source preset varies by camera model.\n**Info**\n\nOn Basler dart cameras, the light source presets are calibrated for the IR cut filter in the CS-mount variant. If you are using an S-mount or bare board variant, make sure your IR cut filter has suitable spectral characteristics.\n\nFor more information about the IR cut filter, see your camera topic. You can find your camera topic in the \"Models\" section.\n\n### Impact on Other Features\n\nWhen you select a light source preset, the camera adjusts the settings of the following color enhancement features:\n+ Balance White\n+ Color Adjustment\n+ Color Transformation\nThe settings will be optimized for the selected light source.\nOn some camera models, you can choose which features you want the camera to adjust.\n\n### Separate Processing\nOn some camera models, when you select a light source preset, the camera processes the changes to the features listed above separately. This means that the values of the corresponding parameters visible in the pylon API and the pylon Viewer are not changed.\n\nExample: If you select the Daylight6500K light source preset, the camera adjusts the white balance, but the values of the BalanceRatio parameter don't change.\n\nThis has the advantage that you don't lose your color enhancement feature settings when you change the light source preset. Your own settings are independent from the light source preset adjustments.\n\n### No Separate Processing\nOn some camera models, when you select a light source preset, the camera doesn't process the feature changes separately. Instead, the camera directly adjusts the corresponding parameter values.\n\nExample: If you select the Daylight6500K light source preset, the values of the BalanceRatio parameter change. You can see the changes in the pylon Viewer or by accessing the parameter via the pylon API.\n\nThis means if you set up the color enhancement features and then change the light source preset, your settings will be overwritten.\n\n### Light Source Preset Feature Selector\n\nOn some camera models, the BslLightSourcePresetFeatureSelector parameter is available.\n\nIf the parameter is available, you can select which features you want the camera to adjust when you select a light source preset.\n\nBy default, the camera adjusts all features.\n\nTo enable or disable adjustment of a specific feature:\n\n1. Set the BslLightSourcePresetFeatureSelector parameter to the desired feature, e.g., ColorAdjustment.\n2. Set the BslLightSourcePresetFeatureEnable parameter to true (feature enabled) or false (feature disabled).\n3. Repeat steps 1 and 2 for all features that you want to enable or disable.\n\n```python\n# Disable light source presets (no correction)\ncamera.BslLightSourcePreset.SetValue(\"Off\")\n# Set the light source preset for daylight (at about 5000K)\ncamera.BslLightSourcePreset.SetValue(\"Daylight5000K\")\n# Set the light source preset for tungsten lighting (at about 2800K)\ncamera.BslLightSourcePreset.SetValue(\"Tungsten\")\n# Set the light source preset for daylight (at about 6500K)\ncamera.BslLightSourcePreset.SetValue(\"Daylight6500K\")\n\n\n# Disable adjustment of a specific feature\ncamera.BslLightSourcePresetFeatureSelector.SetValue(\"ColorAdjustment\")\ncamera.BslLightSourcePresetFeatureEnable.SetValue(False)\n```\n\n","source":"_posts/baslerWithOpencv.md","raw":"---\ntitle: Getting started with Basler Camera With Opencv on Python\ndate: 2020-09-23 14:26:06\ntags:\n - Basler\n - Opencv\n - python\ncategories: Basler\n---\n# Introduction\nThis post document is about using Basler Camera with Opencv on Python. At the beginning of this guide I will introduct how to set-up development environment with Pylon and opencv within Conda virual environment. Seconly, I will talk about how to check and set some of basic Basler feature base on pypylon. At the end, I will give a example about using Opencv read Basler Camera data stream.\n\n# Hardware and Software Testing Environment\n## Hardware Environment\n+ Camera: Basler (a2A1920 - 51gcPRO)\n+ Network Adapter: Intel I350 Gigabit Network adapter (POE)\n+ CPU: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz\n+ RAM: 16GiB system memory\n## Software Environment\n+ Ubuntu 18.04 (Linux version 5.4.0-48-generic)\n+ Need set-up Network exchange environment, the document link: {% post_link ubuntuRouter %}\n\n# Development Environment Set-up\n\n## Creating conda environment\nYou can follow the below steps to create the conda environment. If you want to know more details about Conda, please have a look link: {% post_link conda %}\n\n```bash\nconda create -n baslerOpencv python=3.7.7\nconda activate baslerOpencv\nconda install notebook ipykernel\nipython kernel install --user --name baslerOpencv --display-name \"Python (Basler with Opencv)\"\n```\n## Installing Pylon\n1. Go to [Pylon Official Website](https://www.baslerweb.com/en/products/software/basler-pylon-camera-software-suite/).\n2. Go to Downloads Section\n3. Click link: pylon 6.1.1 Camera Software Suite Linux x86 (64 Bit) - Debian Installer Package\n4. Filling in your personal INFOs and click \"Start the Download!\"\n5. Goto you download directory(Using cd command)\n6. You can use the apt command for install deb file\n```bash\nsudo apt install xxxx.deb\n```\nWhen you done, you can see there are three applications be installed, which are Pylon IP Configurator, pylon viewer and Basler Product Documention.\n\n## Installing pypylon binary wheel file to conda environment\n[pypylon](https://github.com/basler/pypylon)\n## For the Impatient\n+ Download a binary wheel from the [releases](https://github.com/Basler/pypylon/releases) page.\nhttps://github.com/basler/pypylon/releases/download/1.6.0/pypylon-1.6.0-cp37-cp37m-linux_x86_64.whl\n+ Install the wheel using pip3 install <your downloaded wheel>.whl\n+ Look at samples/grab.py in this repository\n\n**TIPS:**\n```bash\nTraceback (most recent call last):\n  File \"opencv.py\", line 6, in <module>\n    from pypylon import pylon\n  File \"/home/yanboyang713/miniconda3/envs/baslerOpencv/lib/python3.7/site-packages/pypylon/pylon.py\", line 40, in <module>\n    from . import _pylon\nImportError: libpython3.7m.so.1.0: cannot open shared object file: No such file or directory\n```\n\n```bash\nexport LD_LIBRARY_PATH=/home/yanboyang713/miniconda3/envs/front/lib\necho $LD_LIBRARY_PATH\n```\n\n## Set-up pypylon-opencv-viewer(Option)\npip install pypylon-opencv-viewer\n\n## Installing Opencv to conda environment\npip install opencv-python==3.4.2.17\npip install opencv-contrib-python==3.4.2.17 \n\n# Image Control\n## Image ROI (Area of Insterest)\n### Getting the width of the maximum value and the height of the maximum value\n```python\nprint (\"MaxWidth: \", camera.Width.GetMax())\nprint (\"MaxHeight: \", camera.Height.GetMax())\n```\n\n### Setting the width of the image ROI and the height of the image ROI\n```python\n# Set the width to 1920\ncamera.Width.SetValue(1920);\n\n# Set the height to 1080\ncamera.Height.SetValue(1080)\n```\n\n### Center the image ROI\n+ To enable Center X, set the CenterX parameter to true.\nThe camera adjusts the OffsetX parameter value to center the image ROI horizontally. When you change the width of the image ROI, the OffsetX parameter value automatically adapts. The OffsetX parameter becomes read-only.\n+ To enable Center Y, set the CenterY parameter to true.\nThe camera adjusts the OffsetY parameter value to center the image ROI vertically. When you change the height of the image ROI, the OffsetY parameter value automatically adapts. The OffsetY parameter becomes read-only.\n\n```python\ncamera.BslCenterX.Execute();\ncamera.BslCenterY.Execute();\n```\n\n### Setting the offset of image ROI\nIf you already center the image ROI, offset parameter becomes read-only. You cannot set offset value again.\n```python\ncamera.OffsetX.SetValue(0);\ncamera.OffsetY.SetValue(0);\n```\n'''\n\n### Print the ROI INFOs\n```python\nprint (\"camera Width increment: \", camera.Width.GetInc())\nprint (\"camera Height increment: \", camera.Height.GetInc())\nprint (\"camera Minimum Width: \", camera.Width.GetMin())\nprint (\"camera Minimum Height: \", camera.Height.GetMin())\n\nprint (\"camera Width: \", camera.Width.GetValue())\nprint (\"Camera offsetX: \", camera.OffsetX.GetValue())\n\nprint (\"camera Height: \", camera.Height.GetValue())\nprint (\"Camera offsetY: \", camera.OffsetY.GetValue() )\n\nassert camera.Width.GetValue() + camera.OffsetX.GetValue() <= camera.Width.GetMax()\nassert camera.Height.GetValue() + camera.OffsetY.GetValue() <= camera.Height.GetMax()\n```\n\n## Image/Pixel Format Control\nThe offical [Pixel Formats](https://docs.baslerweb.com/pixel-format)\n+ list your camera available Pixel Formats\n```python\nprint(camera.PixelFormat.Symbolics)\n```\n+ show your current Pixel Formats in used\n```python\nprint (\"camera.PixelFormat.GetValue: \", camera.PixelFormat.GetValue())\n```\n### Mono Formats\nIf a monochrome camera uses one of the mono pixel formats, it outputs 8, 10, or 12 bits of data per pixel.\n\nIf a color camera uses the Mono 8 pixel format, the values for each pixel are first converted to the YUV color model. The Y component of this model represents a brightness value and is equivalent to the value that would be derived from a pixel in a monochrome image. So in essence, when a color camera is set to Mono 8, it outputs an 8-bit monochrome image. This type of output is sometimes referred to as \"Y Mono 8\".\n\n```python\ncamera.PixelFormat.SetValue(\"Mono8\")\ncamera.PixelFormat.SetValue(\"Mono12\")\ncamera.PixelFormat.SetValue(\"Mono12p\")\n```\n\n### Bayer Formats\nColor cameras are equipped with a Bayer color filter and can output color images based on the Bayer pixel formats given below.\n\nIf a color camera uses one of these Bayer pixel formats, it outputs 8, 10, or 12 bits of data per pixel. The pixel data is not processed or interpolated in any way. For each pixel covered with a red filter, you get 8, 10, or 12 bits of red data. For each pixel covered with a green filter, you get 8, 10, or 12 bits of green data. For each pixel covered with a blue filter, you get 8, 10, or 12 bits of blue data. This type of pixel data is sometimes referred to as \"raw\" output.\n\n```python\ncamera.PixelFormat.SetValue(\"BayerRG8\")\ncamera.PixelFormat.SetValue(\"BayerRG12\")\ncamera.PixelFormat.SetValue(\"BayerRG12p\")\n```\n\n### RGB and BGR Formats\nWhen a color camera uses the RGB 8 or BGR 8 pixel format, the camera outputs 8 bit of red data, 8 bit of green data, and 8 bit of blue data for each pixel in the acquired frame.\n\nThe pixel formats differ by the output sequences for the color data (red, green, blue or blue, green, red).\n\n```python\ncamera.PixelFormat.SetValue(\"RGB8\")\ncamera.PixelFormat.SetValue(\"BGR8\")\n```\n\n### YUV Formats\nColor cameras can also output color images based on pixel data in YUV (or YCbCr) format.\n\nIf a color camera uses this format, each pixel value in the captured image goes through a conversion process as it exits the sensor and passes through the camera. This process yields Y, U, and V color information for each pixel value.\n\n**Info**\n\nThe values for U and V normally range from -128 to +127. Because the camera transfers U values and V values with unsigned integers, 128 is added to each U value and V value before they are transferred from the camera. This way, values from 0 to 255 can be transferred.\n\n```python\ncamera.PixelFormat.SetValue(\"YCbCr422_8\")\n```\n\n## Black Level\n\nThe Black Level camera feature allows you to change the overall brightness of an image. All gray values of the pixels are changed by a specified amount.\n\nFor example, you can increase the gray value of each pixel in the image by 3.\n\nAdjusting the Black Level\n\nTo adjust the black level, enter a value for the BlackLevel parameter.\n\nThe minimum black level setting is 0. The maximum setting depends on the camera model.\n\nThe change in the gray value resulting from the BlackLevel parameter value also depends on the camera model.\n\n**INFO**\nBasler recommends setting the black level to 0 before using any of the color enhancement features, e.g., Balance White, Color Transformation, or Gamma. After the color enhancements have been applied, you can change the black level as desired. However, increasing the black level will decrease the color accuracy.\n\n```python\ncamera.BlackLevel.SetValue(0)\nprint (\"camera.BlackLevel.GetValue()\", camera.BlackLevel.GetValue())\n```\n\n## Gamma\n\n![Gamma correction](https://en.wikipedia.org/wiki/Gamma_correction)\n\nThe Gamma camera feature allows you to optimize the brightness of acquired images for display on a monitor.\n\nUsing the Feature\n\n### How It Works\n\nThe camera applies a gamma correction value (γ) to the brightness value of each pixel according to the following formula (red pixel value (R) of a color camera shown as an example):\n$R_{corrected} = (\\frac{ R_{uncorrected} }{ R_{max} }) ^ γ * R_{max} $\n\nThe maximum pixel value (Rmax) equals, e.g., 255 for 8-bit pixel formats or 1 023 for 10-bit pixel formats.\n\n### Enabling Gamma Correction\n\nTo enable gamma correction:\n\n1. Set the GammaEnable parameter to true (if available).\n2. For best results, set the BlackLevel parameter to 0.\n3. Set the Gamma parameter to the desired value. The parameter's value range is 0 to ≈4.\n    + Gamma = 1: The overall brightness remains unchanged.\n    + Gamma < 1: The overall brightness increases.\n    + Gamma > 1: The overall brightness decreases.\n\nIn all cases, black pixels (brightness = 0) and white pixels (brightness = maximum) will not be adjusted.\n\n**INFO**\nIf you enable gamma correction and the pixel format is set to a 12-bit pixel format, some image information will be lost. Pixel data output will still be 12-bit, but the pixel values will be interpolated during the gamma correction process.\n\n### Additional Parameters\n\nDepending on your camera model, the following additional parameters are available:\n\n+ GammaEnable: Enables or disables gamma correction.\n+ GammaSelector: Allows you to select one of the following gamma correction modes:\n    + User: The gamma correction value can be set as desired. (Default.)\n    + sRGB: The camera automatically sets a gamma correction value of approximately 0.4. This value is optimized for image display on sRGB monitors.\n\n+ BslColorSpaceMode or BslColorSpace: Allows you to select one of the following gamma correction modes:\n    + RGB: No additional gamma correction value is applied.\n    + sRGB: The image brightness is optimized for display on an sRGB monitor. A gamma correction value of approximately 0.4 is applied. For more information, see the footnotes in the Specifics section.\n\n```python\n# Set the Gamma value to 1.2\ncamera.Gamma.SetValue(1.2)\nprint (\"camera.Gamma.GetValue()\", camera.Gamma.GetValue())\n# Set the color space to sRGB\ncamera.BslColorSpace.SetValue(\"sRgb\");\nprint (\"camera.BslColorSpace.GetValue(): \", camera.BslColorSpace.GetValue())\n```\n\n## Auto Function ROI\n\nThe Auto Function ROI camera feature allows you to specify the part of the sensor array with which you want to control the camera's auto functions.\n\nROI is short for region of interest (formerly AOI = area of interest).\n\nYou can create several auto function ROIs, each occupying different parts of the sensor array.\n\nThe settings for the Auto Function ROI feature are independent of the settings for the Image ROI feature.\n\n### Changing Position and Size of an Auto Function ROI\n\nBy default, all auto function ROIs are set to the same size as the camera's image ROI. You can change their positions and sizes to suit your needs.\n\nTo change the position and size of an auto function ROI:\n\n1. Set the AutoFunctionROISelector parameter to one of the available auto function ROIs, e.g., ROI1.\n2. Enter values for the following parameters to specify the position of the auto function ROI selected:\n    + AutoFunctionROIOffsetX\n    + AutoFunctionROIOffsetY\n3. Enter values for the following parameters to specify the size of the auto function ROI selected:\n    + AutoFunctionROIWidth\n    + AutoFunctionROIHeight\n\nThe position of an auto function ROI is specified based on the lines and rows of the sensor array.\n\nExample: Assume that you have selected auto function ROI 1 and specified the following settings:\n\n    AutoFunctionROIOffsetX = 14\n    AutoFunctionROIOffsetY = 7\n    AutoFunctionROIWidth = 5\n    AutoFunctionROIHeight = 6\n\nThis creates the following auto function ROI 1:\n![](https://docs.baslerweb.com/images/drawing-af-aoi.svg)\nOnly the pixel data from the area of overlap between the auto function ROI and the image ROI will be used by the auto function assigned to it.\n**Info**\n\n+ On color cameras, Basler recommends setting the parameters for position and size to even values (multiples of 2). This matches the auto function ROI to the color filter pattern of the sensor.\n+ If the Binning feature is enabled, the auto function ROI settings refer to the binned lines and columns and not to the physical lines in the sensor.\n+ If the Reverse X or Reverse Y feature or both are enabled, the position of the auto function ROI relative to the sensor remains the same. As a consequence, different regions of the image will be controlled depending on whether or not Reverse X, Reverse Y or both are enabled.\n\n### Auto Function ROI Highlighting\nIf highlighting is supported by your camera model, you can highlight one or multiple Auto Function ROIs in the pylon Viewer. Areas that don't belong to the Auto Function ROIs appear darker:\n![](https://docs.baslerweb.com/images/image-auto-function-roi-highlight.jpg)\n\nTo highlight an Auto Function ROI:\n\n1. Set the AutoFunctionROISelector parameter to the desired auto function ROI, e.g., ROI1.\n2. Set the AutoFunctionROIHighlight parameter to true.\n\n### Assigning Auto Functions\n\nBy default, each auto function ROI is assigned to a specific auto function. For example, the pixel data from auto function ROI 2 is used to control the Balance White Auto auto function.\n\nOn some camera models, the default assignments can be changed. To do so:\n\nSet the AutoFunctionROISelector parameter to one of the available auto function ROIs, e.g., ROI1.\n\nAssign the desired auto function(s) to the auto function ROI selected:\n\n+ If you want to assign Balance White Auto, set the AutoFunctionROIUseWhiteBalance parameter to true.\n+ If you want to assign Exposure Auto and gain auto, set the AutoFunctionROIUseBrightness parameter to true. (Exposure Auto and Gain Auto always work together.)\n+ If you want to assign Tonal Range Auto, set the AutoFunctionROIUseTonalRange parameter to true.\n\n**Info**\n\n+ If you assign one auto function to multiple auto function ROIs, the pixel data from all selected auto function ROIs will be used for the auto function.\n+ If you assign multiple auto functions to one auto function ROI, the pixel data from the auto function ROI will be used for all auto functions selected.\n\nExposure Auto and Gain Auto Assignments Work Together\nWhen making auto function ROI assignments, the Gain Auto auto function and the exposure auto auto function always work together. they are considered as a single auto function named \"intensity\" or \"brightness\", depending on your camera model.\n\nThis does not imply, however, that Gain Auto and Exposure Auto must always be enabled at the same time.\n\n### Guidelines\n\nWhen you are setting an auto function ROI, you must follow these guidelines:\n\n| Guideline | Example|\n| --------- |:------:|\n| AutoFunctionROIOffsetX + AutoFunctionROIWidth ≤ Width of camera sensor | Camera with a 1920 x 1080 pixel sensor: AutoFunctionROIOffsetX + AutoFunctionROIWidth ≤ 1920 |\n| AutoFunctionROIOffsetY + AutoFunctionROIHeight ≤ Height of camera sensor | Camera with a 1920 x 1080 pixel sensor: AutoFunctionROIOffsetY + AutoFunctionROIHeight ≤ 1080 |\n\n### Overlap Between Auto Function ROI and Image ROI\n\nThe size and position of an auto function ROI can be identical to the size and position of the image ROI, but this is not a requirement. For an auto function to work, it is sufficient if both ROIs overlap each other partially.\n\nThe overlap between auto function ROI and image ROI determines whether and to what extent the auto function will control the related image property. Only the pixel data from the areas of overlap will be used by the auto function to control the image property of the entire image.\n\n+ If the auto function ROI is completely contained in the image ROI, the pixel data from the auto function ROI will be used to control the image property.\n![](https://docs.baslerweb.com/images/drawing-af-aoi-with-full-effect.svg)\n\n+ If the image ROI is completely contained in the auto function ROI, only the pixel data from the image ROI will be used to control the image property.\n![](https://docs.baslerweb.com/images/drawing-af-aoi-all-encompassing.svg)\n\n+ If the auto function ROI overlaps the image ROI only partially, only the pixel data from the area of partial overlap will be used to control the image property.\n![](https://docs.baslerweb.com/images/drawing-af-aoi-with-partial-effect.svg)\n\n+ If the auto function ROI does not overlap the image ROI, the related auto function will not work.\n![](https://docs.baslerweb.com/images/drawing-af-aoi-with-no-effect.svg)\n**Info**\n\nBasler strongly recommends completely including the auto function ROI within the image ROI or choosing identical positions and sizes for auto function ROI and image ROI.\n\n```python\n# Select auto function ROI 1\ncamera.AutoFunctionROISelector.SetValue(\"ROI1\")\n\n# Specify position and size of the auto function ROI selected\ncamera.AutoFunctionROIOffsetX.SetValue(camera.OffsetX.GetValue())\ncamera.AutoFunctionROIOffsetY.SetValue(camera.OffsetY.GetValue())\ncamera.AutoFunctionROIWidth.SetValue(camera.Width.GetValue())\ncamera.AutoFunctionROIHeight.SetValue(camera.Height.GetValue())\n\nprint (\"camera.AutoFunctionROIOffsetX.GetValue(): \", camera.AutoFunctionROIOffsetX.GetValue())\nprint (\"camera.AutoFunctionROIOffsetY.GetValue(): \", camera.AutoFunctionROIOffsetY.GetValue())\n\nprint (\"camera.AutoFunctionROIWidth.GetValue(): \", camera.AutoFunctionROIWidth.GetValue())\nprint (\"camera.AutoFunctionROIHeight.GetValue(): \", camera.AutoFunctionROIHeight.GetValue())\n\n\nassert camera.AutoFunctionROIOffsetX.GetValue() + camera.AutoFunctionROIWidth.GetValue() <= camera.Width.GetMax()\nassert camera.AutoFunctionROIOffsetY.GetValue() + camera.AutoFunctionROIHeight.GetValue() <= camera.Height.GetMax()\n\n# Enable the 'Brightness' auto function (Gain Auto + Exposure Auto)\n# for the auto function ROI selected\ncamera.AutoFunctionROIUseBrightness.SetValue(True)\n# Highlight the auto function ROI selected\ncamera.AutoFunctionROIHighlight.SetValue(False)\n```\n## Auto Function Profile\nThe Auto Function Profile camera feature allows you to specify how gain and exposure time are balanced when the camera is making automatic adjustments.\n\n### Setting the Auto Function Profile\n\nTo set the auto function profile:\n\n1. Set the Gain Auto auto function and the Exposure Auto auto function to Continuous.\n2. Set the AutoFunctionProfile parameter to one of the following values (if available):\n    + MinimizeGain\n    + MinimizeExposureTime\n    + MinimizeGainQuick\n    + MinimizeExposureTimeQuick\n    + Smart\n    + AntiFlicker50Hz\n    + AntiFlicker60Hz\n\n### Available Auto Function Profiles\n#### Minimize Gain (= Gain Minimum)\n\nThe gain is kept as low as possible during the automatic adjustment process. If the exposure time is at its upper limit and the target brightness value has not been reached yet, the gain will be increased in order to reach the target.\n\n#### Minimize Exposure Time (= Exposure Minimum)\n\nThe exposure time is kept as low as possible during the automatic adjustment process. If the gain is at its upper limit and the target brightness value has not been reached yet, the exposure time will be increased in order to reach the target.\n\n#### Minimize Gain Quick (= Gain Minimum Quick)\n\nThis profile works the same as the Minimize Gain profile. The difference is that it reacts more quickly in situations with extreme changes in brightness or where the image brightness changes rapidly. This situation occurs, for example, when microscope objective lenses are changed using the objective turret.\n\n#### Minimize Exposure Time Quick (= Exposure Minimum Quick)\n\nThis profile works the same as the Minimize Exposure Time profile. The difference is that it reacts more quickly in situations with extreme changes in brightness or where the image brightness changes rapidly. This situation occurs, for example, when microscope objective lenses are changed using the objective turret.\n\n#### Smart\n\nGain is kept as low as possible and the frame rate will be kept as high as possible during automatic adjustments.\n\nThis is a four-step process:\n\n1. The camera adjusts the exposure time to achieve the target brightness value.\n2. If the exposure time must be increased to achieve the target brightness value, the camera does so until the frame rate drops.\n3. If the frame rate drops, the camera stops increasing the exposure time and increases the gain until the AutoGainUpperLimit value is reached.\n4. When the AutoGainUpperLimit value has been reached, the camera stops increasing the gain and increases the exposure time until the target brightness value is reached. Increasing the exposure time results in a lower frame rate.\n\n#### Anti-Flicker 50 Hz / 60 Hz\n\nGain and exposure time are optimized to reduce flickering. If the camera is operating in an environment where the lighting flickers at a 50-Hz or a 60-Hz rate, the flickering lights can cause significant changes in brightness from image to image. Enabling the anti-flicker profile may reduce the effect of the flickering in the captured images.\n\nChoose the frequency (50 Hz or 60 Hz) according your local power line frequency (e.g., North America: 60 Hz, Europe: 50 Hz).\n\n```python\n# Set the auto function profile to Exposure Minimum\ncamera.AutoFunctionProfile.SetValue(\"MinimizeExposureTime\");\nprint (\"camera.AutoFunctionProfile.GetValue(): \", camera.AutoFunctionProfile.GetValue())\n\n# Set the auto function profile to Gain Minimum\ncamera.AutoFunctionProfile.SetValue(\"MinimizeGain\")\nprint (\"camera.AutoFunctionProfile.GetValue(): \", camera.AutoFunctionProfile.GetValue())\n\n# Enable Gain and Exposure Auto auto functions and set the operating mode to Continuous\n\ncamera.GainAuto.SetValue(\"Continuous\")\nprint (\"camera.GainAuto.GetValue(): \", camera.GainAuto.GetValue())\n\ncamera.ExposureAuto.SetValue(\"Continuous\")\nprint (\"camera.ExposureAuto.GetValue(): \", camera.ExposureAuto.GetValue())\n```\n\n## Balance White Auto\n\nThe Balance White Auto camera feature automatically corrects color shifts in images acquired.\n\nThe pixel data for the auto function can come from one or multiple auto function ROIs.\n\nTo correct color shifts manually, use the Balance White feature.\n\n### Enabling or Disabling Balance White Auto\n\nTo enable or disable the Balance White Auto auto function:\n\n1. Assign at least one auto function ROI to the Balance White Auto auto function.\n    Make sure the auto function ROI overlaps the image ROI, either partially or completely.\n2. Set the BalanceWhiteAuto parameter to one of the following operating modes:\n    + Once: The camera adjusts the white balance until the average gray values for red, green, and blue are identical. When this has been achieved, or after a maximum of 30 calculation cycles, the camera sets the auto function to Off and applies the balance ratios resulting from the last calculation to all following images.\n    + Continuous: The camera adjusts the white balance continuously while images are being acquired. The adjustment process continues until the operating mode is set to Once or Off.\n    + Off: Disables the Balance White Auto auto function. The BalanceRatio parameters remain at the values resulting from the last automatic or manual adjustment.\n\n### How It Works\n\nAutomatic white balancing is a two-step process:\n\n1. The camera compares the average gray values of the red, green, and blue pixels. It determines the color with the highest average gray value (i.e., the brightest color) and sets the BalanceRatio parameter value for this color to 1.\n2. The camera automatically adjusts the BalanceRatio parameter values of the other two colors until the average gray values for red, green, and blue are identical.\n\nAs a result, the BalanceRatio parameter is set to 1 for one color and to a value between 1 and ≈15.98 for the other two colors.\n\nExample: Assume the green pixels in your image have the highest average gray value. If you enable the Balance White Auto auto function, the camera sets the BalanceRatio parameter value for green to 1. Then, the camera automatically adjusts the BalanceRatio parameter values for red and blue until the average gray values for red, green, and blue are identical. The new balance ratios could be, e.g., green = 1, red = 1.08789, and blue = 2.19678.\n\n**Info**\n\n+ To view the BalanceRatio parameter values for red, green, or blue, switch to the respective color channel using the BalanceRatioSelector.\n+ When the camera is capturing images continuously, the auto function takes effect with a short delay. The first few images may not be affected by the auto function.\n\n```python\ncamera.AutoFunctionROISelector.SetValue(\"ROI1\")\n\ncamera.AutoFunctionROIUseWhiteBalance.SetValue(True)\nprint (\"camera.AutoFunctionROIUseWhiteBalance.GetValue(): \", camera.AutoFunctionROIUseWhiteBalance.GetValue())\ncamera.BalanceWhiteAuto.SetValue(\"Continuous\")\nprint (\"camera.BalanceWhiteAuto.GetValue(): \", camera.BalanceWhiteAuto.GetValue())\n```\n\n## Light Source Preset\n![](https://docs.baslerweb.com/light-source-preset)\n\nThe Light Source Preset camera feature allows you to correct color shifts caused by certain light sources.\n\nDepending on its specific color temperature, the light used for image acquisition can cause color shifts in the image. You can correct these color shifts by selecting the related light source preset.\n\nSelecting a Light Source Preset\n\nTo select a light source preset, set the BslLightSourcePreset parameter to one of the following values (if available):\n\n    Off: No light source preset is selected.\n    Daylight5000K: The camera corrects color shifts caused by daylight lighting that has a color temperature of about 5 000 K.\n    Daylight6500K: The camera corrects color shifts caused by daylight lighting that has a color temperature of about 6 500 K.\n    Tungsten2800K: The camera corrects color shifts caused by tungsten lighting that has a color temperature of about 2 500 to 3 000 K.\n    MicroscopeLED4500K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 4 500 K.\n    MicroscopeLED5500K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 5 500 K.\n    MicroscopeLED6000K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 6 000 K.\n    Fluorescent4000K: The camera corrects color shifts caused by fluorescent lighting that has a color temperature of about 4 000 K.\n    Custom: Selecting this preset enables the Color Transformation feature which allows you to customize the light source settings. You should only select this preset if you are thoroughly familiar with matrix color transformations. The camera also adjusts the Balance White and Color Adjustment settings so that they have neutral values that do not change the appearance of the colors.\n\nThe default light source preset varies by camera model.\n**Info**\n\nOn Basler dart cameras, the light source presets are calibrated for the IR cut filter in the CS-mount variant. If you are using an S-mount or bare board variant, make sure your IR cut filter has suitable spectral characteristics.\n\nFor more information about the IR cut filter, see your camera topic. You can find your camera topic in the \"Models\" section.\n\n### Impact on Other Features\n\nWhen you select a light source preset, the camera adjusts the settings of the following color enhancement features:\n+ Balance White\n+ Color Adjustment\n+ Color Transformation\nThe settings will be optimized for the selected light source.\nOn some camera models, you can choose which features you want the camera to adjust.\n\n### Separate Processing\nOn some camera models, when you select a light source preset, the camera processes the changes to the features listed above separately. This means that the values of the corresponding parameters visible in the pylon API and the pylon Viewer are not changed.\n\nExample: If you select the Daylight6500K light source preset, the camera adjusts the white balance, but the values of the BalanceRatio parameter don't change.\n\nThis has the advantage that you don't lose your color enhancement feature settings when you change the light source preset. Your own settings are independent from the light source preset adjustments.\n\n### No Separate Processing\nOn some camera models, when you select a light source preset, the camera doesn't process the feature changes separately. Instead, the camera directly adjusts the corresponding parameter values.\n\nExample: If you select the Daylight6500K light source preset, the values of the BalanceRatio parameter change. You can see the changes in the pylon Viewer or by accessing the parameter via the pylon API.\n\nThis means if you set up the color enhancement features and then change the light source preset, your settings will be overwritten.\n\n### Light Source Preset Feature Selector\n\nOn some camera models, the BslLightSourcePresetFeatureSelector parameter is available.\n\nIf the parameter is available, you can select which features you want the camera to adjust when you select a light source preset.\n\nBy default, the camera adjusts all features.\n\nTo enable or disable adjustment of a specific feature:\n\n1. Set the BslLightSourcePresetFeatureSelector parameter to the desired feature, e.g., ColorAdjustment.\n2. Set the BslLightSourcePresetFeatureEnable parameter to true (feature enabled) or false (feature disabled).\n3. Repeat steps 1 and 2 for all features that you want to enable or disable.\n\n```python\n# Disable light source presets (no correction)\ncamera.BslLightSourcePreset.SetValue(\"Off\")\n# Set the light source preset for daylight (at about 5000K)\ncamera.BslLightSourcePreset.SetValue(\"Daylight5000K\")\n# Set the light source preset for tungsten lighting (at about 2800K)\ncamera.BslLightSourcePreset.SetValue(\"Tungsten\")\n# Set the light source preset for daylight (at about 6500K)\ncamera.BslLightSourcePreset.SetValue(\"Daylight6500K\")\n\n\n# Disable adjustment of a specific feature\ncamera.BslLightSourcePresetFeatureSelector.SetValue(\"ColorAdjustment\")\ncamera.BslLightSourcePresetFeatureEnable.SetValue(False)\n```\n\n","slug":"baslerWithOpencv","published":1,"updated":"2020-10-07T04:52:21.541Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckfyx1ajd002tiiiygl3060ia","content":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about using Basler Camera with Opencv on Python. At the beginning of this guide I will introduct how to set-up development environment with Pylon and opencv within Conda virual environment. Seconly, I will talk about how to check and set some of basic Basler feature base on pypylon. At the end, I will give a example about using Opencv read Basler Camera data stream.</p>\n<h1 id=\"Hardware-and-Software-Testing-Environment\"><a href=\"#Hardware-and-Software-Testing-Environment\" class=\"headerlink\" title=\"Hardware and Software Testing Environment\"></a>Hardware and Software Testing Environment</h1><h2 id=\"Hardware-Environment\"><a href=\"#Hardware-Environment\" class=\"headerlink\" title=\"Hardware Environment\"></a>Hardware Environment</h2><ul>\n<li>Camera: Basler (a2A1920 - 51gcPRO)</li>\n<li>Network Adapter: Intel I350 Gigabit Network adapter (POE)</li>\n<li>CPU: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</li>\n<li>RAM: 16GiB system memory<h2 id=\"Software-Environment\"><a href=\"#Software-Environment\" class=\"headerlink\" title=\"Software Environment\"></a>Software Environment</h2></li>\n<li>Ubuntu 18.04 (Linux version 5.4.0-48-generic)</li>\n<li>Need set-up Network exchange environment, the document link: <a href=\"/2020/09/05/ubuntuRouter/\" title=\"Setting up an ubuntu Router with bridge\">Setting up an ubuntu Router with bridge</a></li>\n</ul>\n<h1 id=\"Development-Environment-Set-up\"><a href=\"#Development-Environment-Set-up\" class=\"headerlink\" title=\"Development Environment Set-up\"></a>Development Environment Set-up</h1><h2 id=\"Creating-conda-environment\"><a href=\"#Creating-conda-environment\" class=\"headerlink\" title=\"Creating conda environment\"></a>Creating conda environment</h2><p>You can follow the below steps to create the conda environment. If you want to know more details about Conda, please have a look link: <a href=\"/2020/09/08/conda/\" title=\"Getting started with Python and R environments using Conda\">Getting started with Python and R environments using Conda</a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n baslerOpencv python=3.7.7</span><br><span class=\"line\">conda activate baslerOpencv</span><br><span class=\"line\">conda install notebook ipykernel</span><br><span class=\"line\">ipython kernel install --user --name baslerOpencv --display-name <span class=\"string\">&quot;Python (Basler with Opencv)&quot;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Installing-Pylon\"><a href=\"#Installing-Pylon\" class=\"headerlink\" title=\"Installing Pylon\"></a>Installing Pylon</h2><ol>\n<li>Go to <a href=\"https://www.baslerweb.com/en/products/software/basler-pylon-camera-software-suite/\">Pylon Official Website</a>.</li>\n<li>Go to Downloads Section</li>\n<li>Click link: pylon 6.1.1 Camera Software Suite Linux x86 (64 Bit) - Debian Installer Package</li>\n<li>Filling in your personal INFOs and click “Start the Download!”</li>\n<li>Goto you download directory(Using cd command)</li>\n<li>You can use the apt command for install deb file<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install xxxx.deb</span><br></pre></td></tr></table></figure>\nWhen you done, you can see there are three applications be installed, which are Pylon IP Configurator, pylon viewer and Basler Product Documention.</li>\n</ol>\n<h2 id=\"Installing-pypylon-binary-wheel-file-to-conda-environment\"><a href=\"#Installing-pypylon-binary-wheel-file-to-conda-environment\" class=\"headerlink\" title=\"Installing pypylon binary wheel file to conda environment\"></a>Installing pypylon binary wheel file to conda environment</h2><p><a href=\"https://github.com/basler/pypylon\">pypylon</a></p>\n<h2 id=\"For-the-Impatient\"><a href=\"#For-the-Impatient\" class=\"headerlink\" title=\"For the Impatient\"></a>For the Impatient</h2><ul>\n<li>Download a binary wheel from the <a href=\"https://github.com/Basler/pypylon/releases\">releases</a> page.<br><a href=\"https://github.com/basler/pypylon/releases/download/1.6.0/pypylon-1.6.0-cp37-cp37m-linux_x86_64.whl\">https://github.com/basler/pypylon/releases/download/1.6.0/pypylon-1.6.0-cp37-cp37m-linux_x86_64.whl</a></li>\n<li>Install the wheel using pip3 install <your downloaded wheel>.whl</li>\n<li>Look at samples/grab.py in this repository</li>\n</ul>\n<p><strong>TIPS:</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">&quot;opencv.py&quot;</span>, line 6, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    from pypylon import pylon</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/yanboyang713/miniconda3/envs/baslerOpencv/lib/python3.7/site-packages/pypylon/pylon.py&quot;</span>, line 40, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    from . import _pylon</span><br><span class=\"line\">ImportError: libpython3.7m.so.1.0: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=/home/yanboyang713/miniconda3/envs/front/lib</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Set-up-pypylon-opencv-viewer-Option\"><a href=\"#Set-up-pypylon-opencv-viewer-Option\" class=\"headerlink\" title=\"Set-up pypylon-opencv-viewer(Option)\"></a>Set-up pypylon-opencv-viewer(Option)</h2><p>pip install pypylon-opencv-viewer</p>\n<h2 id=\"Installing-Opencv-to-conda-environment\"><a href=\"#Installing-Opencv-to-conda-environment\" class=\"headerlink\" title=\"Installing Opencv to conda environment\"></a>Installing Opencv to conda environment</h2><p>pip install opencv-python==3.4.2.17<br>pip install opencv-contrib-python==3.4.2.17 </p>\n<h1 id=\"Image-Control\"><a href=\"#Image-Control\" class=\"headerlink\" title=\"Image Control\"></a>Image Control</h1><h2 id=\"Image-ROI-Area-of-Insterest\"><a href=\"#Image-ROI-Area-of-Insterest\" class=\"headerlink\" title=\"Image ROI (Area of Insterest)\"></a>Image ROI (Area of Insterest)</h2><h3 id=\"Getting-the-width-of-the-maximum-value-and-the-height-of-the-maximum-value\"><a href=\"#Getting-the-width-of-the-maximum-value-and-the-height-of-the-maximum-value\" class=\"headerlink\" title=\"Getting the width of the maximum value and the height of the maximum value\"></a>Getting the width of the maximum value and the height of the maximum value</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;MaxWidth: &quot;</span>, camera.Width.GetMax())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;MaxHeight: &quot;</span>, camera.Height.GetMax())</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Setting-the-width-of-the-image-ROI-and-the-height-of-the-image-ROI\"><a href=\"#Setting-the-width-of-the-image-ROI-and-the-height-of-the-image-ROI\" class=\"headerlink\" title=\"Setting the width of the image ROI and the height of the image ROI\"></a>Setting the width of the image ROI and the height of the image ROI</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Set the width to 1920</span></span><br><span class=\"line\">camera.Width.SetValue(<span class=\"number\">1920</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the height to 1080</span></span><br><span class=\"line\">camera.Height.SetValue(<span class=\"number\">1080</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Center-the-image-ROI\"><a href=\"#Center-the-image-ROI\" class=\"headerlink\" title=\"Center the image ROI\"></a>Center the image ROI</h3><ul>\n<li>To enable Center X, set the CenterX parameter to true.<br>The camera adjusts the OffsetX parameter value to center the image ROI horizontally. When you change the width of the image ROI, the OffsetX parameter value automatically adapts. The OffsetX parameter becomes read-only.</li>\n<li>To enable Center Y, set the CenterY parameter to true.<br>The camera adjusts the OffsetY parameter value to center the image ROI vertically. When you change the height of the image ROI, the OffsetY parameter value automatically adapts. The OffsetY parameter becomes read-only.</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.BslCenterX.Execute();</span><br><span class=\"line\">camera.BslCenterY.Execute();</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Setting-the-offset-of-image-ROI\"><a href=\"#Setting-the-offset-of-image-ROI\" class=\"headerlink\" title=\"Setting the offset of image ROI\"></a>Setting the offset of image ROI</h3><p>If you already center the image ROI, offset parameter becomes read-only. You cannot set offset value again.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.OffsetX.SetValue(<span class=\"number\">0</span>);</span><br><span class=\"line\">camera.OffsetY.SetValue(<span class=\"number\">0</span>);</span><br></pre></td></tr></table></figure>\n<p>‘’’</p>\n<h3 id=\"Print-the-ROI-INFOs\"><a href=\"#Print-the-ROI-INFOs\" class=\"headerlink\" title=\"Print the ROI INFOs\"></a>Print the ROI INFOs</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Width increment: &quot;</span>, camera.Width.GetInc())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Height increment: &quot;</span>, camera.Height.GetInc())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Minimum Width: &quot;</span>, camera.Width.GetMin())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Minimum Height: &quot;</span>, camera.Height.GetMin())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Width: &quot;</span>, camera.Width.GetValue())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;Camera offsetX: &quot;</span>, camera.OffsetX.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Height: &quot;</span>, camera.Height.GetValue())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;Camera offsetY: &quot;</span>, camera.OffsetY.GetValue() )</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> camera.Width.GetValue() + camera.OffsetX.GetValue() &lt;= camera.Width.GetMax()</span><br><span class=\"line\"><span class=\"keyword\">assert</span> camera.Height.GetValue() + camera.OffsetY.GetValue() &lt;= camera.Height.GetMax()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Image-Pixel-Format-Control\"><a href=\"#Image-Pixel-Format-Control\" class=\"headerlink\" title=\"Image/Pixel Format Control\"></a>Image/Pixel Format Control</h2><p>The offical <a href=\"https://docs.baslerweb.com/pixel-format\">Pixel Formats</a></p>\n<ul>\n<li>list your camera available Pixel Formats<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(camera.PixelFormat.Symbolics)</span><br></pre></td></tr></table></figure></li>\n<li>show your current Pixel Formats in used<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.PixelFormat.GetValue: &quot;</span>, camera.PixelFormat.GetValue())</span><br></pre></td></tr></table></figure>\n<h3 id=\"Mono-Formats\"><a href=\"#Mono-Formats\" class=\"headerlink\" title=\"Mono Formats\"></a>Mono Formats</h3>If a monochrome camera uses one of the mono pixel formats, it outputs 8, 10, or 12 bits of data per pixel.</li>\n</ul>\n<p>If a color camera uses the Mono 8 pixel format, the values for each pixel are first converted to the YUV color model. The Y component of this model represents a brightness value and is equivalent to the value that would be derived from a pixel in a monochrome image. So in essence, when a color camera is set to Mono 8, it outputs an 8-bit monochrome image. This type of output is sometimes referred to as “Y Mono 8”.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;Mono8&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;Mono12&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;Mono12p&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Bayer-Formats\"><a href=\"#Bayer-Formats\" class=\"headerlink\" title=\"Bayer Formats\"></a>Bayer Formats</h3><p>Color cameras are equipped with a Bayer color filter and can output color images based on the Bayer pixel formats given below.</p>\n<p>If a color camera uses one of these Bayer pixel formats, it outputs 8, 10, or 12 bits of data per pixel. The pixel data is not processed or interpolated in any way. For each pixel covered with a red filter, you get 8, 10, or 12 bits of red data. For each pixel covered with a green filter, you get 8, 10, or 12 bits of green data. For each pixel covered with a blue filter, you get 8, 10, or 12 bits of blue data. This type of pixel data is sometimes referred to as “raw” output.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;BayerRG8&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;BayerRG12&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;BayerRG12p&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"RGB-and-BGR-Formats\"><a href=\"#RGB-and-BGR-Formats\" class=\"headerlink\" title=\"RGB and BGR Formats\"></a>RGB and BGR Formats</h3><p>When a color camera uses the RGB 8 or BGR 8 pixel format, the camera outputs 8 bit of red data, 8 bit of green data, and 8 bit of blue data for each pixel in the acquired frame.</p>\n<p>The pixel formats differ by the output sequences for the color data (red, green, blue or blue, green, red).</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;RGB8&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;BGR8&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"YUV-Formats\"><a href=\"#YUV-Formats\" class=\"headerlink\" title=\"YUV Formats\"></a>YUV Formats</h3><p>Color cameras can also output color images based on pixel data in YUV (or YCbCr) format.</p>\n<p>If a color camera uses this format, each pixel value in the captured image goes through a conversion process as it exits the sensor and passes through the camera. This process yields Y, U, and V color information for each pixel value.</p>\n<p><strong>Info</strong></p>\n<p>The values for U and V normally range from -128 to +127. Because the camera transfers U values and V values with unsigned integers, 128 is added to each U value and V value before they are transferred from the camera. This way, values from 0 to 255 can be transferred.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;YCbCr422_8&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Black-Level\"><a href=\"#Black-Level\" class=\"headerlink\" title=\"Black Level\"></a>Black Level</h2><p>The Black Level camera feature allows you to change the overall brightness of an image. All gray values of the pixels are changed by a specified amount.</p>\n<p>For example, you can increase the gray value of each pixel in the image by 3.</p>\n<p>Adjusting the Black Level</p>\n<p>To adjust the black level, enter a value for the BlackLevel parameter.</p>\n<p>The minimum black level setting is 0. The maximum setting depends on the camera model.</p>\n<p>The change in the gray value resulting from the BlackLevel parameter value also depends on the camera model.</p>\n<p><strong>INFO</strong><br>Basler recommends setting the black level to 0 before using any of the color enhancement features, e.g., Balance White, Color Transformation, or Gamma. After the color enhancements have been applied, you can change the black level as desired. However, increasing the black level will decrease the color accuracy.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.BlackLevel.SetValue(<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.BlackLevel.GetValue()&quot;</span>, camera.BlackLevel.GetValue())</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Gamma\"><a href=\"#Gamma\" class=\"headerlink\" title=\"Gamma\"></a>Gamma</h2><p><img src=\"https://en.wikipedia.org/wiki/Gamma_correction\" alt=\"Gamma correction\"></p>\n<p>The Gamma camera feature allows you to optimize the brightness of acquired images for display on a monitor.</p>\n<p>Using the Feature</p>\n<h3 id=\"How-It-Works\"><a href=\"#How-It-Works\" class=\"headerlink\" title=\"How It Works\"></a>How It Works</h3><p>The camera applies a gamma correction value (γ) to the brightness value of each pixel according to the following formula (red pixel value (R) of a color camera shown as an example):<br>$R_{corrected} = (\\frac{ R_{uncorrected} }{ R_{max} }) ^ γ * R_{max} $</p>\n<p>The maximum pixel value (Rmax) equals, e.g., 255 for 8-bit pixel formats or 1 023 for 10-bit pixel formats.</p>\n<h3 id=\"Enabling-Gamma-Correction\"><a href=\"#Enabling-Gamma-Correction\" class=\"headerlink\" title=\"Enabling Gamma Correction\"></a>Enabling Gamma Correction</h3><p>To enable gamma correction:</p>\n<ol>\n<li>Set the GammaEnable parameter to true (if available).</li>\n<li>For best results, set the BlackLevel parameter to 0.</li>\n<li>Set the Gamma parameter to the desired value. The parameter’s value range is 0 to ≈4.<ul>\n<li>Gamma = 1: The overall brightness remains unchanged.</li>\n<li>Gamma &lt; 1: The overall brightness increases.</li>\n<li>Gamma &gt; 1: The overall brightness decreases.</li>\n</ul>\n</li>\n</ol>\n<p>In all cases, black pixels (brightness = 0) and white pixels (brightness = maximum) will not be adjusted.</p>\n<p><strong>INFO</strong><br>If you enable gamma correction and the pixel format is set to a 12-bit pixel format, some image information will be lost. Pixel data output will still be 12-bit, but the pixel values will be interpolated during the gamma correction process.</p>\n<h3 id=\"Additional-Parameters\"><a href=\"#Additional-Parameters\" class=\"headerlink\" title=\"Additional Parameters\"></a>Additional Parameters</h3><p>Depending on your camera model, the following additional parameters are available:</p>\n<ul>\n<li><p>GammaEnable: Enables or disables gamma correction.</p>\n</li>\n<li><p>GammaSelector: Allows you to select one of the following gamma correction modes:</p>\n<ul>\n<li>User: The gamma correction value can be set as desired. (Default.)</li>\n<li>sRGB: The camera automatically sets a gamma correction value of approximately 0.4. This value is optimized for image display on sRGB monitors.</li>\n</ul>\n</li>\n<li><p>BslColorSpaceMode or BslColorSpace: Allows you to select one of the following gamma correction modes:</p>\n<ul>\n<li>RGB: No additional gamma correction value is applied.</li>\n<li>sRGB: The image brightness is optimized for display on an sRGB monitor. A gamma correction value of approximately 0.4 is applied. For more information, see the footnotes in the Specifics section.</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Set the Gamma value to 1.2</span></span><br><span class=\"line\">camera.Gamma.SetValue(<span class=\"number\">1.2</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.Gamma.GetValue()&quot;</span>, camera.Gamma.GetValue())</span><br><span class=\"line\"><span class=\"comment\"># Set the color space to sRGB</span></span><br><span class=\"line\">camera.BslColorSpace.SetValue(<span class=\"string\">&quot;sRgb&quot;</span>);</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.BslColorSpace.GetValue(): &quot;</span>, camera.BslColorSpace.GetValue())</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Auto-Function-ROI\"><a href=\"#Auto-Function-ROI\" class=\"headerlink\" title=\"Auto Function ROI\"></a>Auto Function ROI</h2><p>The Auto Function ROI camera feature allows you to specify the part of the sensor array with which you want to control the camera’s auto functions.</p>\n<p>ROI is short for region of interest (formerly AOI = area of interest).</p>\n<p>You can create several auto function ROIs, each occupying different parts of the sensor array.</p>\n<p>The settings for the Auto Function ROI feature are independent of the settings for the Image ROI feature.</p>\n<h3 id=\"Changing-Position-and-Size-of-an-Auto-Function-ROI\"><a href=\"#Changing-Position-and-Size-of-an-Auto-Function-ROI\" class=\"headerlink\" title=\"Changing Position and Size of an Auto Function ROI\"></a>Changing Position and Size of an Auto Function ROI</h3><p>By default, all auto function ROIs are set to the same size as the camera’s image ROI. You can change their positions and sizes to suit your needs.</p>\n<p>To change the position and size of an auto function ROI:</p>\n<ol>\n<li>Set the AutoFunctionROISelector parameter to one of the available auto function ROIs, e.g., ROI1.</li>\n<li>Enter values for the following parameters to specify the position of the auto function ROI selected:<ul>\n<li>AutoFunctionROIOffsetX</li>\n<li>AutoFunctionROIOffsetY</li>\n</ul>\n</li>\n<li>Enter values for the following parameters to specify the size of the auto function ROI selected:<ul>\n<li>AutoFunctionROIWidth</li>\n<li>AutoFunctionROIHeight</li>\n</ul>\n</li>\n</ol>\n<p>The position of an auto function ROI is specified based on the lines and rows of the sensor array.</p>\n<p>Example: Assume that you have selected auto function ROI 1 and specified the following settings:</p>\n<pre><code>AutoFunctionROIOffsetX = 14\nAutoFunctionROIOffsetY = 7\nAutoFunctionROIWidth = 5\nAutoFunctionROIHeight = 6</code></pre>\n<p>This creates the following auto function ROI 1:<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi.svg\"><br>Only the pixel data from the area of overlap between the auto function ROI and the image ROI will be used by the auto function assigned to it.<br><strong>Info</strong></p>\n<ul>\n<li>On color cameras, Basler recommends setting the parameters for position and size to even values (multiples of 2). This matches the auto function ROI to the color filter pattern of the sensor.</li>\n<li>If the Binning feature is enabled, the auto function ROI settings refer to the binned lines and columns and not to the physical lines in the sensor.</li>\n<li>If the Reverse X or Reverse Y feature or both are enabled, the position of the auto function ROI relative to the sensor remains the same. As a consequence, different regions of the image will be controlled depending on whether or not Reverse X, Reverse Y or both are enabled.</li>\n</ul>\n<h3 id=\"Auto-Function-ROI-Highlighting\"><a href=\"#Auto-Function-ROI-Highlighting\" class=\"headerlink\" title=\"Auto Function ROI Highlighting\"></a>Auto Function ROI Highlighting</h3><p>If highlighting is supported by your camera model, you can highlight one or multiple Auto Function ROIs in the pylon Viewer. Areas that don’t belong to the Auto Function ROIs appear darker:<br><img src=\"https://docs.baslerweb.com/images/image-auto-function-roi-highlight.jpg\"></p>\n<p>To highlight an Auto Function ROI:</p>\n<ol>\n<li>Set the AutoFunctionROISelector parameter to the desired auto function ROI, e.g., ROI1.</li>\n<li>Set the AutoFunctionROIHighlight parameter to true.</li>\n</ol>\n<h3 id=\"Assigning-Auto-Functions\"><a href=\"#Assigning-Auto-Functions\" class=\"headerlink\" title=\"Assigning Auto Functions\"></a>Assigning Auto Functions</h3><p>By default, each auto function ROI is assigned to a specific auto function. For example, the pixel data from auto function ROI 2 is used to control the Balance White Auto auto function.</p>\n<p>On some camera models, the default assignments can be changed. To do so:</p>\n<p>Set the AutoFunctionROISelector parameter to one of the available auto function ROIs, e.g., ROI1.</p>\n<p>Assign the desired auto function(s) to the auto function ROI selected:</p>\n<ul>\n<li>If you want to assign Balance White Auto, set the AutoFunctionROIUseWhiteBalance parameter to true.</li>\n<li>If you want to assign Exposure Auto and gain auto, set the AutoFunctionROIUseBrightness parameter to true. (Exposure Auto and Gain Auto always work together.)</li>\n<li>If you want to assign Tonal Range Auto, set the AutoFunctionROIUseTonalRange parameter to true.</li>\n</ul>\n<p><strong>Info</strong></p>\n<ul>\n<li>If you assign one auto function to multiple auto function ROIs, the pixel data from all selected auto function ROIs will be used for the auto function.</li>\n<li>If you assign multiple auto functions to one auto function ROI, the pixel data from the auto function ROI will be used for all auto functions selected.</li>\n</ul>\n<p>Exposure Auto and Gain Auto Assignments Work Together<br>When making auto function ROI assignments, the Gain Auto auto function and the exposure auto auto function always work together. they are considered as a single auto function named “intensity” or “brightness”, depending on your camera model.</p>\n<p>This does not imply, however, that Gain Auto and Exposure Auto must always be enabled at the same time.</p>\n<h3 id=\"Guidelines\"><a href=\"#Guidelines\" class=\"headerlink\" title=\"Guidelines\"></a>Guidelines</h3><p>When you are setting an auto function ROI, you must follow these guidelines:</p>\n<table>\n<thead>\n<tr>\n<th>Guideline</th>\n<th align=\"center\">Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>AutoFunctionROIOffsetX + AutoFunctionROIWidth ≤ Width of camera sensor</td>\n<td align=\"center\">Camera with a 1920 x 1080 pixel sensor: AutoFunctionROIOffsetX + AutoFunctionROIWidth ≤ 1920</td>\n</tr>\n<tr>\n<td>AutoFunctionROIOffsetY + AutoFunctionROIHeight ≤ Height of camera sensor</td>\n<td align=\"center\">Camera with a 1920 x 1080 pixel sensor: AutoFunctionROIOffsetY + AutoFunctionROIHeight ≤ 1080</td>\n</tr>\n</tbody></table>\n<h3 id=\"Overlap-Between-Auto-Function-ROI-and-Image-ROI\"><a href=\"#Overlap-Between-Auto-Function-ROI-and-Image-ROI\" class=\"headerlink\" title=\"Overlap Between Auto Function ROI and Image ROI\"></a>Overlap Between Auto Function ROI and Image ROI</h3><p>The size and position of an auto function ROI can be identical to the size and position of the image ROI, but this is not a requirement. For an auto function to work, it is sufficient if both ROIs overlap each other partially.</p>\n<p>The overlap between auto function ROI and image ROI determines whether and to what extent the auto function will control the related image property. Only the pixel data from the areas of overlap will be used by the auto function to control the image property of the entire image.</p>\n<ul>\n<li><p>If the auto function ROI is completely contained in the image ROI, the pixel data from the auto function ROI will be used to control the image property.<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi-with-full-effect.svg\"></p>\n</li>\n<li><p>If the image ROI is completely contained in the auto function ROI, only the pixel data from the image ROI will be used to control the image property.<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi-all-encompassing.svg\"></p>\n</li>\n<li><p>If the auto function ROI overlaps the image ROI only partially, only the pixel data from the area of partial overlap will be used to control the image property.<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi-with-partial-effect.svg\"></p>\n</li>\n<li><p>If the auto function ROI does not overlap the image ROI, the related auto function will not work.<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi-with-no-effect.svg\"></p>\n</li>\n</ul>\n<p><strong>Info</strong></p>\n<p>Basler strongly recommends completely including the auto function ROI within the image ROI or choosing identical positions and sizes for auto function ROI and image ROI.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Select auto function ROI 1</span></span><br><span class=\"line\">camera.AutoFunctionROISelector.SetValue(<span class=\"string\">&quot;ROI1&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Specify position and size of the auto function ROI selected</span></span><br><span class=\"line\">camera.AutoFunctionROIOffsetX.SetValue(camera.OffsetX.GetValue())</span><br><span class=\"line\">camera.AutoFunctionROIOffsetY.SetValue(camera.OffsetY.GetValue())</span><br><span class=\"line\">camera.AutoFunctionROIWidth.SetValue(camera.Width.GetValue())</span><br><span class=\"line\">camera.AutoFunctionROIHeight.SetValue(camera.Height.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIOffsetX.GetValue(): &quot;</span>, camera.AutoFunctionROIOffsetX.GetValue())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIOffsetY.GetValue(): &quot;</span>, camera.AutoFunctionROIOffsetY.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIWidth.GetValue(): &quot;</span>, camera.AutoFunctionROIWidth.GetValue())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIHeight.GetValue(): &quot;</span>, camera.AutoFunctionROIHeight.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> camera.AutoFunctionROIOffsetX.GetValue() + camera.AutoFunctionROIWidth.GetValue() &lt;= camera.Width.GetMax()</span><br><span class=\"line\"><span class=\"keyword\">assert</span> camera.AutoFunctionROIOffsetY.GetValue() + camera.AutoFunctionROIHeight.GetValue() &lt;= camera.Height.GetMax()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Enable the &#x27;Brightness&#x27; auto function (Gain Auto + Exposure Auto)</span></span><br><span class=\"line\"><span class=\"comment\"># for the auto function ROI selected</span></span><br><span class=\"line\">camera.AutoFunctionROIUseBrightness.SetValue(<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\"># Highlight the auto function ROI selected</span></span><br><span class=\"line\">camera.AutoFunctionROIHighlight.SetValue(<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Auto-Function-Profile\"><a href=\"#Auto-Function-Profile\" class=\"headerlink\" title=\"Auto Function Profile\"></a>Auto Function Profile</h2><p>The Auto Function Profile camera feature allows you to specify how gain and exposure time are balanced when the camera is making automatic adjustments.</p>\n<h3 id=\"Setting-the-Auto-Function-Profile\"><a href=\"#Setting-the-Auto-Function-Profile\" class=\"headerlink\" title=\"Setting the Auto Function Profile\"></a>Setting the Auto Function Profile</h3><p>To set the auto function profile:</p>\n<ol>\n<li>Set the Gain Auto auto function and the Exposure Auto auto function to Continuous.</li>\n<li>Set the AutoFunctionProfile parameter to one of the following values (if available):<ul>\n<li>MinimizeGain</li>\n<li>MinimizeExposureTime</li>\n<li>MinimizeGainQuick</li>\n<li>MinimizeExposureTimeQuick</li>\n<li>Smart</li>\n<li>AntiFlicker50Hz</li>\n<li>AntiFlicker60Hz</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"Available-Auto-Function-Profiles\"><a href=\"#Available-Auto-Function-Profiles\" class=\"headerlink\" title=\"Available Auto Function Profiles\"></a>Available Auto Function Profiles</h3><h4 id=\"Minimize-Gain-Gain-Minimum\"><a href=\"#Minimize-Gain-Gain-Minimum\" class=\"headerlink\" title=\"Minimize Gain (= Gain Minimum)\"></a>Minimize Gain (= Gain Minimum)</h4><p>The gain is kept as low as possible during the automatic adjustment process. If the exposure time is at its upper limit and the target brightness value has not been reached yet, the gain will be increased in order to reach the target.</p>\n<h4 id=\"Minimize-Exposure-Time-Exposure-Minimum\"><a href=\"#Minimize-Exposure-Time-Exposure-Minimum\" class=\"headerlink\" title=\"Minimize Exposure Time (= Exposure Minimum)\"></a>Minimize Exposure Time (= Exposure Minimum)</h4><p>The exposure time is kept as low as possible during the automatic adjustment process. If the gain is at its upper limit and the target brightness value has not been reached yet, the exposure time will be increased in order to reach the target.</p>\n<h4 id=\"Minimize-Gain-Quick-Gain-Minimum-Quick\"><a href=\"#Minimize-Gain-Quick-Gain-Minimum-Quick\" class=\"headerlink\" title=\"Minimize Gain Quick (= Gain Minimum Quick)\"></a>Minimize Gain Quick (= Gain Minimum Quick)</h4><p>This profile works the same as the Minimize Gain profile. The difference is that it reacts more quickly in situations with extreme changes in brightness or where the image brightness changes rapidly. This situation occurs, for example, when microscope objective lenses are changed using the objective turret.</p>\n<h4 id=\"Minimize-Exposure-Time-Quick-Exposure-Minimum-Quick\"><a href=\"#Minimize-Exposure-Time-Quick-Exposure-Minimum-Quick\" class=\"headerlink\" title=\"Minimize Exposure Time Quick (= Exposure Minimum Quick)\"></a>Minimize Exposure Time Quick (= Exposure Minimum Quick)</h4><p>This profile works the same as the Minimize Exposure Time profile. The difference is that it reacts more quickly in situations with extreme changes in brightness or where the image brightness changes rapidly. This situation occurs, for example, when microscope objective lenses are changed using the objective turret.</p>\n<h4 id=\"Smart\"><a href=\"#Smart\" class=\"headerlink\" title=\"Smart\"></a>Smart</h4><p>Gain is kept as low as possible and the frame rate will be kept as high as possible during automatic adjustments.</p>\n<p>This is a four-step process:</p>\n<ol>\n<li>The camera adjusts the exposure time to achieve the target brightness value.</li>\n<li>If the exposure time must be increased to achieve the target brightness value, the camera does so until the frame rate drops.</li>\n<li>If the frame rate drops, the camera stops increasing the exposure time and increases the gain until the AutoGainUpperLimit value is reached.</li>\n<li>When the AutoGainUpperLimit value has been reached, the camera stops increasing the gain and increases the exposure time until the target brightness value is reached. Increasing the exposure time results in a lower frame rate.</li>\n</ol>\n<h4 id=\"Anti-Flicker-50-Hz-60-Hz\"><a href=\"#Anti-Flicker-50-Hz-60-Hz\" class=\"headerlink\" title=\"Anti-Flicker 50 Hz / 60 Hz\"></a>Anti-Flicker 50 Hz / 60 Hz</h4><p>Gain and exposure time are optimized to reduce flickering. If the camera is operating in an environment where the lighting flickers at a 50-Hz or a 60-Hz rate, the flickering lights can cause significant changes in brightness from image to image. Enabling the anti-flicker profile may reduce the effect of the flickering in the captured images.</p>\n<p>Choose the frequency (50 Hz or 60 Hz) according your local power line frequency (e.g., North America: 60 Hz, Europe: 50 Hz).</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Set the auto function profile to Exposure Minimum</span></span><br><span class=\"line\">camera.AutoFunctionProfile.SetValue(<span class=\"string\">&quot;MinimizeExposureTime&quot;</span>);</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionProfile.GetValue(): &quot;</span>, camera.AutoFunctionProfile.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the auto function profile to Gain Minimum</span></span><br><span class=\"line\">camera.AutoFunctionProfile.SetValue(<span class=\"string\">&quot;MinimizeGain&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionProfile.GetValue(): &quot;</span>, camera.AutoFunctionProfile.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Enable Gain and Exposure Auto auto functions and set the operating mode to Continuous</span></span><br><span class=\"line\"></span><br><span class=\"line\">camera.GainAuto.SetValue(<span class=\"string\">&quot;Continuous&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.GainAuto.GetValue(): &quot;</span>, camera.GainAuto.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\">camera.ExposureAuto.SetValue(<span class=\"string\">&quot;Continuous&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.ExposureAuto.GetValue(): &quot;</span>, camera.ExposureAuto.GetValue())</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Balance-White-Auto\"><a href=\"#Balance-White-Auto\" class=\"headerlink\" title=\"Balance White Auto\"></a>Balance White Auto</h2><p>The Balance White Auto camera feature automatically corrects color shifts in images acquired.</p>\n<p>The pixel data for the auto function can come from one or multiple auto function ROIs.</p>\n<p>To correct color shifts manually, use the Balance White feature.</p>\n<h3 id=\"Enabling-or-Disabling-Balance-White-Auto\"><a href=\"#Enabling-or-Disabling-Balance-White-Auto\" class=\"headerlink\" title=\"Enabling or Disabling Balance White Auto\"></a>Enabling or Disabling Balance White Auto</h3><p>To enable or disable the Balance White Auto auto function:</p>\n<ol>\n<li>Assign at least one auto function ROI to the Balance White Auto auto function.<br> Make sure the auto function ROI overlaps the image ROI, either partially or completely.</li>\n<li>Set the BalanceWhiteAuto parameter to one of the following operating modes:<ul>\n<li>Once: The camera adjusts the white balance until the average gray values for red, green, and blue are identical. When this has been achieved, or after a maximum of 30 calculation cycles, the camera sets the auto function to Off and applies the balance ratios resulting from the last calculation to all following images.</li>\n<li>Continuous: The camera adjusts the white balance continuously while images are being acquired. The adjustment process continues until the operating mode is set to Once or Off.</li>\n<li>Off: Disables the Balance White Auto auto function. The BalanceRatio parameters remain at the values resulting from the last automatic or manual adjustment.</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"How-It-Works-1\"><a href=\"#How-It-Works-1\" class=\"headerlink\" title=\"How It Works\"></a>How It Works</h3><p>Automatic white balancing is a two-step process:</p>\n<ol>\n<li>The camera compares the average gray values of the red, green, and blue pixels. It determines the color with the highest average gray value (i.e., the brightest color) and sets the BalanceRatio parameter value for this color to 1.</li>\n<li>The camera automatically adjusts the BalanceRatio parameter values of the other two colors until the average gray values for red, green, and blue are identical.</li>\n</ol>\n<p>As a result, the BalanceRatio parameter is set to 1 for one color and to a value between 1 and ≈15.98 for the other two colors.</p>\n<p>Example: Assume the green pixels in your image have the highest average gray value. If you enable the Balance White Auto auto function, the camera sets the BalanceRatio parameter value for green to 1. Then, the camera automatically adjusts the BalanceRatio parameter values for red and blue until the average gray values for red, green, and blue are identical. The new balance ratios could be, e.g., green = 1, red = 1.08789, and blue = 2.19678.</p>\n<p><strong>Info</strong></p>\n<ul>\n<li>To view the BalanceRatio parameter values for red, green, or blue, switch to the respective color channel using the BalanceRatioSelector.</li>\n<li>When the camera is capturing images continuously, the auto function takes effect with a short delay. The first few images may not be affected by the auto function.</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.AutoFunctionROISelector.SetValue(<span class=\"string\">&quot;ROI1&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">camera.AutoFunctionROIUseWhiteBalance.SetValue(<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIUseWhiteBalance.GetValue(): &quot;</span>, camera.AutoFunctionROIUseWhiteBalance.GetValue())</span><br><span class=\"line\">camera.BalanceWhiteAuto.SetValue(<span class=\"string\">&quot;Continuous&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.BalanceWhiteAuto.GetValue(): &quot;</span>, camera.BalanceWhiteAuto.GetValue())</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Light-Source-Preset\"><a href=\"#Light-Source-Preset\" class=\"headerlink\" title=\"Light Source Preset\"></a>Light Source Preset</h2><p><img src=\"https://docs.baslerweb.com/light-source-preset\"></p>\n<p>The Light Source Preset camera feature allows you to correct color shifts caused by certain light sources.</p>\n<p>Depending on its specific color temperature, the light used for image acquisition can cause color shifts in the image. You can correct these color shifts by selecting the related light source preset.</p>\n<p>Selecting a Light Source Preset</p>\n<p>To select a light source preset, set the BslLightSourcePreset parameter to one of the following values (if available):</p>\n<pre><code>Off: No light source preset is selected.\nDaylight5000K: The camera corrects color shifts caused by daylight lighting that has a color temperature of about 5 000 K.\nDaylight6500K: The camera corrects color shifts caused by daylight lighting that has a color temperature of about 6 500 K.\nTungsten2800K: The camera corrects color shifts caused by tungsten lighting that has a color temperature of about 2 500 to 3 000 K.\nMicroscopeLED4500K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 4 500 K.\nMicroscopeLED5500K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 5 500 K.\nMicroscopeLED6000K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 6 000 K.\nFluorescent4000K: The camera corrects color shifts caused by fluorescent lighting that has a color temperature of about 4 000 K.\nCustom: Selecting this preset enables the Color Transformation feature which allows you to customize the light source settings. You should only select this preset if you are thoroughly familiar with matrix color transformations. The camera also adjusts the Balance White and Color Adjustment settings so that they have neutral values that do not change the appearance of the colors.</code></pre>\n<p>The default light source preset varies by camera model.<br><strong>Info</strong></p>\n<p>On Basler dart cameras, the light source presets are calibrated for the IR cut filter in the CS-mount variant. If you are using an S-mount or bare board variant, make sure your IR cut filter has suitable spectral characteristics.</p>\n<p>For more information about the IR cut filter, see your camera topic. You can find your camera topic in the “Models” section.</p>\n<h3 id=\"Impact-on-Other-Features\"><a href=\"#Impact-on-Other-Features\" class=\"headerlink\" title=\"Impact on Other Features\"></a>Impact on Other Features</h3><p>When you select a light source preset, the camera adjusts the settings of the following color enhancement features:</p>\n<ul>\n<li>Balance White</li>\n<li>Color Adjustment</li>\n<li>Color Transformation<br>The settings will be optimized for the selected light source.<br>On some camera models, you can choose which features you want the camera to adjust.</li>\n</ul>\n<h3 id=\"Separate-Processing\"><a href=\"#Separate-Processing\" class=\"headerlink\" title=\"Separate Processing\"></a>Separate Processing</h3><p>On some camera models, when you select a light source preset, the camera processes the changes to the features listed above separately. This means that the values of the corresponding parameters visible in the pylon API and the pylon Viewer are not changed.</p>\n<p>Example: If you select the Daylight6500K light source preset, the camera adjusts the white balance, but the values of the BalanceRatio parameter don’t change.</p>\n<p>This has the advantage that you don’t lose your color enhancement feature settings when you change the light source preset. Your own settings are independent from the light source preset adjustments.</p>\n<h3 id=\"No-Separate-Processing\"><a href=\"#No-Separate-Processing\" class=\"headerlink\" title=\"No Separate Processing\"></a>No Separate Processing</h3><p>On some camera models, when you select a light source preset, the camera doesn’t process the feature changes separately. Instead, the camera directly adjusts the corresponding parameter values.</p>\n<p>Example: If you select the Daylight6500K light source preset, the values of the BalanceRatio parameter change. You can see the changes in the pylon Viewer or by accessing the parameter via the pylon API.</p>\n<p>This means if you set up the color enhancement features and then change the light source preset, your settings will be overwritten.</p>\n<h3 id=\"Light-Source-Preset-Feature-Selector\"><a href=\"#Light-Source-Preset-Feature-Selector\" class=\"headerlink\" title=\"Light Source Preset Feature Selector\"></a>Light Source Preset Feature Selector</h3><p>On some camera models, the BslLightSourcePresetFeatureSelector parameter is available.</p>\n<p>If the parameter is available, you can select which features you want the camera to adjust when you select a light source preset.</p>\n<p>By default, the camera adjusts all features.</p>\n<p>To enable or disable adjustment of a specific feature:</p>\n<ol>\n<li>Set the BslLightSourcePresetFeatureSelector parameter to the desired feature, e.g., ColorAdjustment.</li>\n<li>Set the BslLightSourcePresetFeatureEnable parameter to true (feature enabled) or false (feature disabled).</li>\n<li>Repeat steps 1 and 2 for all features that you want to enable or disable.</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Disable light source presets (no correction)</span></span><br><span class=\"line\">camera.BslLightSourcePreset.SetValue(<span class=\"string\">&quot;Off&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># Set the light source preset for daylight (at about 5000K)</span></span><br><span class=\"line\">camera.BslLightSourcePreset.SetValue(<span class=\"string\">&quot;Daylight5000K&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># Set the light source preset for tungsten lighting (at about 2800K)</span></span><br><span class=\"line\">camera.BslLightSourcePreset.SetValue(<span class=\"string\">&quot;Tungsten&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># Set the light source preset for daylight (at about 6500K)</span></span><br><span class=\"line\">camera.BslLightSourcePreset.SetValue(<span class=\"string\">&quot;Daylight6500K&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Disable adjustment of a specific feature</span></span><br><span class=\"line\">camera.BslLightSourcePresetFeatureSelector.SetValue(<span class=\"string\">&quot;ColorAdjustment&quot;</span>)</span><br><span class=\"line\">camera.BslLightSourcePresetFeatureEnable.SetValue(<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>This post document is about using Basler Camera with Opencv on Python. At the beginning of this guide I will introduct how to set-up development environment with Pylon and opencv within Conda virual environment. Seconly, I will talk about how to check and set some of basic Basler feature base on pypylon. At the end, I will give a example about using Opencv read Basler Camera data stream.</p>\n<h1 id=\"Hardware-and-Software-Testing-Environment\"><a href=\"#Hardware-and-Software-Testing-Environment\" class=\"headerlink\" title=\"Hardware and Software Testing Environment\"></a>Hardware and Software Testing Environment</h1><h2 id=\"Hardware-Environment\"><a href=\"#Hardware-Environment\" class=\"headerlink\" title=\"Hardware Environment\"></a>Hardware Environment</h2><ul>\n<li>Camera: Basler (a2A1920 - 51gcPRO)</li>\n<li>Network Adapter: Intel I350 Gigabit Network adapter (POE)</li>\n<li>CPU: Intel(R) Core(TM) i7-9700F CPU @ 3.00GHz</li>\n<li>RAM: 16GiB system memory<h2 id=\"Software-Environment\"><a href=\"#Software-Environment\" class=\"headerlink\" title=\"Software Environment\"></a>Software Environment</h2></li>\n<li>Ubuntu 18.04 (Linux version 5.4.0-48-generic)</li>\n<li>Need set-up Network exchange environment, the document link: <a href=\"/2020/09/05/ubuntuRouter/\" title=\"Setting up an ubuntu Router with bridge\">Setting up an ubuntu Router with bridge</a></li>\n</ul>\n<h1 id=\"Development-Environment-Set-up\"><a href=\"#Development-Environment-Set-up\" class=\"headerlink\" title=\"Development Environment Set-up\"></a>Development Environment Set-up</h1><h2 id=\"Creating-conda-environment\"><a href=\"#Creating-conda-environment\" class=\"headerlink\" title=\"Creating conda environment\"></a>Creating conda environment</h2><p>You can follow the below steps to create the conda environment. If you want to know more details about Conda, please have a look link: <a href=\"/2020/09/08/conda/\" title=\"Getting started with Python and R environments using Conda\">Getting started with Python and R environments using Conda</a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n baslerOpencv python=3.7.7</span><br><span class=\"line\">conda activate baslerOpencv</span><br><span class=\"line\">conda install notebook ipykernel</span><br><span class=\"line\">ipython kernel install --user --name baslerOpencv --display-name <span class=\"string\">&quot;Python (Basler with Opencv)&quot;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Installing-Pylon\"><a href=\"#Installing-Pylon\" class=\"headerlink\" title=\"Installing Pylon\"></a>Installing Pylon</h2><ol>\n<li>Go to <a href=\"https://www.baslerweb.com/en/products/software/basler-pylon-camera-software-suite/\">Pylon Official Website</a>.</li>\n<li>Go to Downloads Section</li>\n<li>Click link: pylon 6.1.1 Camera Software Suite Linux x86 (64 Bit) - Debian Installer Package</li>\n<li>Filling in your personal INFOs and click “Start the Download!”</li>\n<li>Goto you download directory(Using cd command)</li>\n<li>You can use the apt command for install deb file<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install xxxx.deb</span><br></pre></td></tr></table></figure>\nWhen you done, you can see there are three applications be installed, which are Pylon IP Configurator, pylon viewer and Basler Product Documention.</li>\n</ol>\n<h2 id=\"Installing-pypylon-binary-wheel-file-to-conda-environment\"><a href=\"#Installing-pypylon-binary-wheel-file-to-conda-environment\" class=\"headerlink\" title=\"Installing pypylon binary wheel file to conda environment\"></a>Installing pypylon binary wheel file to conda environment</h2><p><a href=\"https://github.com/basler/pypylon\">pypylon</a></p>\n<h2 id=\"For-the-Impatient\"><a href=\"#For-the-Impatient\" class=\"headerlink\" title=\"For the Impatient\"></a>For the Impatient</h2><ul>\n<li>Download a binary wheel from the <a href=\"https://github.com/Basler/pypylon/releases\">releases</a> page.<br><a href=\"https://github.com/basler/pypylon/releases/download/1.6.0/pypylon-1.6.0-cp37-cp37m-linux_x86_64.whl\">https://github.com/basler/pypylon/releases/download/1.6.0/pypylon-1.6.0-cp37-cp37m-linux_x86_64.whl</a></li>\n<li>Install the wheel using pip3 install <your downloaded wheel>.whl</li>\n<li>Look at samples/grab.py in this repository</li>\n</ul>\n<p><strong>TIPS:</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">&quot;opencv.py&quot;</span>, line 6, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    from pypylon import pylon</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/yanboyang713/miniconda3/envs/baslerOpencv/lib/python3.7/site-packages/pypylon/pylon.py&quot;</span>, line 40, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    from . import _pylon</span><br><span class=\"line\">ImportError: libpython3.7m.so.1.0: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=/home/yanboyang713/miniconda3/envs/front/lib</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Set-up-pypylon-opencv-viewer-Option\"><a href=\"#Set-up-pypylon-opencv-viewer-Option\" class=\"headerlink\" title=\"Set-up pypylon-opencv-viewer(Option)\"></a>Set-up pypylon-opencv-viewer(Option)</h2><p>pip install pypylon-opencv-viewer</p>\n<h2 id=\"Installing-Opencv-to-conda-environment\"><a href=\"#Installing-Opencv-to-conda-environment\" class=\"headerlink\" title=\"Installing Opencv to conda environment\"></a>Installing Opencv to conda environment</h2><p>pip install opencv-python==3.4.2.17<br>pip install opencv-contrib-python==3.4.2.17 </p>\n<h1 id=\"Image-Control\"><a href=\"#Image-Control\" class=\"headerlink\" title=\"Image Control\"></a>Image Control</h1><h2 id=\"Image-ROI-Area-of-Insterest\"><a href=\"#Image-ROI-Area-of-Insterest\" class=\"headerlink\" title=\"Image ROI (Area of Insterest)\"></a>Image ROI (Area of Insterest)</h2><h3 id=\"Getting-the-width-of-the-maximum-value-and-the-height-of-the-maximum-value\"><a href=\"#Getting-the-width-of-the-maximum-value-and-the-height-of-the-maximum-value\" class=\"headerlink\" title=\"Getting the width of the maximum value and the height of the maximum value\"></a>Getting the width of the maximum value and the height of the maximum value</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;MaxWidth: &quot;</span>, camera.Width.GetMax())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;MaxHeight: &quot;</span>, camera.Height.GetMax())</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Setting-the-width-of-the-image-ROI-and-the-height-of-the-image-ROI\"><a href=\"#Setting-the-width-of-the-image-ROI-and-the-height-of-the-image-ROI\" class=\"headerlink\" title=\"Setting the width of the image ROI and the height of the image ROI\"></a>Setting the width of the image ROI and the height of the image ROI</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Set the width to 1920</span></span><br><span class=\"line\">camera.Width.SetValue(<span class=\"number\">1920</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the height to 1080</span></span><br><span class=\"line\">camera.Height.SetValue(<span class=\"number\">1080</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Center-the-image-ROI\"><a href=\"#Center-the-image-ROI\" class=\"headerlink\" title=\"Center the image ROI\"></a>Center the image ROI</h3><ul>\n<li>To enable Center X, set the CenterX parameter to true.<br>The camera adjusts the OffsetX parameter value to center the image ROI horizontally. When you change the width of the image ROI, the OffsetX parameter value automatically adapts. The OffsetX parameter becomes read-only.</li>\n<li>To enable Center Y, set the CenterY parameter to true.<br>The camera adjusts the OffsetY parameter value to center the image ROI vertically. When you change the height of the image ROI, the OffsetY parameter value automatically adapts. The OffsetY parameter becomes read-only.</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.BslCenterX.Execute();</span><br><span class=\"line\">camera.BslCenterY.Execute();</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Setting-the-offset-of-image-ROI\"><a href=\"#Setting-the-offset-of-image-ROI\" class=\"headerlink\" title=\"Setting the offset of image ROI\"></a>Setting the offset of image ROI</h3><p>If you already center the image ROI, offset parameter becomes read-only. You cannot set offset value again.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.OffsetX.SetValue(<span class=\"number\">0</span>);</span><br><span class=\"line\">camera.OffsetY.SetValue(<span class=\"number\">0</span>);</span><br></pre></td></tr></table></figure>\n<p>‘’’</p>\n<h3 id=\"Print-the-ROI-INFOs\"><a href=\"#Print-the-ROI-INFOs\" class=\"headerlink\" title=\"Print the ROI INFOs\"></a>Print the ROI INFOs</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Width increment: &quot;</span>, camera.Width.GetInc())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Height increment: &quot;</span>, camera.Height.GetInc())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Minimum Width: &quot;</span>, camera.Width.GetMin())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Minimum Height: &quot;</span>, camera.Height.GetMin())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Width: &quot;</span>, camera.Width.GetValue())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;Camera offsetX: &quot;</span>, camera.OffsetX.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera Height: &quot;</span>, camera.Height.GetValue())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;Camera offsetY: &quot;</span>, camera.OffsetY.GetValue() )</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> camera.Width.GetValue() + camera.OffsetX.GetValue() &lt;= camera.Width.GetMax()</span><br><span class=\"line\"><span class=\"keyword\">assert</span> camera.Height.GetValue() + camera.OffsetY.GetValue() &lt;= camera.Height.GetMax()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Image-Pixel-Format-Control\"><a href=\"#Image-Pixel-Format-Control\" class=\"headerlink\" title=\"Image/Pixel Format Control\"></a>Image/Pixel Format Control</h2><p>The offical <a href=\"https://docs.baslerweb.com/pixel-format\">Pixel Formats</a></p>\n<ul>\n<li>list your camera available Pixel Formats<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(camera.PixelFormat.Symbolics)</span><br></pre></td></tr></table></figure></li>\n<li>show your current Pixel Formats in used<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.PixelFormat.GetValue: &quot;</span>, camera.PixelFormat.GetValue())</span><br></pre></td></tr></table></figure>\n<h3 id=\"Mono-Formats\"><a href=\"#Mono-Formats\" class=\"headerlink\" title=\"Mono Formats\"></a>Mono Formats</h3>If a monochrome camera uses one of the mono pixel formats, it outputs 8, 10, or 12 bits of data per pixel.</li>\n</ul>\n<p>If a color camera uses the Mono 8 pixel format, the values for each pixel are first converted to the YUV color model. The Y component of this model represents a brightness value and is equivalent to the value that would be derived from a pixel in a monochrome image. So in essence, when a color camera is set to Mono 8, it outputs an 8-bit monochrome image. This type of output is sometimes referred to as “Y Mono 8”.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;Mono8&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;Mono12&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;Mono12p&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Bayer-Formats\"><a href=\"#Bayer-Formats\" class=\"headerlink\" title=\"Bayer Formats\"></a>Bayer Formats</h3><p>Color cameras are equipped with a Bayer color filter and can output color images based on the Bayer pixel formats given below.</p>\n<p>If a color camera uses one of these Bayer pixel formats, it outputs 8, 10, or 12 bits of data per pixel. The pixel data is not processed or interpolated in any way. For each pixel covered with a red filter, you get 8, 10, or 12 bits of red data. For each pixel covered with a green filter, you get 8, 10, or 12 bits of green data. For each pixel covered with a blue filter, you get 8, 10, or 12 bits of blue data. This type of pixel data is sometimes referred to as “raw” output.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;BayerRG8&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;BayerRG12&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;BayerRG12p&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"RGB-and-BGR-Formats\"><a href=\"#RGB-and-BGR-Formats\" class=\"headerlink\" title=\"RGB and BGR Formats\"></a>RGB and BGR Formats</h3><p>When a color camera uses the RGB 8 or BGR 8 pixel format, the camera outputs 8 bit of red data, 8 bit of green data, and 8 bit of blue data for each pixel in the acquired frame.</p>\n<p>The pixel formats differ by the output sequences for the color data (red, green, blue or blue, green, red).</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;RGB8&quot;</span>)</span><br><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;BGR8&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"YUV-Formats\"><a href=\"#YUV-Formats\" class=\"headerlink\" title=\"YUV Formats\"></a>YUV Formats</h3><p>Color cameras can also output color images based on pixel data in YUV (or YCbCr) format.</p>\n<p>If a color camera uses this format, each pixel value in the captured image goes through a conversion process as it exits the sensor and passes through the camera. This process yields Y, U, and V color information for each pixel value.</p>\n<p><strong>Info</strong></p>\n<p>The values for U and V normally range from -128 to +127. Because the camera transfers U values and V values with unsigned integers, 128 is added to each U value and V value before they are transferred from the camera. This way, values from 0 to 255 can be transferred.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.PixelFormat.SetValue(<span class=\"string\">&quot;YCbCr422_8&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Black-Level\"><a href=\"#Black-Level\" class=\"headerlink\" title=\"Black Level\"></a>Black Level</h2><p>The Black Level camera feature allows you to change the overall brightness of an image. All gray values of the pixels are changed by a specified amount.</p>\n<p>For example, you can increase the gray value of each pixel in the image by 3.</p>\n<p>Adjusting the Black Level</p>\n<p>To adjust the black level, enter a value for the BlackLevel parameter.</p>\n<p>The minimum black level setting is 0. The maximum setting depends on the camera model.</p>\n<p>The change in the gray value resulting from the BlackLevel parameter value also depends on the camera model.</p>\n<p><strong>INFO</strong><br>Basler recommends setting the black level to 0 before using any of the color enhancement features, e.g., Balance White, Color Transformation, or Gamma. After the color enhancements have been applied, you can change the black level as desired. However, increasing the black level will decrease the color accuracy.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.BlackLevel.SetValue(<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.BlackLevel.GetValue()&quot;</span>, camera.BlackLevel.GetValue())</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Gamma\"><a href=\"#Gamma\" class=\"headerlink\" title=\"Gamma\"></a>Gamma</h2><p><img src=\"https://en.wikipedia.org/wiki/Gamma_correction\" alt=\"Gamma correction\"></p>\n<p>The Gamma camera feature allows you to optimize the brightness of acquired images for display on a monitor.</p>\n<p>Using the Feature</p>\n<h3 id=\"How-It-Works\"><a href=\"#How-It-Works\" class=\"headerlink\" title=\"How It Works\"></a>How It Works</h3><p>The camera applies a gamma correction value (γ) to the brightness value of each pixel according to the following formula (red pixel value (R) of a color camera shown as an example):<br>$R_{corrected} = (\\frac{ R_{uncorrected} }{ R_{max} }) ^ γ * R_{max} $</p>\n<p>The maximum pixel value (Rmax) equals, e.g., 255 for 8-bit pixel formats or 1 023 for 10-bit pixel formats.</p>\n<h3 id=\"Enabling-Gamma-Correction\"><a href=\"#Enabling-Gamma-Correction\" class=\"headerlink\" title=\"Enabling Gamma Correction\"></a>Enabling Gamma Correction</h3><p>To enable gamma correction:</p>\n<ol>\n<li>Set the GammaEnable parameter to true (if available).</li>\n<li>For best results, set the BlackLevel parameter to 0.</li>\n<li>Set the Gamma parameter to the desired value. The parameter’s value range is 0 to ≈4.<ul>\n<li>Gamma = 1: The overall brightness remains unchanged.</li>\n<li>Gamma &lt; 1: The overall brightness increases.</li>\n<li>Gamma &gt; 1: The overall brightness decreases.</li>\n</ul>\n</li>\n</ol>\n<p>In all cases, black pixels (brightness = 0) and white pixels (brightness = maximum) will not be adjusted.</p>\n<p><strong>INFO</strong><br>If you enable gamma correction and the pixel format is set to a 12-bit pixel format, some image information will be lost. Pixel data output will still be 12-bit, but the pixel values will be interpolated during the gamma correction process.</p>\n<h3 id=\"Additional-Parameters\"><a href=\"#Additional-Parameters\" class=\"headerlink\" title=\"Additional Parameters\"></a>Additional Parameters</h3><p>Depending on your camera model, the following additional parameters are available:</p>\n<ul>\n<li><p>GammaEnable: Enables or disables gamma correction.</p>\n</li>\n<li><p>GammaSelector: Allows you to select one of the following gamma correction modes:</p>\n<ul>\n<li>User: The gamma correction value can be set as desired. (Default.)</li>\n<li>sRGB: The camera automatically sets a gamma correction value of approximately 0.4. This value is optimized for image display on sRGB monitors.</li>\n</ul>\n</li>\n<li><p>BslColorSpaceMode or BslColorSpace: Allows you to select one of the following gamma correction modes:</p>\n<ul>\n<li>RGB: No additional gamma correction value is applied.</li>\n<li>sRGB: The image brightness is optimized for display on an sRGB monitor. A gamma correction value of approximately 0.4 is applied. For more information, see the footnotes in the Specifics section.</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Set the Gamma value to 1.2</span></span><br><span class=\"line\">camera.Gamma.SetValue(<span class=\"number\">1.2</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.Gamma.GetValue()&quot;</span>, camera.Gamma.GetValue())</span><br><span class=\"line\"><span class=\"comment\"># Set the color space to sRGB</span></span><br><span class=\"line\">camera.BslColorSpace.SetValue(<span class=\"string\">&quot;sRgb&quot;</span>);</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.BslColorSpace.GetValue(): &quot;</span>, camera.BslColorSpace.GetValue())</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Auto-Function-ROI\"><a href=\"#Auto-Function-ROI\" class=\"headerlink\" title=\"Auto Function ROI\"></a>Auto Function ROI</h2><p>The Auto Function ROI camera feature allows you to specify the part of the sensor array with which you want to control the camera’s auto functions.</p>\n<p>ROI is short for region of interest (formerly AOI = area of interest).</p>\n<p>You can create several auto function ROIs, each occupying different parts of the sensor array.</p>\n<p>The settings for the Auto Function ROI feature are independent of the settings for the Image ROI feature.</p>\n<h3 id=\"Changing-Position-and-Size-of-an-Auto-Function-ROI\"><a href=\"#Changing-Position-and-Size-of-an-Auto-Function-ROI\" class=\"headerlink\" title=\"Changing Position and Size of an Auto Function ROI\"></a>Changing Position and Size of an Auto Function ROI</h3><p>By default, all auto function ROIs are set to the same size as the camera’s image ROI. You can change their positions and sizes to suit your needs.</p>\n<p>To change the position and size of an auto function ROI:</p>\n<ol>\n<li>Set the AutoFunctionROISelector parameter to one of the available auto function ROIs, e.g., ROI1.</li>\n<li>Enter values for the following parameters to specify the position of the auto function ROI selected:<ul>\n<li>AutoFunctionROIOffsetX</li>\n<li>AutoFunctionROIOffsetY</li>\n</ul>\n</li>\n<li>Enter values for the following parameters to specify the size of the auto function ROI selected:<ul>\n<li>AutoFunctionROIWidth</li>\n<li>AutoFunctionROIHeight</li>\n</ul>\n</li>\n</ol>\n<p>The position of an auto function ROI is specified based on the lines and rows of the sensor array.</p>\n<p>Example: Assume that you have selected auto function ROI 1 and specified the following settings:</p>\n<pre><code>AutoFunctionROIOffsetX = 14\nAutoFunctionROIOffsetY = 7\nAutoFunctionROIWidth = 5\nAutoFunctionROIHeight = 6</code></pre>\n<p>This creates the following auto function ROI 1:<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi.svg\"><br>Only the pixel data from the area of overlap between the auto function ROI and the image ROI will be used by the auto function assigned to it.<br><strong>Info</strong></p>\n<ul>\n<li>On color cameras, Basler recommends setting the parameters for position and size to even values (multiples of 2). This matches the auto function ROI to the color filter pattern of the sensor.</li>\n<li>If the Binning feature is enabled, the auto function ROI settings refer to the binned lines and columns and not to the physical lines in the sensor.</li>\n<li>If the Reverse X or Reverse Y feature or both are enabled, the position of the auto function ROI relative to the sensor remains the same. As a consequence, different regions of the image will be controlled depending on whether or not Reverse X, Reverse Y or both are enabled.</li>\n</ul>\n<h3 id=\"Auto-Function-ROI-Highlighting\"><a href=\"#Auto-Function-ROI-Highlighting\" class=\"headerlink\" title=\"Auto Function ROI Highlighting\"></a>Auto Function ROI Highlighting</h3><p>If highlighting is supported by your camera model, you can highlight one or multiple Auto Function ROIs in the pylon Viewer. Areas that don’t belong to the Auto Function ROIs appear darker:<br><img src=\"https://docs.baslerweb.com/images/image-auto-function-roi-highlight.jpg\"></p>\n<p>To highlight an Auto Function ROI:</p>\n<ol>\n<li>Set the AutoFunctionROISelector parameter to the desired auto function ROI, e.g., ROI1.</li>\n<li>Set the AutoFunctionROIHighlight parameter to true.</li>\n</ol>\n<h3 id=\"Assigning-Auto-Functions\"><a href=\"#Assigning-Auto-Functions\" class=\"headerlink\" title=\"Assigning Auto Functions\"></a>Assigning Auto Functions</h3><p>By default, each auto function ROI is assigned to a specific auto function. For example, the pixel data from auto function ROI 2 is used to control the Balance White Auto auto function.</p>\n<p>On some camera models, the default assignments can be changed. To do so:</p>\n<p>Set the AutoFunctionROISelector parameter to one of the available auto function ROIs, e.g., ROI1.</p>\n<p>Assign the desired auto function(s) to the auto function ROI selected:</p>\n<ul>\n<li>If you want to assign Balance White Auto, set the AutoFunctionROIUseWhiteBalance parameter to true.</li>\n<li>If you want to assign Exposure Auto and gain auto, set the AutoFunctionROIUseBrightness parameter to true. (Exposure Auto and Gain Auto always work together.)</li>\n<li>If you want to assign Tonal Range Auto, set the AutoFunctionROIUseTonalRange parameter to true.</li>\n</ul>\n<p><strong>Info</strong></p>\n<ul>\n<li>If you assign one auto function to multiple auto function ROIs, the pixel data from all selected auto function ROIs will be used for the auto function.</li>\n<li>If you assign multiple auto functions to one auto function ROI, the pixel data from the auto function ROI will be used for all auto functions selected.</li>\n</ul>\n<p>Exposure Auto and Gain Auto Assignments Work Together<br>When making auto function ROI assignments, the Gain Auto auto function and the exposure auto auto function always work together. they are considered as a single auto function named “intensity” or “brightness”, depending on your camera model.</p>\n<p>This does not imply, however, that Gain Auto and Exposure Auto must always be enabled at the same time.</p>\n<h3 id=\"Guidelines\"><a href=\"#Guidelines\" class=\"headerlink\" title=\"Guidelines\"></a>Guidelines</h3><p>When you are setting an auto function ROI, you must follow these guidelines:</p>\n<table>\n<thead>\n<tr>\n<th>Guideline</th>\n<th align=\"center\">Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>AutoFunctionROIOffsetX + AutoFunctionROIWidth ≤ Width of camera sensor</td>\n<td align=\"center\">Camera with a 1920 x 1080 pixel sensor: AutoFunctionROIOffsetX + AutoFunctionROIWidth ≤ 1920</td>\n</tr>\n<tr>\n<td>AutoFunctionROIOffsetY + AutoFunctionROIHeight ≤ Height of camera sensor</td>\n<td align=\"center\">Camera with a 1920 x 1080 pixel sensor: AutoFunctionROIOffsetY + AutoFunctionROIHeight ≤ 1080</td>\n</tr>\n</tbody></table>\n<h3 id=\"Overlap-Between-Auto-Function-ROI-and-Image-ROI\"><a href=\"#Overlap-Between-Auto-Function-ROI-and-Image-ROI\" class=\"headerlink\" title=\"Overlap Between Auto Function ROI and Image ROI\"></a>Overlap Between Auto Function ROI and Image ROI</h3><p>The size and position of an auto function ROI can be identical to the size and position of the image ROI, but this is not a requirement. For an auto function to work, it is sufficient if both ROIs overlap each other partially.</p>\n<p>The overlap between auto function ROI and image ROI determines whether and to what extent the auto function will control the related image property. Only the pixel data from the areas of overlap will be used by the auto function to control the image property of the entire image.</p>\n<ul>\n<li><p>If the auto function ROI is completely contained in the image ROI, the pixel data from the auto function ROI will be used to control the image property.<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi-with-full-effect.svg\"></p>\n</li>\n<li><p>If the image ROI is completely contained in the auto function ROI, only the pixel data from the image ROI will be used to control the image property.<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi-all-encompassing.svg\"></p>\n</li>\n<li><p>If the auto function ROI overlaps the image ROI only partially, only the pixel data from the area of partial overlap will be used to control the image property.<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi-with-partial-effect.svg\"></p>\n</li>\n<li><p>If the auto function ROI does not overlap the image ROI, the related auto function will not work.<br><img src=\"https://docs.baslerweb.com/images/drawing-af-aoi-with-no-effect.svg\"></p>\n</li>\n</ul>\n<p><strong>Info</strong></p>\n<p>Basler strongly recommends completely including the auto function ROI within the image ROI or choosing identical positions and sizes for auto function ROI and image ROI.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Select auto function ROI 1</span></span><br><span class=\"line\">camera.AutoFunctionROISelector.SetValue(<span class=\"string\">&quot;ROI1&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Specify position and size of the auto function ROI selected</span></span><br><span class=\"line\">camera.AutoFunctionROIOffsetX.SetValue(camera.OffsetX.GetValue())</span><br><span class=\"line\">camera.AutoFunctionROIOffsetY.SetValue(camera.OffsetY.GetValue())</span><br><span class=\"line\">camera.AutoFunctionROIWidth.SetValue(camera.Width.GetValue())</span><br><span class=\"line\">camera.AutoFunctionROIHeight.SetValue(camera.Height.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIOffsetX.GetValue(): &quot;</span>, camera.AutoFunctionROIOffsetX.GetValue())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIOffsetY.GetValue(): &quot;</span>, camera.AutoFunctionROIOffsetY.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIWidth.GetValue(): &quot;</span>, camera.AutoFunctionROIWidth.GetValue())</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIHeight.GetValue(): &quot;</span>, camera.AutoFunctionROIHeight.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> camera.AutoFunctionROIOffsetX.GetValue() + camera.AutoFunctionROIWidth.GetValue() &lt;= camera.Width.GetMax()</span><br><span class=\"line\"><span class=\"keyword\">assert</span> camera.AutoFunctionROIOffsetY.GetValue() + camera.AutoFunctionROIHeight.GetValue() &lt;= camera.Height.GetMax()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Enable the &#x27;Brightness&#x27; auto function (Gain Auto + Exposure Auto)</span></span><br><span class=\"line\"><span class=\"comment\"># for the auto function ROI selected</span></span><br><span class=\"line\">camera.AutoFunctionROIUseBrightness.SetValue(<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\"># Highlight the auto function ROI selected</span></span><br><span class=\"line\">camera.AutoFunctionROIHighlight.SetValue(<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Auto-Function-Profile\"><a href=\"#Auto-Function-Profile\" class=\"headerlink\" title=\"Auto Function Profile\"></a>Auto Function Profile</h2><p>The Auto Function Profile camera feature allows you to specify how gain and exposure time are balanced when the camera is making automatic adjustments.</p>\n<h3 id=\"Setting-the-Auto-Function-Profile\"><a href=\"#Setting-the-Auto-Function-Profile\" class=\"headerlink\" title=\"Setting the Auto Function Profile\"></a>Setting the Auto Function Profile</h3><p>To set the auto function profile:</p>\n<ol>\n<li>Set the Gain Auto auto function and the Exposure Auto auto function to Continuous.</li>\n<li>Set the AutoFunctionProfile parameter to one of the following values (if available):<ul>\n<li>MinimizeGain</li>\n<li>MinimizeExposureTime</li>\n<li>MinimizeGainQuick</li>\n<li>MinimizeExposureTimeQuick</li>\n<li>Smart</li>\n<li>AntiFlicker50Hz</li>\n<li>AntiFlicker60Hz</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"Available-Auto-Function-Profiles\"><a href=\"#Available-Auto-Function-Profiles\" class=\"headerlink\" title=\"Available Auto Function Profiles\"></a>Available Auto Function Profiles</h3><h4 id=\"Minimize-Gain-Gain-Minimum\"><a href=\"#Minimize-Gain-Gain-Minimum\" class=\"headerlink\" title=\"Minimize Gain (= Gain Minimum)\"></a>Minimize Gain (= Gain Minimum)</h4><p>The gain is kept as low as possible during the automatic adjustment process. If the exposure time is at its upper limit and the target brightness value has not been reached yet, the gain will be increased in order to reach the target.</p>\n<h4 id=\"Minimize-Exposure-Time-Exposure-Minimum\"><a href=\"#Minimize-Exposure-Time-Exposure-Minimum\" class=\"headerlink\" title=\"Minimize Exposure Time (= Exposure Minimum)\"></a>Minimize Exposure Time (= Exposure Minimum)</h4><p>The exposure time is kept as low as possible during the automatic adjustment process. If the gain is at its upper limit and the target brightness value has not been reached yet, the exposure time will be increased in order to reach the target.</p>\n<h4 id=\"Minimize-Gain-Quick-Gain-Minimum-Quick\"><a href=\"#Minimize-Gain-Quick-Gain-Minimum-Quick\" class=\"headerlink\" title=\"Minimize Gain Quick (= Gain Minimum Quick)\"></a>Minimize Gain Quick (= Gain Minimum Quick)</h4><p>This profile works the same as the Minimize Gain profile. The difference is that it reacts more quickly in situations with extreme changes in brightness or where the image brightness changes rapidly. This situation occurs, for example, when microscope objective lenses are changed using the objective turret.</p>\n<h4 id=\"Minimize-Exposure-Time-Quick-Exposure-Minimum-Quick\"><a href=\"#Minimize-Exposure-Time-Quick-Exposure-Minimum-Quick\" class=\"headerlink\" title=\"Minimize Exposure Time Quick (= Exposure Minimum Quick)\"></a>Minimize Exposure Time Quick (= Exposure Minimum Quick)</h4><p>This profile works the same as the Minimize Exposure Time profile. The difference is that it reacts more quickly in situations with extreme changes in brightness or where the image brightness changes rapidly. This situation occurs, for example, when microscope objective lenses are changed using the objective turret.</p>\n<h4 id=\"Smart\"><a href=\"#Smart\" class=\"headerlink\" title=\"Smart\"></a>Smart</h4><p>Gain is kept as low as possible and the frame rate will be kept as high as possible during automatic adjustments.</p>\n<p>This is a four-step process:</p>\n<ol>\n<li>The camera adjusts the exposure time to achieve the target brightness value.</li>\n<li>If the exposure time must be increased to achieve the target brightness value, the camera does so until the frame rate drops.</li>\n<li>If the frame rate drops, the camera stops increasing the exposure time and increases the gain until the AutoGainUpperLimit value is reached.</li>\n<li>When the AutoGainUpperLimit value has been reached, the camera stops increasing the gain and increases the exposure time until the target brightness value is reached. Increasing the exposure time results in a lower frame rate.</li>\n</ol>\n<h4 id=\"Anti-Flicker-50-Hz-60-Hz\"><a href=\"#Anti-Flicker-50-Hz-60-Hz\" class=\"headerlink\" title=\"Anti-Flicker 50 Hz / 60 Hz\"></a>Anti-Flicker 50 Hz / 60 Hz</h4><p>Gain and exposure time are optimized to reduce flickering. If the camera is operating in an environment where the lighting flickers at a 50-Hz or a 60-Hz rate, the flickering lights can cause significant changes in brightness from image to image. Enabling the anti-flicker profile may reduce the effect of the flickering in the captured images.</p>\n<p>Choose the frequency (50 Hz or 60 Hz) according your local power line frequency (e.g., North America: 60 Hz, Europe: 50 Hz).</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Set the auto function profile to Exposure Minimum</span></span><br><span class=\"line\">camera.AutoFunctionProfile.SetValue(<span class=\"string\">&quot;MinimizeExposureTime&quot;</span>);</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionProfile.GetValue(): &quot;</span>, camera.AutoFunctionProfile.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the auto function profile to Gain Minimum</span></span><br><span class=\"line\">camera.AutoFunctionProfile.SetValue(<span class=\"string\">&quot;MinimizeGain&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionProfile.GetValue(): &quot;</span>, camera.AutoFunctionProfile.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Enable Gain and Exposure Auto auto functions and set the operating mode to Continuous</span></span><br><span class=\"line\"></span><br><span class=\"line\">camera.GainAuto.SetValue(<span class=\"string\">&quot;Continuous&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.GainAuto.GetValue(): &quot;</span>, camera.GainAuto.GetValue())</span><br><span class=\"line\"></span><br><span class=\"line\">camera.ExposureAuto.SetValue(<span class=\"string\">&quot;Continuous&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.ExposureAuto.GetValue(): &quot;</span>, camera.ExposureAuto.GetValue())</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Balance-White-Auto\"><a href=\"#Balance-White-Auto\" class=\"headerlink\" title=\"Balance White Auto\"></a>Balance White Auto</h2><p>The Balance White Auto camera feature automatically corrects color shifts in images acquired.</p>\n<p>The pixel data for the auto function can come from one or multiple auto function ROIs.</p>\n<p>To correct color shifts manually, use the Balance White feature.</p>\n<h3 id=\"Enabling-or-Disabling-Balance-White-Auto\"><a href=\"#Enabling-or-Disabling-Balance-White-Auto\" class=\"headerlink\" title=\"Enabling or Disabling Balance White Auto\"></a>Enabling or Disabling Balance White Auto</h3><p>To enable or disable the Balance White Auto auto function:</p>\n<ol>\n<li>Assign at least one auto function ROI to the Balance White Auto auto function.<br> Make sure the auto function ROI overlaps the image ROI, either partially or completely.</li>\n<li>Set the BalanceWhiteAuto parameter to one of the following operating modes:<ul>\n<li>Once: The camera adjusts the white balance until the average gray values for red, green, and blue are identical. When this has been achieved, or after a maximum of 30 calculation cycles, the camera sets the auto function to Off and applies the balance ratios resulting from the last calculation to all following images.</li>\n<li>Continuous: The camera adjusts the white balance continuously while images are being acquired. The adjustment process continues until the operating mode is set to Once or Off.</li>\n<li>Off: Disables the Balance White Auto auto function. The BalanceRatio parameters remain at the values resulting from the last automatic or manual adjustment.</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"How-It-Works-1\"><a href=\"#How-It-Works-1\" class=\"headerlink\" title=\"How It Works\"></a>How It Works</h3><p>Automatic white balancing is a two-step process:</p>\n<ol>\n<li>The camera compares the average gray values of the red, green, and blue pixels. It determines the color with the highest average gray value (i.e., the brightest color) and sets the BalanceRatio parameter value for this color to 1.</li>\n<li>The camera automatically adjusts the BalanceRatio parameter values of the other two colors until the average gray values for red, green, and blue are identical.</li>\n</ol>\n<p>As a result, the BalanceRatio parameter is set to 1 for one color and to a value between 1 and ≈15.98 for the other two colors.</p>\n<p>Example: Assume the green pixels in your image have the highest average gray value. If you enable the Balance White Auto auto function, the camera sets the BalanceRatio parameter value for green to 1. Then, the camera automatically adjusts the BalanceRatio parameter values for red and blue until the average gray values for red, green, and blue are identical. The new balance ratios could be, e.g., green = 1, red = 1.08789, and blue = 2.19678.</p>\n<p><strong>Info</strong></p>\n<ul>\n<li>To view the BalanceRatio parameter values for red, green, or blue, switch to the respective color channel using the BalanceRatioSelector.</li>\n<li>When the camera is capturing images continuously, the auto function takes effect with a short delay. The first few images may not be affected by the auto function.</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera.AutoFunctionROISelector.SetValue(<span class=\"string\">&quot;ROI1&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">camera.AutoFunctionROIUseWhiteBalance.SetValue(<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.AutoFunctionROIUseWhiteBalance.GetValue(): &quot;</span>, camera.AutoFunctionROIUseWhiteBalance.GetValue())</span><br><span class=\"line\">camera.BalanceWhiteAuto.SetValue(<span class=\"string\">&quot;Continuous&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">&quot;camera.BalanceWhiteAuto.GetValue(): &quot;</span>, camera.BalanceWhiteAuto.GetValue())</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Light-Source-Preset\"><a href=\"#Light-Source-Preset\" class=\"headerlink\" title=\"Light Source Preset\"></a>Light Source Preset</h2><p><img src=\"https://docs.baslerweb.com/light-source-preset\"></p>\n<p>The Light Source Preset camera feature allows you to correct color shifts caused by certain light sources.</p>\n<p>Depending on its specific color temperature, the light used for image acquisition can cause color shifts in the image. You can correct these color shifts by selecting the related light source preset.</p>\n<p>Selecting a Light Source Preset</p>\n<p>To select a light source preset, set the BslLightSourcePreset parameter to one of the following values (if available):</p>\n<pre><code>Off: No light source preset is selected.\nDaylight5000K: The camera corrects color shifts caused by daylight lighting that has a color temperature of about 5 000 K.\nDaylight6500K: The camera corrects color shifts caused by daylight lighting that has a color temperature of about 6 500 K.\nTungsten2800K: The camera corrects color shifts caused by tungsten lighting that has a color temperature of about 2 500 to 3 000 K.\nMicroscopeLED4500K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 4 500 K.\nMicroscopeLED5500K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 5 500 K.\nMicroscopeLED6000K: The camera corrects color shifts caused by microscope LED lighting that has a color temperature of about 6 000 K.\nFluorescent4000K: The camera corrects color shifts caused by fluorescent lighting that has a color temperature of about 4 000 K.\nCustom: Selecting this preset enables the Color Transformation feature which allows you to customize the light source settings. You should only select this preset if you are thoroughly familiar with matrix color transformations. The camera also adjusts the Balance White and Color Adjustment settings so that they have neutral values that do not change the appearance of the colors.</code></pre>\n<p>The default light source preset varies by camera model.<br><strong>Info</strong></p>\n<p>On Basler dart cameras, the light source presets are calibrated for the IR cut filter in the CS-mount variant. If you are using an S-mount or bare board variant, make sure your IR cut filter has suitable spectral characteristics.</p>\n<p>For more information about the IR cut filter, see your camera topic. You can find your camera topic in the “Models” section.</p>\n<h3 id=\"Impact-on-Other-Features\"><a href=\"#Impact-on-Other-Features\" class=\"headerlink\" title=\"Impact on Other Features\"></a>Impact on Other Features</h3><p>When you select a light source preset, the camera adjusts the settings of the following color enhancement features:</p>\n<ul>\n<li>Balance White</li>\n<li>Color Adjustment</li>\n<li>Color Transformation<br>The settings will be optimized for the selected light source.<br>On some camera models, you can choose which features you want the camera to adjust.</li>\n</ul>\n<h3 id=\"Separate-Processing\"><a href=\"#Separate-Processing\" class=\"headerlink\" title=\"Separate Processing\"></a>Separate Processing</h3><p>On some camera models, when you select a light source preset, the camera processes the changes to the features listed above separately. This means that the values of the corresponding parameters visible in the pylon API and the pylon Viewer are not changed.</p>\n<p>Example: If you select the Daylight6500K light source preset, the camera adjusts the white balance, but the values of the BalanceRatio parameter don’t change.</p>\n<p>This has the advantage that you don’t lose your color enhancement feature settings when you change the light source preset. Your own settings are independent from the light source preset adjustments.</p>\n<h3 id=\"No-Separate-Processing\"><a href=\"#No-Separate-Processing\" class=\"headerlink\" title=\"No Separate Processing\"></a>No Separate Processing</h3><p>On some camera models, when you select a light source preset, the camera doesn’t process the feature changes separately. Instead, the camera directly adjusts the corresponding parameter values.</p>\n<p>Example: If you select the Daylight6500K light source preset, the values of the BalanceRatio parameter change. You can see the changes in the pylon Viewer or by accessing the parameter via the pylon API.</p>\n<p>This means if you set up the color enhancement features and then change the light source preset, your settings will be overwritten.</p>\n<h3 id=\"Light-Source-Preset-Feature-Selector\"><a href=\"#Light-Source-Preset-Feature-Selector\" class=\"headerlink\" title=\"Light Source Preset Feature Selector\"></a>Light Source Preset Feature Selector</h3><p>On some camera models, the BslLightSourcePresetFeatureSelector parameter is available.</p>\n<p>If the parameter is available, you can select which features you want the camera to adjust when you select a light source preset.</p>\n<p>By default, the camera adjusts all features.</p>\n<p>To enable or disable adjustment of a specific feature:</p>\n<ol>\n<li>Set the BslLightSourcePresetFeatureSelector parameter to the desired feature, e.g., ColorAdjustment.</li>\n<li>Set the BslLightSourcePresetFeatureEnable parameter to true (feature enabled) or false (feature disabled).</li>\n<li>Repeat steps 1 and 2 for all features that you want to enable or disable.</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Disable light source presets (no correction)</span></span><br><span class=\"line\">camera.BslLightSourcePreset.SetValue(<span class=\"string\">&quot;Off&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># Set the light source preset for daylight (at about 5000K)</span></span><br><span class=\"line\">camera.BslLightSourcePreset.SetValue(<span class=\"string\">&quot;Daylight5000K&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># Set the light source preset for tungsten lighting (at about 2800K)</span></span><br><span class=\"line\">camera.BslLightSourcePreset.SetValue(<span class=\"string\">&quot;Tungsten&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># Set the light source preset for daylight (at about 6500K)</span></span><br><span class=\"line\">camera.BslLightSourcePreset.SetValue(<span class=\"string\">&quot;Daylight6500K&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Disable adjustment of a specific feature</span></span><br><span class=\"line\">camera.BslLightSourcePresetFeatureSelector.SetValue(<span class=\"string\">&quot;ColorAdjustment&quot;</span>)</span><br><span class=\"line\">camera.BslLightSourcePresetFeatureEnable.SetValue(<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ckfyx1aio0001iiiy08kbgek4","category_id":"ckfyx1air0004iiiya4hf8xra","_id":"ckfyx1aix000fiiiybatm6tvf"},{"post_id":"ckfyx1aiv000ciiiyhmjp9k94","category_id":"ckfyx1air0004iiiya4hf8xra","_id":"ckfyx1aiy000kiiiy9ifa5659"},{"post_id":"ckfyx1aiq0003iiiy3ve66u8c","category_id":"ckfyx1air0004iiiya4hf8xra","_id":"ckfyx1aj0000oiiiy1xiyagi2"},{"post_id":"ckfyx1ais0007iiiy3lun02jm","category_id":"ckfyx1air0004iiiya4hf8xra","_id":"ckfyx1aj0000riiiy9qlk2bji"},{"post_id":"ckfyx1ait0008iiiy551egwrt","category_id":"ckfyx1aiy000liiiy4jgf5hfq","_id":"ckfyx1aj2000yiiiyfhpkadh3"},{"post_id":"ckfyx1aiw000diiiya6lr3zr6","category_id":"ckfyx1aj0000siiiydv9nbh1i","_id":"ckfyx1aj30014iiiy99ewhqrz"},{"post_id":"ckfyx1aiy000jiiiycrqw76q3","category_id":"ckfyx1aj2000ziiiy9la91kr5","_id":"ckfyx1aj40018iiiybo7shzau"},{"post_id":"ckfyx1aj30013iiiy9m6re4o8","category_id":"ckfyx1aj2000ziiiy9la91kr5","_id":"ckfyx1aj5001biiiy9rq7bj85"},{"post_id":"ckfyx1aj0000qiiiy413c0vsh","category_id":"ckfyx1aj40016iiiy5lfw19cx","_id":"ckfyx1aj5001eiiiy751q5ke5"},{"post_id":"ckfyx1aj1000viiiyblinca3r","category_id":"ckfyx1aj40019iiiy5itq550o","_id":"ckfyx1aj5001iiiiy4g9v5b7i"},{"post_id":"ckfyx1aj1000xiiiyd9gfbfcz","category_id":"ckfyx1aj2000ziiiy9la91kr5","_id":"ckfyx1aj6001kiiiyhk0s06je"},{"post_id":"ckfyx1aj20011iiiyc53efllz","category_id":"ckfyx1aj5001hiiiy2v3j3rhm","_id":"ckfyx1aj6001oiiiya1143mpk"},{"post_id":"ckfyx1ajd002siiiycqnh9bbm","category_id":"ckfyx1aje002uiiiyhkbrd9yd","_id":"ckfyx1ajf002ziiiy86uvcuvw"},{"post_id":"ckfyx1ajd002tiiiygl3060ia","category_id":"ckfyx1aje002wiiiy36rs0sah","_id":"ckfyx1ajf0031iiiyeru8ej1w"}],"PostTag":[{"post_id":"ckfyx1aiv000ciiiyhmjp9k94","tag_id":"ckfyx1ais0005iiiy8lgh4d3t","_id":"ckfyx1aix000hiiiy7pyl0wwb"},{"post_id":"ckfyx1aio0001iiiy08kbgek4","tag_id":"ckfyx1ais0005iiiy8lgh4d3t","_id":"ckfyx1aj0000piiiy4ms17i5c"},{"post_id":"ckfyx1aio0001iiiy08kbgek4","tag_id":"ckfyx1aiu000biiiy2imifuo2","_id":"ckfyx1aj0000tiiiyf2hpevyl"},{"post_id":"ckfyx1aio0001iiiy08kbgek4","tag_id":"ckfyx1aix000giiiy65uj2664","_id":"ckfyx1aj1000wiiiyh6mi4fh9"},{"post_id":"ckfyx1aiq0003iiiy3ve66u8c","tag_id":"ckfyx1ais0005iiiy8lgh4d3t","_id":"ckfyx1aj30012iiiy5f1ighnv"},{"post_id":"ckfyx1aiq0003iiiy3ve66u8c","tag_id":"ckfyx1aj1000uiiiyd4mt2y6n","_id":"ckfyx1aj30015iiiyf53h6icp"},{"post_id":"ckfyx1ais0007iiiy3lun02jm","tag_id":"ckfyx1ais0005iiiy8lgh4d3t","_id":"ckfyx1aj5001ciiiy5bwwcful"},{"post_id":"ckfyx1ais0007iiiy3lun02jm","tag_id":"ckfyx1aj40017iiiy8o984goh","_id":"ckfyx1aj5001diiiyfghn44h7"},{"post_id":"ckfyx1ait0008iiiy551egwrt","tag_id":"ckfyx1aj1000uiiiyd4mt2y6n","_id":"ckfyx1aj6001miiiyhww06he7"},{"post_id":"ckfyx1ait0008iiiy551egwrt","tag_id":"ckfyx1aj5001fiiiyhzhi6fbn","_id":"ckfyx1aj6001niiiy6z4618lq"},{"post_id":"ckfyx1ait0008iiiy551egwrt","tag_id":"ckfyx1aj5001jiiiy4jfm8on7","_id":"ckfyx1aj6001qiiiy18d33tde"},{"post_id":"ckfyx1aiu0009iiiy7max3bkm","tag_id":"ckfyx1aj1000uiiiyd4mt2y6n","_id":"ckfyx1aj7001siiiy3txa5vga"},{"post_id":"ckfyx1aiu0009iiiy7max3bkm","tag_id":"ckfyx1aj6001piiiy6ipp9scg","_id":"ckfyx1aj7001tiiiy1ghc7xre"},{"post_id":"ckfyx1aiw000diiiya6lr3zr6","tag_id":"ckfyx1aj1000uiiiyd4mt2y6n","_id":"ckfyx1aj9001yiiiy4s77886g"},{"post_id":"ckfyx1aiw000diiiya6lr3zr6","tag_id":"ckfyx1aj7001uiiiy1xrjeqng","_id":"ckfyx1aj9001ziiiygm1b1998"},{"post_id":"ckfyx1aiw000diiiya6lr3zr6","tag_id":"ckfyx1aj8001viiiy8xe1377a","_id":"ckfyx1aj90021iiiybhz608g2"},{"post_id":"ckfyx1aiw000diiiya6lr3zr6","tag_id":"ckfyx1aj9001wiiiy0pw74ctf","_id":"ckfyx1aj90022iiiy434rfnxz"},{"post_id":"ckfyx1aiy000jiiiycrqw76q3","tag_id":"ckfyx1aj9001xiiiy0oswdt11","_id":"ckfyx1aja0024iiiy2fxp5szl"},{"post_id":"ckfyx1aiz000niiiy2s1dfcpd","tag_id":"ckfyx1aj90020iiiybl3gd8sw","_id":"ckfyx1aja0025iiiy0zhw99t2"},{"post_id":"ckfyx1aj0000qiiiy413c0vsh","tag_id":"ckfyx1aj90023iiiy79uv8ah8","_id":"ckfyx1aja0027iiiy9fo9ejns"},{"post_id":"ckfyx1aj1000viiiyblinca3r","tag_id":"ckfyx1aja0026iiiybkoj2qgs","_id":"ckfyx1ajb002diiiye0kmhkyi"},{"post_id":"ckfyx1aj1000viiiyblinca3r","tag_id":"ckfyx1aja0028iiiyh3yfdhce","_id":"ckfyx1ajb002eiiiy9c5xbcw0"},{"post_id":"ckfyx1aj1000viiiyblinca3r","tag_id":"ckfyx1aja0029iiiyav0t42nh","_id":"ckfyx1ajb002giiiycuzkfobl"},{"post_id":"ckfyx1aj1000viiiyblinca3r","tag_id":"ckfyx1aja002aiiiyd57a192d","_id":"ckfyx1ajb002hiiiya8f657jq"},{"post_id":"ckfyx1aj1000viiiyblinca3r","tag_id":"ckfyx1ajb002biiiybwij91ov","_id":"ckfyx1ajc002jiiiy7bw70dak"},{"post_id":"ckfyx1aj1000xiiiyd9gfbfcz","tag_id":"ckfyx1aj9001xiiiy0oswdt11","_id":"ckfyx1ajc002kiiiyayo5ealk"},{"post_id":"ckfyx1aj1000xiiiyd9gfbfcz","tag_id":"ckfyx1ajb002fiiiy2x2l574p","_id":"ckfyx1ajc002miiiy1bku6xvm"},{"post_id":"ckfyx1aj20011iiiyc53efllz","tag_id":"ckfyx1ajb002iiiiy4xvd6y48","_id":"ckfyx1ajc002oiiiyf4pkdsa8"},{"post_id":"ckfyx1aj20011iiiyc53efllz","tag_id":"ckfyx1aj1000uiiiyd4mt2y6n","_id":"ckfyx1ajc002piiiyeon7hjnm"},{"post_id":"ckfyx1aj20011iiiyc53efllz","tag_id":"ckfyx1ajc002liiiy20lje3jw","_id":"ckfyx1ajc002qiiiy5fyn6sf0"},{"post_id":"ckfyx1aj30013iiiy9m6re4o8","tag_id":"ckfyx1aj9001xiiiy0oswdt11","_id":"ckfyx1ajc002riiiyfzm35x4u"},{"post_id":"ckfyx1ajd002siiiycqnh9bbm","tag_id":"ckfyx1aje002viiiy2zgl9b66","_id":"ckfyx1ajf002yiiiy8uwzek2x"},{"post_id":"ckfyx1ajd002tiiiygl3060ia","tag_id":"ckfyx1aje002xiiiy405h6sb2","_id":"ckfyx1ajf0033iiiy9j3mhft8"},{"post_id":"ckfyx1ajd002tiiiygl3060ia","tag_id":"ckfyx1ajf0030iiiy7bfbamzp","_id":"ckfyx1ajf0034iiiyd8g77ljo"},{"post_id":"ckfyx1ajd002tiiiygl3060ia","tag_id":"ckfyx1ajf0032iiiy1vzbgnw1","_id":"ckfyx1ajg0035iiiy8ljm7wim"}],"Tag":[{"name":"Azure","_id":"ckfyx1ais0005iiiy8lgh4d3t"},{"name":"Compute instance","_id":"ckfyx1aiu000biiiy2imifuo2"},{"name":"Azure Machine Learning","_id":"ckfyx1aix000giiiy65uj2664"},{"name":"Machine Learning","_id":"ckfyx1aj1000uiiiyd4mt2y6n"},{"name":"Virtual Machine","_id":"ckfyx1aj40017iiiy8o984goh"},{"name":"Extented Image Training Set","_id":"ckfyx1aj5001fiiiyhzhi6fbn"},{"name":"OpenCV","_id":"ckfyx1aj5001jiiiy4jfm8on7"},{"name":"machine Learning File Formats","_id":"ckfyx1aj6001piiiy6ipp9scg"},{"name":"Conda","_id":"ckfyx1aj7001uiiiy1xrjeqng"},{"name":"Python","_id":"ckfyx1aj8001viiiy8xe1377a"},{"name":"R","_id":"ckfyx1aj9001wiiiy0pw74ctf"},{"name":"Networking","_id":"ckfyx1aj9001xiiiy0oswdt11"},{"name":"Linux command","_id":"ckfyx1aj90020iiiybl3gd8sw"},{"name":"Patent","_id":"ckfyx1aj90023iiiy79uv8ah8"},{"name":"UML","_id":"ckfyx1aja0026iiiybkoj2qgs"},{"name":"plantuml","_id":"ckfyx1aja0028iiiyh3yfdhce"},{"name":"Markdown","_id":"ckfyx1aja0029iiiyav0t42nh"},{"name":"Emacs","_id":"ckfyx1aja002aiiiyd57a192d"},{"name":"spacemacs","_id":"ckfyx1ajb002biiiybwij91ov"},{"name":"SSH","_id":"ckfyx1ajb002fiiiy2x2l574p"},{"name":"Tensorflow","_id":"ckfyx1ajb002iiiiy4xvd6y48"},{"name":"Nvidia GPU","_id":"ckfyx1ajc002liiiy20lje3jw"},{"name":"vim","_id":"ckfyx1aje002viiiy2zgl9b66"},{"name":"Basler","_id":"ckfyx1aje002xiiiy405h6sb2"},{"name":"Opencv","_id":"ckfyx1ajf0030iiiy7bfbamzp"},{"name":"python","_id":"ckfyx1ajf0032iiiy1vzbgnw1"}]}}